{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN implementation by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# utility関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_metrics(metrics, epoch=None):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"dis_loss\"], label=\"discriminative loss\", color=\"b\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"dloss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"gen_loss\"], label=\"generative loss\", color=\"r\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"g_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# noise[[examples, 100]]から生成した画像をplot_dim(例えば4x4)で表示\n",
    "def save_imgs(images, plot_dim=(5,12), size=(12,5), epoch=None):\n",
    "    examples = plot_dim[0]*plot_dim[1]\n",
    "\n",
    "    # 表示\n",
    "    fig = plt.figure(figsize=size)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(plot_dim[0], plot_dim[1], i+1)\n",
    "        img = images[i, :]\n",
    "        img = img.reshape((96, 96, 3))\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(os.path.join(\"generated_figures\", str(epoch) + \".png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, depths=[1024,512,256,128], s_size=6):\n",
    "        self.depths = depths + [3]\n",
    "        self.s_size = s_size\n",
    "        self.reuse = False\n",
    "\n",
    "    def __call__(self, inputs, training=False):\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            # reshape from inputs\n",
    "            outputs = tf.reshape(inputs, [-1, ])\n",
    "            with tf.variable_scope('reshape'):\n",
    "                outputs = tf.layers.dense(inputs, self.depths[0] * self.s_size * self.s_size)\n",
    "                outputs = tf.reshape(outputs, [-1, self.s_size, self.s_size, self.depths[0]])\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            # deconvolution (transpose of convolution) x 4\n",
    "            with tf.variable_scope('deconv1'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[1], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('deconv2'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[2], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('deconv3'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[3], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = tf.nn.relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('deconv4'):\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.depths[4], [5, 5], strides=(2, 2), padding='SAME')\n",
    "            # output images\n",
    "            with tf.variable_scope('tanh'):\n",
    "                outputs = tf.tanh(outputs, name='outputs')\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, depths=[64,128,256,512]):\n",
    "        self.depths = [3] + depths\n",
    "        self.reuse = False\n",
    "\n",
    "    def __call__(self, inputs, training=False, name=''):\n",
    "        def leaky_relu(x, leak=0.2, name=''):\n",
    "            return tf.maximum(x, x * leak, name=name)\n",
    "        outputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "        with tf.name_scope('d' + name), tf.variable_scope('d', reuse=self.reuse):\n",
    "            # convolution x 4\n",
    "            with tf.variable_scope('conv1'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[1], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('conv2'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[2], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('conv3'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[3], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('conv4'):\n",
    "                outputs = tf.layers.conv2d(outputs, self.depths[4], [5, 5], strides=(2, 2), padding='SAME')\n",
    "                outputs = leaky_relu(tf.layers.batch_normalization(outputs, training=training), name='outputs')\n",
    "            with tf.variable_scope('classify'):\n",
    "                batch_size = outputs.get_shape()[0].value\n",
    "                reshape = tf.reshape(outputs, [batch_size, -1])\n",
    "                outputs = tf.layers.dense(reshape, 1, name='outputs')\n",
    "                outputs = tf.nn.sigmoid(outputs)\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self,\n",
    "                 batch_size=64, s_size=6, z_dim=100,\n",
    "                 g_depths=[1024, 512, 256, 128],\n",
    "                 d_depths=[64, 128, 256, 512]):\n",
    "        self.batch_size = batch_size\n",
    "        self.s_size = s_size\n",
    "        self.z_dim = z_dim\n",
    "        self.g = Generator(depths=g_depths, s_size=self.s_size)\n",
    "        self.d = Discriminator(depths=d_depths)\n",
    "        self.z = tf.random_uniform([self.batch_size, self.z_dim], minval=-1.0, maxval=1.0)\n",
    "\n",
    "    def d_loss_calc(self, g_outputs, t_outputs):\n",
    "        \"\"\"\n",
    "        clipvalue = tf.constant(1e-10, shape=[self.batch_size,1], dtype=tf.float32)\n",
    "\n",
    "        loss = tf.log(tf.clip_by_value(t_outputs[0:self.batch_size], clipvalue, tf.ones(self.batch_size, tf.float32))) + tf.log(tf.clip_by_value(tf.ones(self.batch_size, tf.float32)-g_outputs[0:self.batch_size], clipvalue, tf.ones(self.batch_size, tf.float32)))\n",
    "\n",
    "        loss = tf.reduce_sum(loss, axis=1)\n",
    "        loss = -tf.reduce_mean(loss)\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = -tf.reduce_mean(tf.log(t_outputs) + tf.log(1. - g_outputs))\n",
    "        return loss\n",
    "\n",
    "    def g_loss_calc(self, g_outputs):\n",
    "#        clipvalue = tf.constant(1e-10, shape=[self.batch_size,1], dtype=tf.float32)\n",
    " #       loss = tf.log(tf.clip_by_value(tf.ones(self.batch_size, tf.float32)-g_outputs[0:self.batch_size], clipvalue, tf.ones(self.batch_size, tf.float32)))\n",
    "    #      loss = tf.reduce_sum(loss, axis=1)\n",
    "    #     loss = tf.reduce_mean(loss)\n",
    "\n",
    "        loss = -tf.reduce_mean(tf.log(g_outputs))\n",
    "        \n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "    def loss(self, traindata):\n",
    "        \"\"\"build models, calculate losses.\n",
    "        Args:\n",
    "            traindata: 4-D Tensor of shape `[batch, height, width, channels]`.\n",
    "        Returns:\n",
    "            dict of each models' losses.\n",
    "        \"\"\"\n",
    "        \n",
    "        generated = self.g(self.z, training=True)\n",
    "        g_outputs = self.d(generated, training=True, name='g')\n",
    "        t_outputs = self.d(traindata, training=True, name='t')\n",
    "        # add each losses to collection\n",
    "        \n",
    "        \"\"\"\n",
    "        tf.add_to_collection(\n",
    "            'g_losses',\n",
    "            tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.ones([self.batch_size], dtype=tf.int64),\n",
    "                    logits=g_outputs)))\n",
    "        tf.add_to_collection(\n",
    "            'd_losses',\n",
    "            tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.ones([self.batch_size], dtype=tf.int64),\n",
    "                    logits=t_outputs)))\n",
    "        tf.add_to_collection(\n",
    "            'd_losses',\n",
    "            tf.reduce_mean(\n",
    "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=tf.zeros([self.batch_size], dtype=tf.int64),\n",
    "                    logits=g_outputs)))\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # add each losses to collection\n",
    "        tf.add_to_collection(\n",
    "            'g_losses',\n",
    "            self.g_loss_calc(g_outputs))\n",
    "\n",
    "        tf.add_to_collection(\n",
    "            'd_losses',\n",
    "            self.d_loss_calc(g_outputs, t_outputs)\n",
    "        )\n",
    "\n",
    "\n",
    "        return {\n",
    "            self.g: tf.add_n(tf.get_collection('g_losses'), name='total_g_loss'),\n",
    "            self.d: tf.add_n(tf.get_collection('d_losses'), name='total_d_loss'),\n",
    "        }\n",
    "\n",
    "    def train(self, losses, learning_rate=0.0002, beta1=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            losses dict.\n",
    "        Returns:\n",
    "            train op.\n",
    "        \"\"\"\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "        g_opt_op = g_opt.minimize(losses[self.g], var_list=self.g.variables)\n",
    "        d_opt_op = d_opt.minimize(losses[self.d], var_list=self.d.variables)\n",
    "        with tf.control_dependencies([g_opt_op, d_opt_op]):\n",
    "            return tf.no_op(name='train')\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, losses, learning_rate=0.0002, beta1=0.5):\n",
    "        g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "        d_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "\n",
    "        g_optimizer = g_optimizer.minimize(losses[self.g], var_list=self.g.variables)\n",
    "        d_optimizer = d_optimizer.minimize(losses[self.d], var_list=self.d.variables)\n",
    "        with tf.control_dependencies([g_optimizer, d_optimizer]):\n",
    "            return tf.no_op(name=\"train\")\n",
    "\n",
    "    def sample_images(self, row=5, col=12, inputs=None, epoch=None):\n",
    "        images = self.g(inputs, training=True)\n",
    "        #save_imgs(images, epoch=epoch)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"irasutoya_10575x96x96x3_jpg.npy\")\n",
    "X_train = X_train/255\n",
    "\n",
    "z_dim = 100\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "display_epoch = 100\n",
    "param_save_epoch = 100000\n",
    "loss = {\"dis_loss\":[], \"gen_loss\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_noise = tf.placeholder(tf.float32, [None, z_dim])\n",
    "noise_check = np.random.uniform(-1, 1, size=[60, z_dim]).astype(np.float32)\n",
    "\n",
    "dcgan = DCGAN()\n",
    "p_train_images = tf.placeholder(tf.float32, [batch_size, 96, 96, 3])\n",
    "losses = dcgan.loss(traindata=p_train_images)\n",
    "train_op = dcgan.train(losses)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #self.z = tf.random_uniform([self.batch_size, self.z_dim], minval=-1.0, maxval=1.0) # 値域これでいいんだっけ？\n",
    "        \n",
    "        # ノイズから生成データを生成\n",
    "        noise = np.random.uniform(-1, 1, size=[batch_size, z_dim])\n",
    "\n",
    "        if epoch % display_epoch == 0:\n",
    "            imgs_gen = dcgan.sample_images(inputs=noise_check).eval()\n",
    "            print(\"saving images\")\n",
    "            save_imgs(imgs_gen, epoch=epoch)\n",
    "\n",
    "        # 訓練データを抜粋\n",
    "        rand_index = np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "        exImgs = X_train[rand_index, :].astype(np.float32)\n",
    "\n",
    "        _, g_loss_value, d_loss_value = sess.run([train_op, losses[dcgan.g], losses[dcgan.d]], feed_dict={p_train_images: exImgs})\n",
    "\n",
    "\n",
    "        # 結果をappend\n",
    "        loss[\"dis_loss\"].append(d_loss_value)\n",
    "        loss[\"gen_loss\"].append(g_loss_value)\n",
    "        print(\"epoch:\" + str(epoch))\n",
    "        # グラフの描画（余裕があったら）\n",
    "        if epoch % display_epoch == 0:\n",
    "            save_metrics(loss, epoch)\n",
    "\n",
    "        if epoch % param_save_epoch == 0:\n",
    "            saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(batch_size, x):\n",
    "    with tf.variable_scope(\"G\"):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = tf.reshape(x, [batch_size, 100])\n",
    "\n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            weights = tf.get_variable(\"fcw1\", [100, 1024], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"fcb1\", [1024], initializer=tf.random_normal_initializer())\n",
    "            fc1 = tf.add(tf.matmul(x, weights), biases)\n",
    "            fc1 = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, scope=\"bn\")\n",
    "            fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "        with tf.variable_scope(\"fc2\"):\n",
    "            weights = tf.get_variable(\"fcw1\", [1024, 64*24*24],initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"fcb1\", [64*24*24], initializer=tf.random_normal_initializer())\n",
    "            fc2 = tf.matmul(fc1, weights)\n",
    "            fc2 = tf.add(fc2, biases)\n",
    "            fc2 = tf.contrib.layers.batch_norm(fc2, center=True, scale=True, scope=\"bn\")\n",
    "            fc2 = tf.nn.relu(fc2)\n",
    "            fc2 = tf.reshape(fc2, [batch_size,24,24,64])\n",
    "\n",
    "        with tf.variable_scope(\"deconv1\"):\n",
    "            weights = tf.get_variable(\"dcw1\", [5, 5, 64, 64], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"dcb1\", [64], initializer=tf.random_normal_initializer())\n",
    "            deconv1 = tf.nn.conv2d_transpose(fc2, weights, output_shape=[batch_size, 48, 48, 64], strides=[1, 2, 2, 1])\n",
    "            deconv1 = tf.nn.bias_add(deconv1, biases)\n",
    "            deconv1 = tf.contrib.layers.batch_norm(deconv1, center=True, scale=True, scope=\"bn\")\n",
    "            deconv1 = tf.nn.relu(deconv1)\n",
    "\n",
    "        with tf.variable_scope(\"deconv2\"):\n",
    "            weights = tf.get_variable(\"dcw2\", [5, 5, 3, 64], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"dcb2\", [3], initializer=tf.random_normal_initializer())\n",
    "            deconv2 = tf.nn.conv2d_transpose(deconv1, weights, output_shape=[batch_size, 96, 96, 3], strides=[1,2,2,1])\n",
    "            deconv2 = tf.nn.bias_add(deconv2, biases)\n",
    "            deconv2 = tf.tanh(deconv2)\n",
    "    return deconv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator(x, dropout=0.5, reuse=False):\n",
    "\n",
    "    x = tf.reshape(x, [-1, 96, 96, 3])\n",
    "    with tf.variable_scope(\"D\", reuse=reuse):\n",
    "        with tf.variable_scope(\"conv1\"):\n",
    "            weights = tf.get_variable(\"cw1\", [5, 5, 3, 64], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"cb1\", [64], initializer=tf.random_normal_initializer())\n",
    "            conv1 = tf.nn.conv2d(x, weights, strides=[1, 2, 2, 1], padding='SAME')\n",
    "            conv1 = tf.nn.bias_add(conv1, biases)\n",
    "            conv1 = lrelu(conv1)\n",
    "\n",
    "        with tf.variable_scope(\"conv2\"):\n",
    "            # Convolution\n",
    "            weights = tf.get_variable(\"cw2\", [5, 5, 64, 128], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"cb2\", [128], initializer=tf.random_normal_initializer())\n",
    "            conv2 = tf.nn.conv2d(conv1, weights, strides=[1, 2, 2, 1], padding='SAME')\n",
    "            conv2 = tf.nn.bias_add(conv2, biases)\n",
    "            conv2 = lrelu(conv2)\n",
    "\n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            weights = tf.get_variable(\"fcw1\", [24*24*128, 256], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"fcb1\", [256], initializer=tf.random_normal_initializer())\n",
    "            fc1 = tf.reshape(conv2, [-1, weights.get_shape().as_list()[0]])\n",
    "            fc1 = tf.add(tf.matmul(fc1, weights), biases)\n",
    "            fc1 = lrelu(fc1)\n",
    "            fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "        with tf.variable_scope(\"fc2\"):\n",
    "            weights = tf.get_variable(\"fcw2\", [256,1], initializer=tf.random_normal_initializer())\n",
    "            biases = tf.get_variable(\"fcb1\", [1], initializer=tf.random_normal_initializer())\n",
    "            fc2 = tf.add(tf.matmul(fc1, weights), biases)\n",
    "            fc2 = tf.sigmoid(fc2)\n",
    "\n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_train(batch_size, output):\n",
    "    # lossの定義\n",
    "    clipvalue = tf.constant(1e-10, shape=[batch_size,1], dtype=tf.float32)\n",
    "    loss = tf.log(tf.clip_by_value(output[0:batch_size], clipvalue, tf.ones(batch_size, tf.float32))) + tf.log(tf.clip_by_value(tf.ones(batch_size, tf.float32)-output[batch_size:2*batch_size], clipvalue, tf.ones(batch_size, tf.float32)))\n",
    "    loss = tf.reduce_sum(loss, axis=1)\n",
    "    loss = -tf.reduce_mean(loss)\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    beta1 = 0.1\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "\n",
    "\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    print()\n",
    "    print(\"discriminator\")\n",
    "    for g,v in grads_and_vars:\n",
    "        print(v.name)\n",
    "    print()\n",
    "\n",
    "    grads_and_vars = [[grad, var] for grad, var in grads_and_vars if var.name.startswith(\"D\")]\n",
    "    # grads_and_vars = [[grad, var] for grad, var in grads_and_vars if grad is not None]\n",
    "    for g,v in grads_and_vars:\n",
    "        print(v.name)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_train(batch_size, output):\n",
    "    # 全てが生成データ\n",
    "    # discriの符号逆転バージョン\n",
    "    #clipvalue = tf.constant(1e-10, shape=[batch_size,1], dtype=tf.float32)\n",
    "    #loss = tf.log(tf.clip_by_value(tf.ones(batch_size, tf.float32)-output[0:batch_size], clipvalue, tf.ones(batch_size, tf.float32)))\n",
    "    #loss = tf.reduce_sum(loss, axis=1)\n",
    "    #loss = tf.reduce_mean(loss)    \n",
    "    \n",
    "\n",
    "    # lossの定義\n",
    "    clipvalue = tf.constant(1e-10, shape=[batch_size,1], dtype=tf.float32)\n",
    "    loss = -tf.reduce_sum(tf.log(tf.clip_by_value(output[0:batch_size], clipvalue, tf.ones(batch_size, tf.float32))), axis=1)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    learning_rate = 1e-5\n",
    "    beta1 = 0.1\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    \n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    print()\n",
    "    print(\"generator\")\n",
    "    for g,v in grads_and_vars:\n",
    "        print(v.name)\n",
    "    print()\n",
    "    grads_and_vars = [[grad, var] for grad, var in grads_and_vars if var.name.startswith(\"G\")]\n",
    "    for g,v in grads_and_vars:\n",
    "        print(v.name)\n",
    "    #print(grads_and_vars)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars)\n",
    "    #train_op = optimizer.minimize(loss, grads_and_vars[1])\n",
    "\n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"irasutoya_10575x96x96x3_jpg.npy\")\n",
    "X_train = X_train/255\n",
    "\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "display_epoch = 50\n",
    "save_param_epoch = 10000\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 100 # MNIST data input (img shape: 28*28)\n",
    "#n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "#dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# 結果\n",
    "loss = {\"dis_loss\":[], \"gen_loss\":[]}\n",
    "print(type(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import tensorboard as tb\n",
    "#tf.get_default_graph().get_operations()\n",
    "\n",
    "#config = tf.ConfigProto(allow_soft_placement=True)\n",
    "#config.gpu_options.allow_growth = True\n",
    "\n",
    "p_noise = tf.placeholder(tf.float32, [None, n_input])\n",
    "p_img_trainX = tf.placeholder(tf.float32, [None, 96, 96, 3])\n",
    "p_batch_size = tf.placeholder(tf.int32)\n",
    "\n",
    "generated_trainX = generator(p_batch_size, p_noise)\n",
    "\n",
    "# 生成データと訓練データを結合\n",
    "# X = np.vstack((img_trainX, generated_trainX))\n",
    "X = tf.concat([p_img_trainX, generated_trainX], 0)\n",
    "\n",
    "# ラベル作成\n",
    "#y = np.ones(int(2*batch_size))\n",
    "#y[batch_size:] = 0\n",
    "#y = y.astype(int)\n",
    "\n",
    "print()\n",
    "\n",
    "dis = discriminator(X, reuse=False)\n",
    "dis_train_op, dis_loss = discriminator_train(batch_size, dis)\n",
    "\n",
    "print()\n",
    "\n",
    "gan = discriminator(generated_trainX, reuse=True)\n",
    "gen_train_op, gen_loss = generator_train(batch_size, gan)\n",
    "\n",
    "# 画像可視化チェック用noise\n",
    "noise_check = np.random.uniform(0, 1, size=[60, n_input])\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "#    step = 1\n",
    "    for epoch in range(epochs+1):\n",
    "        print(epoch)\n",
    "        \n",
    "        # ノイズから生成データを生成\n",
    "        noise = np.random.uniform(0, 1, size=[batch_size, n_input])\n",
    "\n",
    "        if epoch % display_epoch == 0:\n",
    "            gen_check_imgs = sess.run(generated_trainX, feed_dict={p_noise: noise_check, p_batch_size: 60})\n",
    "            print(\"saving images\")\n",
    "            save_imgs(gen_check_imgs, epoch=epoch)\n",
    "\n",
    "        # 訓練データを抜粋\n",
    "        rand_train_index = np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "        img_trainX = X_train[rand_train_index, :].astype(np.float32)\n",
    "        #img_trainX = tf.constant(img_trainX)\n",
    "\n",
    "        # discriminatorの学習\n",
    "        _, d_loss = sess.run([dis_train_op, dis_loss], feed_dict={p_noise: noise, p_img_trainX: img_trainX, p_batch_size: batch_size})\n",
    "        #sess.run(dis_train_op, feed_dict={p_noise: noise, p_img_trainX: img_trainX, p_batch_size: batch_size})\n",
    "\n",
    "        # generatorの学習\n",
    "        _, g_loss = sess.run([gen_train_op, gen_loss], feed_dict={p_noise: noise, p_batch_size: batch_size})\n",
    "        #sess.run(gen_train_op, feed_dict={p_noise: noise, p_batch_size: batch_size})\n",
    "        #gen_loss = sess.run(gen_loss, feed_dict={p_noise: noise})\n",
    "        \n",
    "        # 結果をappend\n",
    "        loss[\"dis_loss\"].append(d_loss)\n",
    "        loss[\"gen_loss\"].append(g_loss)\n",
    "\n",
    "        # グラフの描画（余裕があったら）\n",
    "        if epoch % display_epoch == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            # d_loss, acc = sess.run([loss, accuracy], feed_dict)\n",
    "\n",
    "            print(\"display_epoch:\" + str(epoch))\n",
    "            #print(\"dis_loss:\" + str(dis_loss))\n",
    "            #print(\"gen_loss:\" + str(gen_loss))\n",
    "            \n",
    "            save_metrics(loss, epoch)\n",
    "        # 訓練したgeneratorによる生成画像の可視化\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "tb.show_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
