{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN implementation by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util import *\n",
    "from ops import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "        self.X_dim = 96*96*3\n",
    "        self.z_dim = 100\n",
    "\n",
    "    def __call__(self, inputs, name):\n",
    "        with tf.variable_scope('g_' + name, reuse=self.reuse):\n",
    "            inputs = tf.reshape(inputs, [-1, self.z_dim])\n",
    "            fc1 = inputs\n",
    "            fc2 = tf.layers.dense(fc1, 6*6*512)\n",
    "            fc2 = tf.reshape(fc2, [-1, 6,6,512])\n",
    "            fc2 = tf.nn.relu(fc2)\n",
    "            conv1 = tf.contrib.layers.conv2d_transpose(fc2, 512, [4,4],[2,2]) # 12\n",
    "            conv1 = tf.nn.relu(conv1)\n",
    "            conv2 = tf.contrib.layers.conv2d_transpose(conv1, 256, [4,4],[2,2]) # 24\n",
    "            conv2 = tf.nn.relu(conv2)\n",
    "            conv3 = tf.contrib.layers.conv2d_transpose(conv2, 128, [4,4],[2,2]) # 48\n",
    "            conv3 = tf.nn.relu(conv3)\n",
    "            conv4 = tf.contrib.layers.conv2d_transpose(conv3, 3, [4,4],[2,2], activation_fn=tf.sigmoid)\n",
    "            conv4 = tf.reshape(conv4, [-1, 96*96*3])\n",
    "            outputs = conv4\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.reuse = False\n",
    "        self.X_dim = 96*96*3\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "        self.s_size = 6\n",
    "\n",
    "    def __call__(self, inputs, name):\n",
    "        def leaky_relu(x, leak=0.2, name='outputs'):\n",
    "            return tf.maximum(x, x * leak, name=name)\n",
    "\n",
    "        with tf.variable_scope('d_'+name, reuse=self.reuse):\n",
    "            x = tf.reshape(inputs, [-1, 96, 96, 3])\n",
    "            conv1 = tf.layers.conv2d(x, 64, [4,4], [2,2])\n",
    "            conv1 = leaky_relu(conv1)\n",
    "            conv2 = tf.layers.conv2d(conv1, 128, [4,4], [2,2])\n",
    "            conv2 = leaky_relu(conv2)\n",
    "            conv3 = tf.layers.conv2d(conv2, 256, [4,4], [2,2])\n",
    "            conv3 = leaky_relu(conv3)\n",
    "            conv4 = tf.layers.conv2d(conv3, 512, [4,4], [2,2])\n",
    "            conv4 = leaky_relu(conv4)\n",
    "            conv4 = tf.contrib.layers.flatten(conv4)\n",
    "            fc1 = tf.layers.dense(conv4, 512)\n",
    "            fc1 = leaky_relu(fc1)\n",
    "            fc2 = tf.layers.dense(fc1, 256)\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "        return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f(x) = ||h(x) - h(x_)|| - ||h(x)||\n",
    "class Critic(object):\n",
    "    def __init__(self, h):\n",
    "        self.h = h\n",
    "    def __call__(self, x, x_):\n",
    "        return tf.norm(self.h(x) - self.h(x_), axis=1) - tf.norm(self.h(x), axis=1)\n",
    "\n",
    "# f(x) = ||h(x) - h(x_)||\n",
    "class calc_Norm(object):\n",
    "    def __init__(self, h):\n",
    "        self.h = h\n",
    "    def __call__(self, x, x_):\n",
    "        return tf.norm(self.h(x) -self.h(x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(x1, x2, weights=1.0):\n",
    "    loss = tf.reduce_mean((x1 - x2) ** 2) * weights\n",
    "    return loss\n",
    "\n",
    "def l1_loss(x1, x2, weights=1.0):\n",
    "    loss = tf.reduce_mean(tf.abs(x1 - x2)) * weights\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cycleGAN:\n",
    "    def __init__(self):\n",
    "        # definition of G and D for each X2Y, Y2X\n",
    "        self.g_X2Y = Generator(name=\"X2Y\")\n",
    "        self.g_Y2X = Generator(name=\"Y2X\")\n",
    "        self.d_X2Y = Discriminator(name=\"X2Y\")\n",
    "        self.d_Y2X = Discriminator(name=\"Y2X\")\n",
    "        \n",
    "        self.z_dim = 100\n",
    "        self.critic = Critic(self.d)\n",
    "        self.calcNorm = calc_Norm(self.d)\n",
    "\n",
    "        self.X_train = np.load(\"irasutoya_face_1813x96x96x3_jpg.npy\")\n",
    "        self.X_train = self.X_train/255\n",
    "        self.X_dim = 96*96*3\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 500000\n",
    "        self.display_epoch = 100\n",
    "        self.param_save_epoch = 10000\n",
    "        self.loss = {\"d_loss_X\":[], \"d_loss_Y\":[], \"g_loss\":[]}\n",
    "        \n",
    "        self.crop_size = 256\n",
    "\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, sefl.crop_size, self.crop_size, 3])\n",
    "        self.Y_tr = tf.placeholder(tf.float32, shape=[None, self.crop_size, self.crop_size, 3])\n",
    "\n",
    "        self.lr = 0.0002\n",
    "\n",
    "        \n",
    "    def loss_(self):\n",
    "        # the results of generation\n",
    "        X2Y = self.g_X2Y(X_tr) #X→Y\n",
    "        Y2X = self.g_Y2X(Y_tr) #Y→X\n",
    "        X2Y2X = self.g_Y2X(X2Y) #X→Y→X\n",
    "        Y2X2Y = self.g_X2Y(Y2X) #Y→X→Y\n",
    "\n",
    "        # the results of discrimination\n",
    "        X_dis = self.d_Y2X(self.X_tr)\n",
    "        Y2X_dis = self.d_Y2X(Y2X)\n",
    "        Y_dis = self.d_X2Y(self.Y_tr)\n",
    "        X2Y_dis = self.d_X2Y(X2Y)\n",
    "\n",
    "        # g_losses\n",
    "        g_loss_X2Y = tf.identity(l2_loss(X2Y_dis, tf.ones_like(X2Y_dis)))\n",
    "        g_loss_Y2X = tf.identity(l2_loss(Y2X_dis, tf.ones_like(Y2X_dis)))\n",
    "        cyc_loss_X = tf.identity(l1_loss(self.X_tr, X2Y2X) * 10.0)\n",
    "        cyc_loss_Y = tf.identity(l1_loss(self.Y_tr, Y2X2Y) * 10.0)\n",
    "        g_loss = g_loss_X2Y + g_loss_Y2X + cyc_loss_X + cyc_loss_Y\n",
    "\n",
    "        #  d_losses\n",
    "        d_loss_Xtr = l2_loss(X_dis, tf.ones_like(X_dis))\n",
    "        d_loss_Y2X = l2_loss(Y2X_dis, tf.ones_like(Y2X_dis))\n",
    "        d_loss_X = d_loss_Xtr + d_loss_Y2X\n",
    "        \n",
    "        d_loss_Ytr = l2_loss(Y_dis, tf.ones_like(Y_dis))\n",
    "        d_loss_X2Y = l2_loss(X2Y_dis, tf.ones_like(X2Y_dis))\n",
    "        d_loss_Y = d_loss_Ytr + d_loss_X2Y\n",
    " \n",
    "        return g_loss, d_loss_X, d_loss_Y\n",
    "\n",
    "    def train():\n",
    "        g_loss, d_loss_X, d_loss_Y = self.loss()\n",
    "\n",
    "        # Optimizer\n",
    "        g_var = [var for var in (self.g_X2Y or self.g_Y2X)]\n",
    "        d_X_train_op = tf.train.AdamOptimizer(self.lr, beta1=0.5).minimize(d_loss_X, var_list=self.d_Y2X)\n",
    "        d_Y_train_op = tf.train.AdamOptimizer(self.lr, beta1=0.5).minimize(d_loss_Y, var_list=self.d_X2Y)\n",
    "        g_train_op = tf.train.AdamOptimizer(self.lr, beta1=0.5).minimize(g_loss, var_list=g_var)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        #%debug\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(epochs):\n",
    "\n",
    "                # X_mb, Y_mbを収集\n",
    "                \n",
    "                \n",
    "                # train G\n",
    "                _,  = sess.run([g_train_op, g_loss], feed_dict={self.X_tr: X_mb, self.Y_tr: Y_mb})\n",
    "                    \n",
    "                # train D_X\n",
    "                _ = sess.run([d_X_train_op, d_loss_X], feed_dict={self.X_tr: X_mb, self.Y_tr: Y_mb})\n",
    "                \n",
    "                # train D_Y\n",
    "                _ = sess.run([d_Y_train_op, d_loss_Y], feed_dict={self.X_tr: X_mb, self.Y_tr:Y_mb})\n",
    "              \n",
    "                # 結果をappend\n",
    "                loss[\"d_loss_X\"].append(d_loss)\n",
    "                loss[\"d_loss_Y\"].append(d_loss_value)\n",
    "                loss[\"n_loss\"].append(g_loss_value)\n",
    "                print(\"epoch:\" + str(epoch))\n",
    "                # グラフの描画（余裕があったら）\n",
    "                if epoch % display_epoch == 0:\n",
    "                    save_metrics(loss, epoch)\n",
    "\n",
    "                if epoch % param_save_epoch == 0:\n",
    "                    path = \"model\"\n",
    "                    if not os.path.isdir(path):\n",
    "                        os.makedirs(path)\n",
    "\n",
    "                    saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def sample_images(self, row=5, col=12, inputs=None, epoch=None):\n",
    "        images = self.g(inputs, training=True)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
