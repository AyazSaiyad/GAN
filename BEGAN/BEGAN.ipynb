{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGAN implementation by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# utility関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_metrics(metrics, epoch=None):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"dis_loss\"], label=\"discriminative loss\", color=\"b\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"dloss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"gen_loss\"], label=\"generative loss\", color=\"r\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"g_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"dis_train_loss\"], label=\"discriminative loss(train_data)\", color=\"g\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"dis_train_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"dis_gen_loss\"], label=\"discriminative loss(generated data)\", color=\"c\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"dis_gen_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"m_global_loss\"], label=\"global loss\", color=\"k\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(\"metrics\", \"global_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# noise[[examples, 100]]から生成した画像をplot_dim(例えば4x4)で表示\n",
    "def save_imgs(images, plot_dim=(5,12), size=(12,5), epoch=None):\n",
    "    examples = plot_dim[0]*plot_dim[1]\n",
    "\n",
    "    # 表示\n",
    "    fig = plt.figure(figsize=size)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(plot_dim[0], plot_dim[1], i+1)\n",
    "        img = images[i, :]\n",
    "        img = img.reshape((96, 96, 3))\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(os.path.join(\"generated_figures\", str(epoch) + \".png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv2d(x, filter_shape, stride, padding, name):\n",
    "    initializer = tf.random_normal_initializer(0., 0.001)\n",
    "    with tf.variable_scope(name):\n",
    "        weight = tf.get_variable(\"weight\", shape=filter_shape, initializer=initializer)\n",
    "        bias = tf.get_variable(\"bias\", shape=filter_shape[-1], initializer=tf.constant_initializer(0.))\n",
    "\n",
    "        x = tf.nn.conv2d(x, weight, [1, stride, stride, 1], padding=padding)\n",
    "        x = tf.nn.bias_add(x,bias)\n",
    "    return x\n",
    "\n",
    "def fc(x, output_shape, name):\n",
    "    shape = x.get_shape().as_list()\n",
    "    dim = np.prod(shape[1:])\n",
    "    x = tf.reshape(x, [-1, dim])\n",
    "    input_shape = dim\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.001)\n",
    "    with tf.variable_scope(name):\n",
    "        weight = tf.get_variable(\"weight\", shape=[input_shape, output_shape], initializer=initializer)\n",
    "        x = tf.matmul(x, weight)\n",
    "\n",
    "        bias = tf.get_variable(\"bias\", shape=[output_shape], initializer=tf.constant_initializer(0.))\n",
    "        x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "    return x\n",
    "\n",
    "def l1_loss(x, y):\n",
    "    return tf.reduce_mean(tf.abs(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.n = 64\n",
    "        self.size = 96\n",
    "\n",
    "    def __call__(self, x, reuse=False):\n",
    "        with tf.variable_scope(\"gen_\", reuse=reuse):\n",
    "            x = fc(x, 6*6*self.n, name=\"fc\")\n",
    "            x = tf.reshape(x, [-1, 6, 6, self.n])\n",
    "            \n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv1_a\")\n",
    "            x = tf.nn.elu(x)\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv1_b\")\n",
    "            x = tf.nn.elu(x)\n",
    "            \n",
    "            x = tf.image.resize_nearest_neighbor(x, size=(self.size//8, self.size//8))\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv2_a\")\n",
    "            x = tf.nn.elu(x)\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv2_b\")\n",
    "            x = tf.nn.elu(x)\n",
    "\n",
    "            x = tf.image.resize_nearest_neighbor(x, size=(self.size//4, self.size//4))\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv3_a\")\n",
    "            x = tf.nn.elu(x)\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv3_b\")\n",
    "            x = tf.nn.elu(x)\n",
    "\n",
    "            x = tf.image.resize_nearest_neighbor(x, size=(self.size//2, self.size//2))\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv4_a\")\n",
    "            x = tf.nn.elu(x)\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv4_b\")\n",
    "            x = tf.nn.elu(x)\n",
    "            \n",
    "            x = tf.image.resize_nearest_neighbor(x, size=(self.size, self.size))\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv5_a\")\n",
    "            x = tf.nn.elu(x)\n",
    "            x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv5_b\")\n",
    "            x = tf.nn.elu(x)\n",
    "\n",
    "            x = conv2d(x, [3,3,self.n,3], stride=1, padding=\"SAME\", name=\"conv6_a\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AutoEncoder:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.n = 64\n",
    "        self.size = 96\n",
    "\n",
    "    def __call__(self, x, reuse=False):\n",
    "        with tf.variable_scope(\"ae_\", reuse=reuse):\n",
    "            with tf.variable_scope(\"encoder\"):\n",
    "                x = conv2d(x, [3,3,3,self.n], stride=1, padding=\"SAME\", name=\"conv1_enc_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv2_enc_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv2_enc_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = conv2d(x, [1,1,self.n,self.n*2], stride=1, padding=\"SAME\", name=\"conv3_enc_0\")\n",
    "                x = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "                x = conv2d(x, [3,3,self.n*2,self.n*2], stride=1, padding=\"SAME\", name=\"conv3_enc_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n*2,self.n*2], stride=1, padding=\"SAME\", name=\"conv3_enc_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = conv2d(x, [1,1,self.n*2,self.n*3], stride=1, padding=\"SAME\", name=\"conv4_enc_0\")\n",
    "                x = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "                x = conv2d(x, [3,3,self.n*3,self.n*3], stride=1, padding=\"SAME\", name=\"conv4_enc_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n*3,self.n*3], stride=1, padding=\"SAME\", name=\"conv4_enc_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = conv2d(x, [1,1,self.n*3,self.n*4], stride=1, padding=\"SAME\", name=\"conv5_enc_0\")\n",
    "                x = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "                x = conv2d(x, [3,3,self.n*4,self.n*4], stride=1, padding=\"SAME\", name=\"conv5_enc_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n*4,self.n*4], stride=1, padding=\"SAME\", name=\"conv5_enc_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = conv2d(x, [1,1,self.n*4,self.n*5], stride=1, padding=\"SAME\", name=\"conv6_enc_0\")\n",
    "                x = tf.nn.avg_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "                x = conv2d(x, [3,3,self.n*5,self.n*5], stride=1, padding=\"SAME\", name=\"conv6_enc_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n*5,self.n*5], stride=1, padding=\"SAME\", name=\"conv6_enc_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = fc(x, 64, name=\"enc_fc\") ## TODO:修正 ## \n",
    "\n",
    "            with tf.variable_scope(\"decoder\"):\n",
    "                x = fc(x, 6*6*self.n, name=\"fc\")\n",
    "                x = tf.reshape(x, [-1, 6, 6, self.n])\n",
    "\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv1_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv1_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = tf.image.resize_nearest_neighbor(x, size=(self.size//8, self.size//8))\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv2_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv2_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = tf.image.resize_nearest_neighbor(x, size=(self.size//4, self.size//4))\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv3_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv3_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = tf.image.resize_nearest_neighbor(x, size=(self.size//2, self.size//2))\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv4_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv4_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = tf.image.resize_nearest_neighbor(x, size=(self.size, self.size))\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv5_a\")\n",
    "                x = tf.nn.elu(x)\n",
    "                x = conv2d(x, [3,3,self.n,self.n], stride=1, padding=\"SAME\", name=\"conv5_b\")\n",
    "                x = tf.nn.elu(x)\n",
    "\n",
    "                x = conv2d(x, [3,3,self.n,3], stride=1, padding=\"SAME\", name=\"conv6_a\")\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.load(\"irasutoya_face_1813x96x96x3_jpg.npy\")\n",
    "X_train = X_train/255\n",
    "\n",
    "z_dim = 64\n",
    "batch_size = 16\n",
    "epochs = 400000\n",
    "display_epoch = 1000\n",
    "param_save_epoch = 10000\n",
    "loss = {\"dis_loss\":[],\n",
    "        \"gen_loss\":[],\n",
    "        \"dis_train_loss\":[],\n",
    "        \"dis_gen_loss\":[],\n",
    "        \"m_global_loss\":[]}\n",
    "\n",
    "gamma = 0.5 ## TODO ##\n",
    "lambda_ = 0.001\n",
    "lr_ = 1e-4 ## TODO ##\n",
    "kt_ = 0.\n",
    "mm = 0.5\n",
    "\n",
    "nsnapshot = 2440\n",
    "niter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = tf.placeholder(tf.float32, shape=[None, z_dim], name=\"z\")\n",
    "x = tf.placeholder(tf.float32, shape=[None, 96, 96, 3], name=\"x\")\n",
    "kt = tf.placeholder(tf.float32, name=\"kt\")\n",
    "lr = tf.placeholder(tf.float32, name=\"lr\")\n",
    "\n",
    "Gen = Generator()\n",
    "AE = AutoEncoder()\n",
    "\n",
    "AE_traindata = AE(x)\n",
    "generateddata = Gen(z)\n",
    "AE_generateddata = AE(generateddata, reuse=True)\n",
    "\n",
    "d_traindata_loss = l1_loss(x, AE_traindata)\n",
    "d_generateddata_loss = l1_loss(generateddata, AE_generateddata)\n",
    "d_loss = d_traindata_loss - kt * d_generateddata_loss\n",
    "g_loss = d_generateddata_loss\n",
    "\n",
    "t_vars = tf.global_variables()\n",
    "g_vars = [var for var in t_vars if \"gen_\" in var.name]\n",
    "d_vars = [var for var in t_vars if \"ae_\" in var.name]\n",
    "\n",
    "opt_g = tf.train.AdamOptimizer(lr, mm).minimize(g_loss, var_list=g_vars)\n",
    "opt_d = tf.train.AdamOptimizer(lr, mm).minimize(d_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving images\n",
      "epoch:0\n",
      "saving images\n",
      "epoch:1000\n",
      "saving images\n",
      "epoch:2000\n",
      "saving images\n",
      "epoch:3000\n",
      "saving images\n",
      "epoch:4000\n",
      "saving images\n",
      "epoch:5000\n",
      "saving images\n",
      "epoch:6000\n",
      "saving images\n",
      "epoch:7000\n"
     ]
    }
   ],
   "source": [
    "noise_check = np.random.uniform(-1, 1, size=[60, z_dim]).astype(np.float32)\n",
    "sample_imgs = Gen(z, reuse=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "p_noise = tf.placeholder(tf.float32, [None, z_dim])\n",
    "\n",
    "\n",
    "dcgan = DCGAN()\n",
    "p_train_images = tf.placeholder(tf.float32, [batch_size, 96, 96, 3])\n",
    "losses = dcgan.loss(traindata=p_train_images)\n",
    "\n",
    "d_train_op = dcgan.d_train(losses)\n",
    "g_train_op = dcgan.g_train(losses)\n",
    "\n",
    "clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in dcgan.d.variables]\n",
    "\"\"\"\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # ノイズから生成データを生成\n",
    "        noise = np.random.uniform(-1, 1, size=[batch_size, z_dim])\n",
    "        # 訓練データを抜粋\n",
    "        rand_index = np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "        exImgs = X_train[rand_index, :].astype(np.float32)\n",
    "\n",
    "        _, loss_g, d_train_loss, d_gen_loss = sess.run([opt_g, g_loss, d_traindata_loss, d_generateddata_loss,], feed_dict={z: noise, x: exImgs, kt:kt_, lr:lr_})\n",
    "        _, loss_d = sess.run([opt_d, d_loss], feed_dict={z: noise, x:exImgs, kt:kt_, lr:lr_})\n",
    "\n",
    "        kt_ = np.maximum(np.minimum(1., kt_ + lambda_ * (gamma * d_train_loss - d_gen_loss)), 0)\n",
    "        m_global = d_train_loss + np.abs(gamma*d_train_loss - d_gen_loss)\n",
    "\n",
    "        if epoch % display_epoch == 0:\n",
    "            imgs_gen = sess.run(sample_imgs, feed_dict={z:noise_check})\n",
    "            print(\"saving images\")\n",
    "            save_imgs(imgs_gen, epoch=epoch)\n",
    "\n",
    "        # 結果をappend\n",
    "        loss[\"dis_loss\"].append(loss_d)\n",
    "        loss[\"gen_loss\"].append(loss_g)\n",
    "        loss[\"dis_train_loss\"].append(d_train_loss)\n",
    "        loss[\"dis_gen_loss\"].append(d_gen_loss)\n",
    "        loss[\"m_global_loss\"].append(m_global)\n",
    "\n",
    "        if epoch % nsnapshot == nsnapshot-1:\n",
    "            lr_ = lr_*0.95\n",
    "\n",
    "        # グラフの描画（余裕があったら）\n",
    "        if epoch % display_epoch == 0:\n",
    "            save_metrics(loss, epoch)\n",
    "            print(\"epoch:\" + str(epoch))\n",
    "        if epoch % param_save_epoch == 0:\n",
    "            saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
