{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metrics\n",
    "def save_metrics(metrics, epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"metrics\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # save metrics\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"loss\"], label=\"discriminative loss X\", color=\"r\")\n",
    "    plt.plot(metrics[\"d_loss_Y\"], label=\"discriminative loss Y\", color=\"c\")\n",
    "    #plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"acc\"], label=\"generative loss X2Y\", color=\"g\")\n",
    "    #plt.plot(metrics[\"g_loss_Y2X\"], label=\"generative loss Y2X\", color=\"b\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"acc\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save metrics\n",
    "def metrics_compare(metrics, epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"metrics\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # save metrics\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.rcParams[\"font.size\"] = 25\n",
    "    plt.yscale(\"log\")\n",
    "    plt.plot(metrics[0][\"loss\"], label=\"cnn\", color=\"r\")\n",
    "    plt.plot(metrics[1][\"loss\"], label=\"cnn_BN\", color=\"c\")\n",
    "    plt.plot(metrics[2][\"loss\"], label=\"SNN\", color=\"b\")\n",
    "    #plt.plot(metrics[2][\"loss\"], label=\"discriminative loss Y\", color=\"c\")\n",
    "    #plt.ylim(0,1)\n",
    "    plt.xlabel(\"epoch\", fontsize=25)\n",
    "    plt.ylabel(\"loss\", fontsize=25)\n",
    "    plt.legend(fontsize=25)\n",
    "    plt.savefig(os.path.join(path, \"loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.rcParams[\"font.size\"] = 25\n",
    "    plt.plot(metrics[0][\"acc\"], label=\"cnn\", color=\"r\")\n",
    "    plt.plot(metrics[1][\"acc\"], label=\"cnn_BN\", color=\"c\")\n",
    "    plt.plot(metrics[2][\"acc\"], label=\"SNN\", color=\"b\")\n",
    "    #plt.plot(metrics[\"g_loss_Y2X\"], label=\"generative loss Y2X\", color=\"b\")\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel(\"epoch\", fontsize=25)\n",
    "    plt.ylabel(\"acc\", fontsize=25)\n",
    "    plt.legend(fontsize=25)\n",
    "    plt.savefig(os.path.join(path, \"acc\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot images\n",
    "def save_imgs(images, plot_dim=(1,2), size=(8,4), epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"generated_figures\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    numImgs = images.shape[0]\n",
    "    eachNumImgs = images.shape[0]/3\n",
    "\n",
    "    #num_examples = plot_dim[0]*plot_dim[1]\n",
    "    num_examples = numImgs\n",
    "    size = (3*4, eachNumImgs*4)\n",
    "    plot_dim = (eachNumImgs,3)\n",
    "\n",
    "    fig = plt.figure(figsize=size)\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(plot_dim[0], plot_dim[1], i+1)\n",
    "        img = images[i, :]\n",
    "        img = img.reshape((256, 256, 3))\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(os.path.join(path, str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_only_Dropout:\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.reuse = False\n",
    "        self.name = name\n",
    "        print(\"init... name of d:\" + self.name)\n",
    "        \n",
    "        # difinition of loss\n",
    "        self.batch_size = 128\n",
    "\n",
    "        self.epochs = 200\n",
    "        self.epoch_saveMetrics = 100\n",
    "        self.epoch_saveSampleImg = 100\n",
    "        self.epoch_saveParamter = 100\n",
    "        self.metrics = {\"loss\":[], \"acc\":[]}\n",
    "\n",
    "        img_size = 784\n",
    "        num_class = 10\n",
    "        # training data\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, img_size])\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, num_class])\n",
    "        \n",
    "        # generate img from generated data\n",
    "        out = self.model(self.X_tr) #X→Y→X\n",
    "\n",
    "        lr = 0.025\n",
    "\n",
    "        # the results of discrimination\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=self.y))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "        \n",
    "        # evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(self.y,1 ))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.scaler = StandardScaler().fit(mnist.train.images)\n",
    "        \n",
    "    def model(self, x, df_dim=64):\n",
    "        with tf.variable_scope('dropout' + self.name, reuse=self.reuse):\n",
    "            # x: 28x28x1\n",
    "            print(\"called... name of d:\" + self.name)\n",
    "            x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "            conv1 = tf.layers.conv2d(x, 32, [5,5], [1,1], name=\"c1\") # 28x28x32\n",
    "            conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # 14x14\n",
    "            \n",
    "            conv2 = tf.layers.conv2d(x, 64, [4,4], [2,2], name=\"c2\") # 14x14x64\n",
    "            conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding=\"SAME\") # 7x7x64\n",
    "\n",
    "            shape = conv2.get_shape().as_list()\n",
    "            dim = np.prod(shape[1:])\n",
    "            \n",
    "            conv2 = tf.reshape(conv2, [-1, dim])\n",
    "            \n",
    "            fc1 = tf.layers.dense(conv2, 1024, name='outputs')\n",
    "            fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "            \n",
    "            fc2 = tf.layers.dense(fc1, 10)\n",
    "        return fc2\n",
    "    \n",
    "    def train(self):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                batch_x, batch_y = mnist.train.next_batch(self.batch_size)\n",
    "                batch_x_norm = self.scaler.transform(batch_x)\n",
    "                _, loss, acc = sess.run([self.optimizer, self.loss, self.accuracy], feed_dict={self.X_tr: batch_x, self.y: batch_y})\n",
    "                \n",
    "                # 結果をappend\n",
    "                self.metrics[\"loss\"].append(loss)\n",
    "                self.metrics[\"acc\"].append(acc)\n",
    "                \n",
    "                print(\"epoch:\" + str(epoch))\n",
    "\n",
    "                # lossの可視化\n",
    "                #if (epoch+1) % self.epoch_saveMetrics == 0:\n",
    "                    #save_metrics(self.metrics, epoch)\n",
    "\n",
    "                # parameterのsave\n",
    "                if (epoch+1) % self.epoch_saveParamter == 0:\n",
    "                    path = \"model\"\n",
    "                    if not os.path.isdir(path):\n",
    "                        os.makedirs(path)\n",
    "\n",
    "                    saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Relu:\n",
    "    def __init__(self, batch_size, epochs, name=\"\"):\n",
    "        self.reuse = False\n",
    "        self.name = name\n",
    "        print(\"init... name of d:\" + self.name)\n",
    "        \n",
    "        # difinition of loss\n",
    "        self.batch_size = 128\n",
    "\n",
    "        self.epochs = 200\n",
    "        self.epoch_saveMetrics = 100\n",
    "        self.epoch_saveSampleImg = 100\n",
    "        self.epoch_saveParamter = 100\n",
    "        self.metrics = {\"loss\":[], \"acc\":[]}\n",
    "\n",
    "        img_size = 784\n",
    "        num_class = 10\n",
    "        # training data\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, img_size])\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, num_class])\n",
    "        \n",
    "        # generate img from generated data\n",
    "        out = self.model(self.X_tr) #X→Y→X\n",
    "\n",
    "        lr = 0.025\n",
    "\n",
    "        # the results of discrimination\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=self.y))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "        \n",
    "        # evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(self.y,1 ))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.scaler = StandardScaler().fit(mnist.train.images)\n",
    "        \n",
    "    def model(self, x, df_dim=64):\n",
    "        with tf.variable_scope('Relu' + self.name, reuse=self.reuse):\n",
    "            # x: 28x28x1\n",
    "            print(\"called... name of d:\" + self.name)\n",
    "            x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "            conv1 = tf.layers.conv2d(x, 32, [5,5], [1,1], name=\"c1\") # 28x28x32\n",
    "            conv1 = tf.nn.relu(conv1)\n",
    "            conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # 14x14\n",
    "            \n",
    "            conv2 = tf.layers.conv2d(x, 64, [4,4], [2,2], name=\"c2\") # 14x14x64\n",
    "            conv2 = tf.nn.relu(conv2)\n",
    "            conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding=\"SAME\") # 7x7x64\n",
    "\n",
    "            shape = conv2.get_shape().as_list()\n",
    "            dim = np.prod(shape[1:])\n",
    "            \n",
    "            conv2 = tf.reshape(conv2, [-1, dim])\n",
    "            \n",
    "            fc1 = tf.layers.dense(conv2, 1024, name='outputs')\n",
    "            #fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "            \n",
    "            fc2 = tf.layers.dense(fc1, 10)\n",
    "        return fc2\n",
    "    \n",
    "    def train(self):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                batch_x, batch_y = mnist.train.next_batch(self.batch_size)\n",
    "                batch_x_norm = self.scaler.transform(batch_x)\n",
    "                _, loss, acc = sess.run([self.optimizer, self.loss, self.accuracy], feed_dict={self.X_tr: batch_x, self.y: batch_y})\n",
    "                \n",
    "                # 結果をappend\n",
    "                self.metrics[\"loss\"].append(loss)\n",
    "                self.metrics[\"acc\"].append(acc)\n",
    "                \n",
    "                #print(\"epoch:\" + str(epoch))\n",
    "\n",
    "                # lossの可視化\n",
    "                #if (epoch+1) % self.epoch_saveMetrics == 0:\n",
    "                    #save_metrics(self.metrics, epoch)\n",
    "\n",
    "                # parameterのsave\n",
    "                if (epoch+1) % self.epoch_saveParamter == 0:\n",
    "                    path = \"model\"\n",
    "                    if not os.path.isdir(path):\n",
    "                        os.makedirs(path)\n",
    "\n",
    "                    saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_BN:\n",
    "    def __init__(self, batch_size, epochs, name=\"\"):\n",
    "        self.reuse = False\n",
    "        self.name = name\n",
    "        print(\"init... name of d:\" + self.name)\n",
    "        \n",
    "        # difinition of loss\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.epoch_saveMetrics = 100\n",
    "        self.epoch_saveSampleImg = 100\n",
    "        self.epoch_saveParamter = 100\n",
    "        self.metrics = {\"loss\":[], \"acc\":[]}\n",
    "\n",
    "        img_size = 784\n",
    "        num_class = 10\n",
    "        # training data\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, img_size])\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, num_class])\n",
    "        \n",
    "        # generate img from generated data\n",
    "        out = self.model(self.X_tr) #X→Y→X\n",
    "\n",
    "        lr = 0.025\n",
    "\n",
    "        # the results of discrimination\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=self.y))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "        \n",
    "        # evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(self.y,1 ))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.scaler = StandardScaler().fit(mnist.train.images)\n",
    "        \n",
    "    def model(self, x, df_dim=64):\n",
    "        with tf.variable_scope('BN' + self.name, reuse=self.reuse):\n",
    "            # x: 28x28x1\n",
    "            print(\"called... name of d:\" + self.name)\n",
    "            x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "            conv1 = tf.layers.conv2d(x, 32, [5,5], [1,1], name=\"c1\") # 28x28x32\n",
    "            conv1 = tf.layers.batch_normalization(conv1)\n",
    "            conv1 = tf.nn.relu(conv1)\n",
    "            conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # 14x14\n",
    "            \n",
    "            conv2 = tf.layers.conv2d(x, 64, [4,4], [2,2], name=\"c2\") # 14x14x64\n",
    "            conv2 = tf.layers.batch_normalization(conv2)\n",
    "            conv2 = tf.nn.relu(conv2)\n",
    "            conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding=\"SAME\") # 7x7x64\n",
    "\n",
    "            shape = conv2.get_shape().as_list()\n",
    "            dim = np.prod(shape[1:])\n",
    "            \n",
    "            conv2 = tf.reshape(conv2, [-1, dim])\n",
    "            \n",
    "            fc1 = tf.layers.dense(conv2, 1024, name='outputs')\n",
    "            #fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "            \n",
    "            fc2 = tf.layers.dense(fc1, 10)\n",
    "        return fc2\n",
    "    \n",
    "    def train(self):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                batch_x, batch_y = mnist.train.next_batch(self.batch_size)\n",
    "                batch_x_norm = self.scaler.transform(batch_x)\n",
    "                _, loss, acc = sess.run([self.optimizer, self.loss, self.accuracy], feed_dict={self.X_tr: batch_x, self.y: batch_y})\n",
    "                \n",
    "                # 結果をappend\n",
    "                self.metrics[\"loss\"].append(loss)\n",
    "                self.metrics[\"acc\"].append(acc)\n",
    "                \n",
    "                #print(\"epoch:\" + str(epoch))\n",
    "\n",
    "                # lossの可視化\n",
    "                #if (epoch+1) % self.epoch_saveMetrics == 0:\n",
    "                    #save_metrics(self.metrics, epoch)\n",
    "\n",
    "                # parameterのsave\n",
    "                if (epoch+1) % self.epoch_saveParamter == 0:\n",
    "                    path = \"model\"\n",
    "                    if not os.path.isdir(path):\n",
    "                        os.makedirs(path)\n",
    "\n",
    "                    saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SNN:\n",
    "    def __init__(self, batch_size, epochs, name=\"\"):\n",
    "        self.reuse = False\n",
    "        self.name = name\n",
    "        print(\"init... name of d:\" + self.name)\n",
    "        \n",
    "        # difinition of loss\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.epoch_saveMetrics = 100\n",
    "        self.epoch_saveSampleImg = 100\n",
    "        self.epoch_saveParamter = 100\n",
    "        self.metrics = {\"loss\":[], \"acc\":[]}\n",
    "\n",
    "        img_size = 784\n",
    "        num_class = 10\n",
    "        # training data\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, img_size])\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, num_class])\n",
    "        \n",
    "        # generate img from generated data\n",
    "        out = self.model(self.X_tr) #X→Y→X\n",
    "\n",
    "        lr = 0.025\n",
    "\n",
    "        # the results of discrimination\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=self.y))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "        \n",
    "        # evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(self.y,1 ))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        \n",
    "        self.scaler = StandardScaler().fit(mnist.train.images)\n",
    "    \n",
    "    def selu(self, x):\n",
    "        #with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))\n",
    "\n",
    "    def model(self, x, df_dim=64):\n",
    "        with tf.variable_scope('SNN' + self.name, reuse=self.reuse):\n",
    "            # x: 28x28x1\n",
    "            print(\"called... name of d:\" + self.name)\n",
    "            x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "            conv1 = tf.layers.conv2d(x, 32, [5,5], [1,1], name=\"c1\") # 28x28x32\n",
    "            conv1 = self.selu(conv1)\n",
    "            #conv1 = tf.layers.batch_normalization(conv1)\n",
    "            #conv1 = tf.nn.relu(conv1)\n",
    "            conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # 14x14\n",
    "            \n",
    "            conv2 = tf.layers.conv2d(x, 64, [4,4], [2,2], name=\"c2\") # 14x14x64\n",
    "            conv2 = self.selu(conv2)\n",
    "            #conv2 = tf.layers.batch_normalization(conv2)\n",
    "            #conv2 = tf.nn.relu(conv2)\n",
    "            conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding=\"SAME\") # 7x7x64\n",
    "\n",
    "            shape = conv2.get_shape().as_list()\n",
    "            dim = np.prod(shape[1:])\n",
    "            \n",
    "            conv2 = tf.reshape(conv2, [-1, dim])\n",
    "            \n",
    "            fc1 = tf.layers.dense(conv2, 1024, name='outputs')\n",
    "            #fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "        \n",
    "            fc2 = tf.layers.dense(fc1, 10)\n",
    "        return fc2\n",
    "    \n",
    "    def train(self):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                batch_x, batch_y = mnist.train.next_batch(self.batch_size)\n",
    "                batch_x_norm = self.scaler.transform(batch_x)\n",
    "                _, loss, acc = sess.run([self.optimizer, self.loss, self.accuracy], feed_dict={self.X_tr: batch_x, self.y: batch_y})\n",
    "                \n",
    "                # 結果をappend\n",
    "                self.metrics[\"loss\"].append(loss)\n",
    "                self.metrics[\"acc\"].append(acc)\n",
    "                \n",
    "                #print(\"epoch:\" + str(epoch))\n",
    "\n",
    "                # lossの可視化\n",
    "                #if (epoch+1) % self.epoch_saveMetrics == 0:\n",
    "                    #save_metrics(self.metrics, epoch)\n",
    "\n",
    "                # parameterのsave\n",
    "                if (epoch+1) % self.epoch_saveParamter == 0:\n",
    "                    path = \"model\"\n",
    "                    if not os.path.isdir(path):\n",
    "                        os.makedirs(path)\n",
    "\n",
    "                    saver.save(sess, \"./model/dcgan_model\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init... name of d:\n",
      "called... name of d:\n",
      "init... name of d:\n",
      "called... name of d:\n",
      "init... name of d:\n",
      "called... name of d:\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #cnn_only_dropout = CNN_only_Dropout()\n",
    "    #cnn_only_dropout.train()\n",
    "    \n",
    "    cnn_relu = CNN_Relu(256, 2000)\n",
    "    cnn_relu.train()\n",
    "    \n",
    "    cnn_BN = CNN_BN(256, 2000)\n",
    "    cnn_BN.train()\n",
    "    \n",
    "    snn = SNN(256, 2000)\n",
    "    snn.train()\n",
    "    \n",
    "    metrics_compare([cnn_relu.metrics, cnn_BN.metrics, snn.metrics])\n",
    "    #cnn_selu = CNN_Selu()\n",
    "    #cnn_selu.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
