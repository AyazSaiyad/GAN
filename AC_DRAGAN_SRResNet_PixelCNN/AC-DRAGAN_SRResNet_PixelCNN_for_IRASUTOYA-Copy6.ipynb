{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"AC-DRAGAN_SRResNet_PixelCNN_for_IRASUTOYA_gpu1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.g_bn0 = BatchNormalization(name = 'g_bn0')\n",
    "\n",
    "        self.num_res_blocks = 16\n",
    "        self.num_pixel_CNN_blocks = 3\n",
    "        \n",
    "        self.res_bns = []\n",
    "        for i in range(int(self.num_res_blocks)):\n",
    "            self.res_bns.append(BatchNormalization(name = \"res_%d\" % (2*i)))\n",
    "            self.res_bns.append(BatchNormalization(name = \"res_%d\" % (2*i+1)))\n",
    "        \n",
    "        self.ps_bns = []\n",
    "        for i in range(int(self.num_pixel_CNN_blocks)):\n",
    "            self.ps_bns.append(BatchNormalization(name = \"ps_%d\" % i))\n",
    "        \n",
    "        self.g_bn1 = BatchNormalization(name = 'g_bn1')\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            \n",
    "            # reshape from inputs\n",
    "            with tf.variable_scope('fc0'):\n",
    "                #z0 = tf.reshape(z, [-1, self.z_dim])\n",
    "                fc0 = full_connection_layer(z, 64*16*16, name=\"fc0\")\n",
    "                fc0 = self.g_bn0(fc0)\n",
    "                fc0 = tf.nn.relu(fc0)\n",
    "                fc0 = tf.reshape(fc0, [-1,16,16,64])\n",
    "\n",
    "            assert fc0.get_shape().as_list()[1:] == [16,16,64]\n",
    "            \n",
    "            layers = []\n",
    "            layers.append(fc0)\n",
    "            \n",
    "            for i in range(int(self.num_res_blocks)):\n",
    "                with tf.variable_scope('res_%d' % (i+1)):\n",
    "                    res = conv2d_layer(layers[-1], 64, kernel_size=3, strides=1, name=\"g_conv_res_%d\" % (2*i))\n",
    "                    res = self.res_bns[2*i](res)\n",
    "                    res = tf.nn.relu(res)\n",
    "\n",
    "                    res = conv2d_layer(res, 64, kernel_size=3, strides=1, name=\"g_conv_res_%d\" % (2*i+1))\n",
    "                    res = self.res_bns[2*i+1](res)\n",
    "                    res = layers[-1] + res\n",
    "                    layers.append(res)                    \n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [16,16,64]\n",
    "            \n",
    "            with tf.variable_scope('conv17'):\n",
    "                conv17 = conv2d_layer(layers[-1], 64, kernel_size=3, strides=1, name=\"g_conv_17\")\n",
    "                conv17 = self.g_bn1(conv17)\n",
    "                conv17 = tf.nn.relu(conv17)\n",
    "                conv17 = layers[0] + conv17\n",
    "                layers.append(conv17)\n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [16, 16, 64]\n",
    "\n",
    "            for i in range(int(self.num_pixel_CNN_blocks)):\n",
    "                with tf.variable_scope('pixel_CNN_%d' % (i+1)):\n",
    "                    ps = conv2d_layer(layers[-1], 256, kernel_size=3, strides=1, name=\"g_conv_ps_%d\" % (i))\n",
    "                    ps = pixel_shuffle_layer(ps, 2, 64)\n",
    "                    ps = self.ps_bns[i](ps)\n",
    "                    ps = tf.nn.relu(ps)\n",
    "                    layers.append(ps)\n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [128, 128, 64]\n",
    "                    \n",
    "            with tf.variable_scope('output'):\n",
    "                output = conv2d_layer(layers[-1], 3, kernel_size=9, strides=1, name=\"output\")\n",
    "                output = tf.nn.sigmoid(output)\n",
    "\n",
    "            assert output.get_shape().as_list()[1:] == [128, 128, 3]            \n",
    "            \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, cat_size):\n",
    "        self.reuse = False\n",
    "        self.d_bn0 = BatchNormalization(name=\"d_bn0\")\n",
    "        self.d_bn1 = BatchNormalization(name=\"d_bn1\")\n",
    "        self.d_bn2 = BatchNormalization(name=\"d_bn2\")\n",
    "        self.d_bn3 = BatchNormalization(name=\"d_bn3\")\n",
    "        self.d_bn4 = BatchNormalization(name=\"d_bn4\")\n",
    "        \n",
    "        self.cat_size = cat_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        def leaky_relu(x):\n",
    "            return lrelu(x, leak=0.2)\n",
    "\n",
    "        with tf.variable_scope('d', reuse=self.reuse):\n",
    "           \n",
    "            x = tf.reshape(x, [-1, 128, 128, 3])\n",
    "            with tf.variable_scope('conv1'):\n",
    "                conv1 = tf.layers.conv2d(x, 32, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv1 = leaky_relu(conv1)\n",
    "\n",
    "            with tf.variable_scope('res1'):\n",
    "                res1 = tf.layers.conv2d(conv1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res1 = leaky_relu(res1)\n",
    "                res1 = tf.layers.conv2d(res1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res1 = res1 + conv1\n",
    "                res1 = leaky_relu(res1)\n",
    "\n",
    "            with tf.variable_scope('res2'):\n",
    "                res2 = tf.layers.conv2d(res1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res2 = leaky_relu(res2)\n",
    "                res2 = tf.layers.conv2d(res2, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res2 = res2 + res1\n",
    "                res2 = leaky_relu(res2)\n",
    "\n",
    "            with tf.variable_scope('conv2'):\n",
    "                conv2 = tf.layers.conv2d(res2, 64, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv2 = leaky_relu(conv2)\n",
    "\n",
    "            with tf.variable_scope('res3'):\n",
    "                res3 = tf.layers.conv2d(conv2, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res3 = leaky_relu(res3)\n",
    "                res3 = tf.layers.conv2d(res3, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res3 = leaky_relu(res3)\n",
    "                res3 = res3 + conv2\n",
    "                res3 = leaky_relu(res3)\n",
    "\n",
    "            with tf.variable_scope('res4'):\n",
    "                res4 = tf.layers.conv2d(res3, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res4 = leaky_relu(res4)\n",
    "                res4 = tf.layers.conv2d(res4, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res4 = leaky_relu(res4)\n",
    "                res4 = res4 + res3\n",
    "                res4 = leaky_relu(res4)\n",
    "\n",
    "            with tf.variable_scope('conv3'):\n",
    "                conv3 = tf.layers.conv2d(res4, 128, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv3 = leaky_relu(conv3)\n",
    "\n",
    "            num_res_itr = 3\n",
    "            layers = []\n",
    "            layers.append(conv3)\n",
    "            \n",
    "            depth = [128, 256, 512, 1024]\n",
    "            for i in range(int(num_res_itr)):\n",
    "                with tf.variable_scope('res_%d_1' % (i+1+4)):\n",
    "                    res = tf.layers.conv2d(layers[-1], depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = tf.layers.conv2d(res, depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = layers[-1] + res\n",
    "                    res = leaky_relu(res)\n",
    "                layers.append(res)\n",
    "\n",
    "                with tf.variable_scope('res_%d_2' % (i+1+4)):\n",
    "                    res = tf.layers.conv2d(layers[-1], depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = tf.layers.conv2d(res, depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = layers[-1] + res\n",
    "                    res = leaky_relu(res)\n",
    "\n",
    "                conv = tf.layers.conv2d(res, depth[i+1], [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv = leaky_relu(conv) \n",
    "                layers.append(conv)\n",
    "\n",
    "            disc = full_connection_layer(layers[-1], 1, name=\"disc\")\n",
    "            aux = full_connection_layer(layers[-1], self.cat_size, name=\"aux\")\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "\n",
    "        return disc, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.img_size = 128\n",
    "        self.rand_size = 100\n",
    "        self.cat_size = 4\n",
    "        self.z_size = self.rand_size + self.cat_size\n",
    "        \n",
    "        self.epochs = 50000\n",
    "        self.epoch_saveMetrics = 50\n",
    "        self.epoch_saveSampleImg = 50\n",
    "        self.epoch_saveParamter = 5000\n",
    "        self.losses = {\"d_loss\":[], \"g_loss\":[]}\n",
    "\n",
    "        # unrolled counts\n",
    "        self.steps = 5\n",
    "\n",
    "        #self.dataset = np.load(\"irasutoya_face_1813x96x96x3_jpg.npy\")\n",
    "        #self.dataset = (self.dataset/255)# - 0.5\n",
    "\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, self.img_size*self.img_size*3])\n",
    "        self.Y_tr = tf.placeholder(tf.float32, shape=[None, self.cat_size])\n",
    "        self.z = tf.placeholder(tf.float32, [None, self.z_size])\n",
    "        self.X_per = tf.placeholder(tf.float32, shape=[None, self.img_size*self.img_size*3])\n",
    "\n",
    "        self.g = Generator()\n",
    "        self.d = Discriminator(self.cat_size)\n",
    "        self.Xg = self.g(self.z)\n",
    "        #self.dtd = DTD()\n",
    "        self.irasutoya = IRASUTOYA()\n",
    "\n",
    "    def loss(self):\n",
    "        disc_tr, aux_tr = self.d(self.X_tr)\n",
    "        disc_gen, aux_gen = self.d(self.Xg)\n",
    "        \n",
    "        lambda_adv = 1\n",
    "        lambda_gp = 10\n",
    "        lambda_c = 0.4\n",
    "       \n",
    "        loss_g = lambda_adv*tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_gen, labels=tf.ones_like(disc_gen)))\n",
    "        #loss_g = lambda_adv*tf.reduce_mean(1 - tf.log(disc_gen + TINY))\n",
    "\n",
    "        diff = self.X_per - self.X_tr\n",
    "        #print(g_outputs.shape[0])\n",
    "        alpha = tf.random_uniform(shape=[self.batch_size,1], minval=0., maxval=1.)\n",
    "        interpolates = self.X_tr + (alpha*diff)\n",
    "        disc_interplates, _ = self.d(interpolates)\n",
    "        gradients = tf.gradients(disc_interplates, [interpolates])[0]\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "        gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "\n",
    "        loss_d_tr = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_tr, labels=tf.ones_like(disc_tr)))\n",
    "        loss_d_gen = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_gen, labels=tf.zeros_like(disc_gen)))\n",
    "        loss_d = lambda_adv*(loss_d_tr + loss_d_gen)\n",
    "        loss_d += lambda_gp*gradient_penalty\n",
    "\n",
    "        loss_c_tr = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=aux_tr, labels=self.Y_tr))\n",
    "        loss_c_gen = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=aux_gen, labels=self.Y_tr))\n",
    "        loss_c = (loss_c_tr + loss_c_gen)\n",
    "\n",
    "        loss_g += loss_c*lambda_c\n",
    "        loss_d += loss_c*lambda_c\n",
    "        return loss_g, loss_d\n",
    "\n",
    "    def train(self):\n",
    "        # Optimizer\n",
    "        d_lr = 1e-4\n",
    "        d_beta1 = 0.5\n",
    "        g_lr = 1e-4\n",
    "        g_beta1 = 0.5\n",
    "\n",
    "        self.L_g, self.L_d = self.loss()\n",
    "\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate=d_lr)\n",
    "        d_train_op = d_opt.minimize(self.L_d, var_list=self.d.variables)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate=g_lr)\n",
    "        g_train_op = g_opt.minimize(self.L_g, var_list=self.g.variables)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        config = tf.ConfigProto(\n",
    "            gpu_options=tf.GPUOptions(\n",
    "                visible_device_list= \"0\"\n",
    "            )\n",
    "        )\n",
    "                \n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # preparing noise vec for test\n",
    "            bs = 100\n",
    "            test_z = np.random.uniform(0, 1, size=[bs, self.z_size])\n",
    "\n",
    "            # cat 0\n",
    "            bs = 10\n",
    "            test_cat0_rand = np.random.uniform(0, 1, size=[bs, self.rand_size])\n",
    "            test_cat0_cat = np.zeros([bs, self.cat_size]) + 0.5\n",
    "            test_cat0_cat[:, 0] = np.linspace(0, 1, num=bs)\n",
    "            test_cat0_z = np.concatenate((test_cat0_rand, test_cat0_cat), axis=1)  \n",
    "\n",
    "            # cat 1\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat1_cat = np.zeros([bs, self.cat_size]) + 0.5\n",
    "            test_cat1_cat[:, 1] = np.linspace(0, 1, num=bs)\n",
    "            test_cat1_z = np.concatenate((test_cat0_rand, test_cat1_cat), axis=1)  \n",
    "\n",
    "            # cat 2\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat2_cat = np.zeros([bs, self.cat_size]) + 0.5\n",
    "            test_cat2_cat[:, 2] = np.linspace(0, 1, num=bs)\n",
    "            test_cat2_z = np.concatenate((test_cat0_rand, test_cat2_cat), axis=1)\n",
    "\n",
    "            # cat 3\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat3_cat = np.zeros([bs, self.cat_size]) + 0.5\n",
    "            test_cat3_cat[:, 3] = np.linspace(0, 1, num=bs)\n",
    "            test_cat3_z = np.concatenate((test_cat0_rand, test_cat3_cat), axis=1)\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "\n",
    "                # visualize generated images during training\n",
    "                if epoch % self.epoch_saveSampleImg == 0:\n",
    "                    # rand\n",
    "                    img = sess.run(self.Xg, feed_dict={self.z: test_z})\n",
    "                    save_imgs(model_name, img, name=str(epoch)+\"_rand\")\n",
    "\n",
    "                    # cat\n",
    "                    test_cat = np.concatenate((test_cat0_z, test_cat1_z, test_cat2_z, test_cat3_z), axis=0)\n",
    "                    img = sess.run(self.Xg, feed_dict={self.z: test_cat})\n",
    "                    save_imgs(model_name, img, plot_dim=(4,10), size=(20, 8), name=str(epoch)+\"_cat\")\n",
    "\n",
    "                for step in range(self.steps):\n",
    "                    # extract images for training\n",
    "                    #rand_index = np.random.randint(0, self.dataset.shape[0], size=self.batch_size)\n",
    "                    #X_mb, Y_mb = self.dataset[rand_index, :].astype(np.float32)\n",
    "                    X_mb, Y_mb = self.irasutoya.extract(self.batch_size, self.img_size)\n",
    "                    X_mb = np.reshape(X_mb, [self.batch_size, -1])\n",
    "                    X_mb_per = X_mb + 0.5*np.std(X_mb)*np.random.random(X_mb.shape)\n",
    "\n",
    "                    rand = np.random.uniform(0, 1, size=[self.batch_size, self.rand_size])\n",
    "                    #print(rand.shape)\n",
    "                    #print(Y_mb.shape)\n",
    "                    z = np.hstack((rand, Y_mb))\n",
    "                    #print(z.shape)\n",
    "\n",
    "                    # train Discriminator\n",
    "                    _, d_loss_value = sess.run([d_train_op, self.L_d], feed_dict={\n",
    "                        self.X_tr: X_mb,\n",
    "                        self.z:z,\n",
    "                        self.Y_tr: Y_mb,\n",
    "                        self.X_per: X_mb_per,\n",
    "                    })\n",
    "\n",
    "                # train Generator\n",
    "                _, g_loss_value = sess.run([g_train_op, self.L_g], feed_dict={\n",
    "                    self.X_tr: X_mb,\n",
    "                    self.z:z,\n",
    "                    self.Y_tr: Y_mb,\n",
    "                    self.X_per: X_mb_per,\n",
    "                })\n",
    "\n",
    "                # append loss value for visualizing\n",
    "                self.losses[\"d_loss\"].append(np.sum(d_loss_value))\n",
    "                self.losses[\"g_loss\"].append(np.sum(g_loss_value))\n",
    "                \n",
    "                # print epoch\n",
    "                if epoch % 1 == 0:\n",
    "                    print('epoch:{0}, d_loss:{1}, g_loss: {2} '.format(epoch, d_loss_value, g_loss_value))\n",
    "                \n",
    "                # visualize loss\n",
    "                if epoch % self.epoch_saveMetrics == 0:\n",
    "                    save_metrics(model_name, self.losses, epoch)\n",
    "\n",
    "\n",
    "                # save model parameters \n",
    "                if epoch % self.epoch_saveParamter == 0:\n",
    "                    dir_path = \"model_\" + model_name\n",
    "                    if not os.path.isdir(dir_path):\n",
    "                        os.makedirs(dir_path)\n",
    "\n",
    "                    saver.save(sess, dir_path + \"/\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init IRASUTOYA\n",
      "1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujitoko/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:82: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, d_loss:12.246145248413086, g_loss: 2.042067766189575 \n",
      "epoch:1, d_loss:7.122689723968506, g_loss: 5.637639999389648 \n",
      "epoch:2, d_loss:14.626873016357422, g_loss: 11.994833946228027 \n",
      "epoch:3, d_loss:78.51971435546875, g_loss: 89.03184509277344 \n",
      "epoch:4, d_loss:54.98441696166992, g_loss: 32.02779769897461 \n",
      "epoch:5, d_loss:45.693603515625, g_loss: 18.935874938964844 \n",
      "epoch:6, d_loss:423.3928527832031, g_loss: 250.8941650390625 \n",
      "epoch:7, d_loss:227986.34375, g_loss: 2739.82568359375 \n",
      "epoch:8, d_loss:5074.3291015625, g_loss: 35.33503723144531 \n",
      "epoch:9, d_loss:359.25628662109375, g_loss: 74.56608581542969 \n",
      "epoch:10, d_loss:102.20967102050781, g_loss: 24.549436569213867 \n",
      "epoch:11, d_loss:67.05526733398438, g_loss: 24.311965942382812 \n",
      "epoch:12, d_loss:42.471675872802734, g_loss: 11.940296173095703 \n",
      "epoch:13, d_loss:35.95812225341797, g_loss: 10.131754875183105 \n",
      "epoch:14, d_loss:24.578411102294922, g_loss: 1.2267920970916748 \n",
      "epoch:15, d_loss:26.10809898376465, g_loss: 3.880197048187256 \n",
      "epoch:16, d_loss:30.635265350341797, g_loss: 9.074752807617188 \n",
      "epoch:17, d_loss:27.030858993530273, g_loss: 5.924488544464111 \n",
      "epoch:18, d_loss:27.659584045410156, g_loss: 6.864084243774414 \n",
      "epoch:19, d_loss:23.147125244140625, g_loss: 2.615724563598633 \n",
      "epoch:20, d_loss:22.60874366760254, g_loss: 2.238896131515503 \n",
      "epoch:21, d_loss:24.426570892333984, g_loss: 4.1696038246154785 \n",
      "epoch:22, d_loss:23.505590438842773, g_loss: 3.341531753540039 \n",
      "epoch:23, d_loss:22.38162612915039, g_loss: 2.361105442047119 \n",
      "epoch:24, d_loss:24.06536865234375, g_loss: 4.12097692489624 \n",
      "epoch:25, d_loss:22.095367431640625, g_loss: 2.2387547492980957 \n",
      "epoch:26, d_loss:23.743518829345703, g_loss: 3.9296112060546875 \n",
      "epoch:27, d_loss:24.29278564453125, g_loss: 4.611625671386719 \n",
      "epoch:28, d_loss:29.012399673461914, g_loss: 9.456270217895508 \n",
      "epoch:29, d_loss:22.042024612426758, g_loss: 2.6333959102630615 \n",
      "epoch:30, d_loss:25.86429214477539, g_loss: 6.49192476272583 \n",
      "epoch:31, d_loss:27.963172912597656, g_loss: 8.645403861999512 \n",
      "epoch:32, d_loss:25.284561157226562, g_loss: 6.111649513244629 \n",
      "epoch:33, d_loss:22.66118812561035, g_loss: 3.6257681846618652 \n",
      "epoch:34, d_loss:21.87818717956543, g_loss: 2.9994759559631348 \n",
      "epoch:35, d_loss:24.57253646850586, g_loss: 5.897705078125 \n",
      "epoch:36, d_loss:21.166824340820312, g_loss: 2.750321865081787 \n",
      "epoch:37, d_loss:21.87887954711914, g_loss: 3.6698150634765625 \n",
      "epoch:38, d_loss:21.697330474853516, g_loss: 3.6699929237365723 \n",
      "epoch:39, d_loss:21.536855697631836, g_loss: 3.7125604152679443 \n",
      "epoch:40, d_loss:19.582637786865234, g_loss: 1.9410368204116821 \n",
      "epoch:41, d_loss:21.374465942382812, g_loss: 3.953491687774658 \n",
      "epoch:42, d_loss:20.680301666259766, g_loss: 3.5201776027679443 \n",
      "epoch:43, d_loss:17.180479049682617, g_loss: 0.24334682524204254 \n",
      "epoch:44, d_loss:21.65711784362793, g_loss: 4.795355796813965 \n",
      "epoch:45, d_loss:20.416706085205078, g_loss: 3.638279676437378 \n",
      "epoch:46, d_loss:19.827306747436523, g_loss: 3.164454936981201 \n",
      "epoch:47, d_loss:17.91062355041504, g_loss: 1.463760495185852 \n",
      "epoch:48, d_loss:19.80658531188965, g_loss: 3.526669502258301 \n",
      "epoch:49, d_loss:18.01031494140625, g_loss: 1.9960706233978271 \n",
      "epoch:50, d_loss:20.53219985961914, g_loss: 4.7736382484436035 \n",
      "epoch:51, d_loss:16.135997772216797, g_loss: 0.5476937294006348 \n",
      "epoch:52, d_loss:18.245941162109375, g_loss: 2.7706351280212402 \n",
      "epoch:53, d_loss:19.60042953491211, g_loss: 4.273731708526611 \n",
      "epoch:54, d_loss:20.317508697509766, g_loss: 5.129091739654541 \n",
      "epoch:55, d_loss:17.88331413269043, g_loss: 2.903964042663574 \n",
      "epoch:56, d_loss:16.169435501098633, g_loss: 1.3904660940170288 \n",
      "epoch:57, d_loss:16.28564453125, g_loss: 1.7409387826919556 \n",
      "epoch:58, d_loss:15.531621932983398, g_loss: 1.2017830610275269 \n",
      "epoch:59, d_loss:17.215553283691406, g_loss: 3.0963075160980225 \n",
      "epoch:60, d_loss:17.701087951660156, g_loss: 3.865534543991089 \n",
      "epoch:61, d_loss:16.699417114257812, g_loss: 3.132071018218994 \n",
      "epoch:62, d_loss:14.832930564880371, g_loss: 1.5252515077590942 \n",
      "epoch:63, d_loss:16.2901554107666, g_loss: 3.095123052597046 \n",
      "epoch:64, d_loss:14.973973274230957, g_loss: 1.8860342502593994 \n",
      "epoch:65, d_loss:14.240543365478516, g_loss: 1.2082196474075317 \n",
      "epoch:66, d_loss:16.92264747619629, g_loss: 3.9772071838378906 \n",
      "epoch:67, d_loss:14.748069763183594, g_loss: 1.905023455619812 \n",
      "epoch:68, d_loss:15.416919708251953, g_loss: 2.657775402069092 \n",
      "epoch:69, d_loss:15.687389373779297, g_loss: 3.177823543548584 \n",
      "epoch:70, d_loss:15.375264167785645, g_loss: 3.0960893630981445 \n",
      "epoch:71, d_loss:18.39320945739746, g_loss: 6.237951755523682 \n",
      "epoch:72, d_loss:13.064830780029297, g_loss: 1.213639259338379 \n",
      "epoch:73, d_loss:14.281682014465332, g_loss: 2.6671080589294434 \n",
      "epoch:74, d_loss:13.965667724609375, g_loss: 2.573259115219116 \n",
      "epoch:75, d_loss:12.754388809204102, g_loss: 1.5969414710998535 \n",
      "epoch:76, d_loss:13.03508186340332, g_loss: 1.9053630828857422 \n",
      "epoch:77, d_loss:13.9253511428833, g_loss: 2.768171548843384 \n",
      "epoch:78, d_loss:12.406595230102539, g_loss: 1.3438842296600342 \n",
      "epoch:79, d_loss:12.506195068359375, g_loss: 1.5605533123016357 \n",
      "epoch:80, d_loss:12.845505714416504, g_loss: 1.9717223644256592 \n",
      "epoch:81, d_loss:13.877825736999512, g_loss: 3.0507397651672363 \n",
      "epoch:82, d_loss:13.44194221496582, g_loss: 2.7009689807891846 \n",
      "epoch:83, d_loss:12.906962394714355, g_loss: 2.3505375385284424 \n",
      "epoch:84, d_loss:13.477188110351562, g_loss: 3.148256778717041 \n",
      "epoch:85, d_loss:13.272534370422363, g_loss: 3.1714603900909424 \n",
      "epoch:86, d_loss:11.599185943603516, g_loss: 1.6994293928146362 \n",
      "epoch:87, d_loss:12.892534255981445, g_loss: 3.0480146408081055 \n",
      "epoch:88, d_loss:11.234593391418457, g_loss: 1.3601752519607544 \n",
      "epoch:89, d_loss:13.382124900817871, g_loss: 3.450745105743408 \n",
      "epoch:90, d_loss:12.508434295654297, g_loss: 2.5888466835021973 \n",
      "epoch:91, d_loss:12.486019134521484, g_loss: 2.552464008331299 \n",
      "epoch:92, d_loss:12.383376121520996, g_loss: 2.344193935394287 \n",
      "epoch:93, d_loss:11.204858779907227, g_loss: 1.00611412525177 \n",
      "epoch:94, d_loss:15.018918991088867, g_loss: 4.693766117095947 \n",
      "epoch:95, d_loss:13.764261245727539, g_loss: 3.5919229984283447 \n",
      "epoch:96, d_loss:12.155567169189453, g_loss: 2.199995279312134 \n",
      "epoch:97, d_loss:11.845954895019531, g_loss: 2.048046827316284 \n",
      "epoch:98, d_loss:13.127708435058594, g_loss: 3.2615623474121094 \n",
      "epoch:99, d_loss:11.973161697387695, g_loss: 2.2056028842926025 \n",
      "epoch:100, d_loss:15.064498901367188, g_loss: 5.335971832275391 \n",
      "epoch:101, d_loss:10.970799446105957, g_loss: 1.4486199617385864 \n",
      "epoch:102, d_loss:11.518291473388672, g_loss: 2.024526357650757 \n",
      "epoch:103, d_loss:12.131174087524414, g_loss: 2.6550683975219727 \n",
      "epoch:104, d_loss:13.781275749206543, g_loss: 4.158299446105957 \n",
      "epoch:105, d_loss:11.81562614440918, g_loss: 2.142408609390259 \n",
      "epoch:106, d_loss:11.942864418029785, g_loss: 2.1868138313293457 \n",
      "epoch:107, d_loss:11.58970832824707, g_loss: 1.7881112098693848 \n",
      "epoch:108, d_loss:15.658821105957031, g_loss: 5.773525714874268 \n",
      "epoch:109, d_loss:10.909663200378418, g_loss: 1.837861180305481 \n",
      "epoch:110, d_loss:12.632387161254883, g_loss: 3.3936586380004883 \n",
      "epoch:111, d_loss:12.157052040100098, g_loss: 4.351895332336426 \n",
      "epoch:112, d_loss:15.253227233886719, g_loss: 2.7636616230010986 \n",
      "epoch:113, d_loss:15.847185134887695, g_loss: 1.9996675252914429 \n",
      "epoch:114, d_loss:29.476564407348633, g_loss: 47.19145202636719 \n",
      "epoch:115, d_loss:130.35205078125, g_loss: 116.35763549804688 \n",
      "epoch:116, d_loss:400.3915100097656, g_loss: 451.129638671875 \n",
      "epoch:117, d_loss:29875.30859375, g_loss: 2558.3349609375 \n",
      "epoch:118, d_loss:12460.134765625, g_loss: 2825.5302734375 \n",
      "epoch:119, d_loss:838223.6875, g_loss: 14280.65234375 \n",
      "epoch:120, d_loss:3117.6533203125, g_loss: 1012.2034912109375 \n",
      "epoch:121, d_loss:655.4923095703125, g_loss: 586.1305541992188 \n",
      "epoch:122, d_loss:243.3426971435547, g_loss: 230.40342712402344 \n",
      "epoch:123, d_loss:180.44631958007812, g_loss: 173.11099243164062 \n",
      "epoch:124, d_loss:204.21664428710938, g_loss: 165.11199951171875 \n",
      "epoch:125, d_loss:89.42707061767578, g_loss: 80.15577697753906 \n",
      "epoch:126, d_loss:239.7402801513672, g_loss: 193.2057647705078 \n",
      "epoch:127, d_loss:88.31839752197266, g_loss: 13.032758712768555 \n",
      "epoch:128, d_loss:163.00823974609375, g_loss: 121.16094970703125 \n",
      "epoch:129, d_loss:522.591064453125, g_loss: 2385.303466796875 \n",
      "epoch:130, d_loss:87871.8125, g_loss: 8361.224609375 \n",
      "epoch:131, d_loss:2487.787353515625, g_loss: 1766.22412109375 \n",
      "epoch:132, d_loss:1759.2471923828125, g_loss: 1695.5367431640625 \n",
      "epoch:133, d_loss:1604.02197265625, g_loss: 1527.2828369140625 \n",
      "epoch:134, d_loss:830.810302734375, g_loss: 752.9552001953125 \n",
      "epoch:135, d_loss:315.6943664550781, g_loss: 412.7706298828125 \n",
      "epoch:136, d_loss:3236.223388671875, g_loss: 2698.9697265625 \n",
      "epoch:137, d_loss:134913456.0, g_loss: 105308.609375 \n",
      "epoch:138, d_loss:92876.6953125, g_loss: 6510.5322265625 \n",
      "epoch:139, d_loss:4589.6171875, g_loss: 666.3675537109375 \n",
      "epoch:140, d_loss:1886.917724609375, g_loss: 411.60302734375 \n",
      "epoch:141, d_loss:1458.2320556640625, g_loss: 308.69708251953125 \n",
      "epoch:142, d_loss:1285.69482421875, g_loss: 140.90061950683594 \n",
      "epoch:143, d_loss:1439.36767578125, g_loss: 240.822998046875 \n",
      "epoch:144, d_loss:1403.611572265625, g_loss: 230.83273315429688 \n",
      "epoch:145, d_loss:1176.599609375, g_loss: 70.1417007446289 \n",
      "epoch:146, d_loss:1032.0389404296875, g_loss: 47.782188415527344 \n",
      "epoch:147, d_loss:974.9091796875, g_loss: 134.545654296875 \n",
      "epoch:148, d_loss:953.0103149414062, g_loss: 263.86297607421875 \n",
      "epoch:149, d_loss:612.6685791015625, g_loss: 80.59349060058594 \n",
      "epoch:150, d_loss:400.221923828125, g_loss: 5.673041343688965 \n",
      "epoch:151, d_loss:280.2318420410156, g_loss: 0.5617625713348389 \n",
      "epoch:152, d_loss:253.95016479492188, g_loss: 72.30703735351562 \n",
      "epoch:153, d_loss:239.99386596679688, g_loss: 150.43605041503906 \n",
      "epoch:154, d_loss:22.667774200439453, g_loss: 28.434720993041992 \n",
      "epoch:155, d_loss:190.52174377441406, g_loss: 181.9387969970703 \n",
      "epoch:156, d_loss:121.81925201416016, g_loss: 104.58088684082031 \n",
      "epoch:157, d_loss:225.5037078857422, g_loss: 198.1584014892578 \n",
      "epoch:158, d_loss:154.7034912109375, g_loss: 130.4129180908203 \n",
      "epoch:159, d_loss:94.6162338256836, g_loss: 86.7598876953125 \n",
      "epoch:160, d_loss:79.95320892333984, g_loss: 67.05828094482422 \n",
      "epoch:161, d_loss:143.2248992919922, g_loss: 128.7060546875 \n",
      "epoch:162, d_loss:137.7132568359375, g_loss: 126.46595764160156 \n",
      "epoch:163, d_loss:13.890403747558594, g_loss: 3.295504331588745 \n",
      "epoch:164, d_loss:74.58122253417969, g_loss: 64.29141235351562 \n",
      "epoch:165, d_loss:10.622113227844238, g_loss: 1.7447888851165771 \n",
      "epoch:166, d_loss:10.05601692199707, g_loss: 1.5866193771362305 \n",
      "epoch:167, d_loss:9.951826095581055, g_loss: 2.0394935607910156 \n",
      "epoch:168, d_loss:74.45296478271484, g_loss: 66.2158203125 \n",
      "epoch:169, d_loss:9.773626327514648, g_loss: 1.4001158475875854 \n",
      "epoch:170, d_loss:9.849390983581543, g_loss: 1.3109239339828491 \n",
      "epoch:171, d_loss:137.8509063720703, g_loss: 129.972900390625 \n",
      "epoch:172, d_loss:10.031492233276367, g_loss: 2.0889759063720703 \n",
      "epoch:173, d_loss:9.077860832214355, g_loss: 1.4339497089385986 \n",
      "epoch:174, d_loss:208.30348205566406, g_loss: 200.76145935058594 \n",
      "epoch:175, d_loss:143.7581024169922, g_loss: 137.52410888671875 \n",
      "epoch:176, d_loss:9.08721923828125, g_loss: 1.7385632991790771 \n",
      "epoch:177, d_loss:8.895245552062988, g_loss: 0.8519558310508728 \n",
      "epoch:178, d_loss:75.97378540039062, g_loss: 67.9937515258789 \n",
      "epoch:179, d_loss:142.9815673828125, g_loss: 137.53675842285156 \n",
      "epoch:180, d_loss:74.28138732910156, g_loss: 66.9115219116211 \n",
      "epoch:181, d_loss:8.798460960388184, g_loss: 2.2811951637268066 \n",
      "epoch:182, d_loss:8.02488899230957, g_loss: 1.9806474447250366 \n",
      "epoch:183, d_loss:8.645447731018066, g_loss: 3.3084402084350586 \n",
      "epoch:184, d_loss:10.640953063964844, g_loss: 2.661189079284668 \n",
      "epoch:185, d_loss:75.27111053466797, g_loss: 68.0721664428711 \n",
      "epoch:186, d_loss:141.70993041992188, g_loss: 134.33499145507812 \n",
      "epoch:187, d_loss:12.319734573364258, g_loss: 2.1391665935516357 \n",
      "epoch:188, d_loss:139.53488159179688, g_loss: 140.20497131347656 \n",
      "epoch:189, d_loss:82.96815490722656, g_loss: 69.04347229003906 \n",
      "epoch:190, d_loss:92.41470336914062, g_loss: 95.03790283203125 \n",
      "epoch:191, d_loss:27.840412139892578, g_loss: 0.6683714985847473 \n",
      "epoch:192, d_loss:69.78985595703125, g_loss: 59.88077163696289 \n",
      "epoch:193, d_loss:27.476707458496094, g_loss: 0.97962486743927 \n",
      "epoch:194, d_loss:27.367408752441406, g_loss: 6.430438041687012 \n",
      "epoch:195, d_loss:63.346153259277344, g_loss: 82.50617980957031 \n",
      "epoch:196, d_loss:33.849124908447266, g_loss: 70.39973449707031 \n",
      "epoch:197, d_loss:90.6123046875, g_loss: 78.23394775390625 \n",
      "epoch:198, d_loss:60.16429138183594, g_loss: 38.776615142822266 \n",
      "epoch:199, d_loss:79.97908020019531, g_loss: 75.7679443359375 \n",
      "epoch:200, d_loss:289.0899658203125, g_loss: 126.58795928955078 \n",
      "epoch:201, d_loss:131.40199279785156, g_loss: 471.35589599609375 \n",
      "epoch:202, d_loss:791.5901489257812, g_loss: 207.5716552734375 \n",
      "epoch:203, d_loss:622.6217041015625, g_loss: 135.8135986328125 \n",
      "epoch:204, d_loss:2273.360107421875, g_loss: 1186.43798828125 \n",
      "epoch:205, d_loss:5035.572265625, g_loss: 1332.5205078125 \n",
      "epoch:206, d_loss:12243.84765625, g_loss: 28844.08203125 \n",
      "epoch:207, d_loss:22308.62890625, g_loss: 123327.296875 \n",
      "epoch:208, d_loss:99899.0, g_loss: 25747.037109375 \n",
      "epoch:209, d_loss:100566.265625, g_loss: 12874.6689453125 \n",
      "epoch:210, d_loss:18337.875, g_loss: 6646.2138671875 \n",
      "epoch:211, d_loss:20395.4765625, g_loss: 21153.173828125 \n",
      "epoch:212, d_loss:25905.83203125, g_loss: 23511.625 \n",
      "epoch:213, d_loss:15812.0546875, g_loss: 4383.177734375 \n",
      "epoch:214, d_loss:29373.974609375, g_loss: 41947.6328125 \n",
      "epoch:215, d_loss:46537416.0, g_loss: 1864056.5 \n",
      "epoch:216, d_loss:584651.9375, g_loss: 204724.734375 \n",
      "epoch:217, d_loss:32998.30078125, g_loss: 20026.03515625 \n",
      "epoch:218, d_loss:5791.19580078125, g_loss: 4338.5283203125 \n",
      "epoch:219, d_loss:1872.945556640625, g_loss: 1640.197509765625 \n",
      "epoch:220, d_loss:1118.9749755859375, g_loss: 1044.4798583984375 \n",
      "epoch:221, d_loss:742.0052490234375, g_loss: 700.5717163085938 \n",
      "epoch:222, d_loss:603.414306640625, g_loss: 571.3445434570312 \n",
      "epoch:223, d_loss:469.6402587890625, g_loss: 443.41986083984375 \n",
      "epoch:224, d_loss:333.2475280761719, g_loss: 310.2320556640625 \n",
      "epoch:225, d_loss:204.6053466796875, g_loss: 182.41375732421875 \n",
      "epoch:226, d_loss:126.97272491455078, g_loss: 103.81940460205078 \n",
      "epoch:227, d_loss:107.66758728027344, g_loss: 60.25532150268555 \n",
      "epoch:228, d_loss:117.55632019042969, g_loss: 62.1188850402832 \n",
      "epoch:229, d_loss:87.3636245727539, g_loss: 76.357177734375 \n",
      "epoch:230, d_loss:102.63121032714844, g_loss: 99.56814575195312 \n",
      "epoch:231, d_loss:76.58323669433594, g_loss: 70.66569519042969 \n",
      "epoch:232, d_loss:77.3675537109375, g_loss: 64.27603149414062 \n",
      "epoch:233, d_loss:62.666725158691406, g_loss: 57.94135284423828 \n",
      "epoch:234, d_loss:70.24758911132812, g_loss: 62.01842498779297 \n",
      "epoch:235, d_loss:56.057403564453125, g_loss: 50.817378997802734 \n",
      "epoch:236, d_loss:133.049560546875, g_loss: 131.8853302001953 \n",
      "epoch:237, d_loss:56.612266540527344, g_loss: 51.393104553222656 \n",
      "epoch:238, d_loss:89.78429412841797, g_loss: 85.18257141113281 \n",
      "epoch:239, d_loss:64.74526977539062, g_loss: 61.36608123779297 \n",
      "epoch:240, d_loss:114.94286346435547, g_loss: 112.04328155517578 \n",
      "epoch:241, d_loss:64.83084106445312, g_loss: 61.812294006347656 \n",
      "epoch:242, d_loss:91.12382507324219, g_loss: 87.45040130615234 \n",
      "epoch:243, d_loss:45.66035079956055, g_loss: 42.03125 \n",
      "epoch:244, d_loss:69.7581787109375, g_loss: 66.4696044921875 \n",
      "epoch:245, d_loss:79.35340881347656, g_loss: 75.9268798828125 \n",
      "epoch:246, d_loss:101.53973388671875, g_loss: 98.1596450805664 \n",
      "epoch:247, d_loss:39.300201416015625, g_loss: 36.0960693359375 \n",
      "epoch:248, d_loss:69.70467376708984, g_loss: 65.4720687866211 \n",
      "epoch:249, d_loss:64.81726837158203, g_loss: 60.73514175415039 \n",
      "epoch:250, d_loss:73.98544311523438, g_loss: 69.984375 \n",
      "epoch:251, d_loss:38.27123260498047, g_loss: 34.82783889770508 \n",
      "epoch:252, d_loss:67.59355926513672, g_loss: 63.82377243041992 \n",
      "epoch:253, d_loss:103.36750030517578, g_loss: 99.79411315917969 \n",
      "epoch:254, d_loss:71.50303649902344, g_loss: 68.74906158447266 \n",
      "epoch:255, d_loss:51.94997024536133, g_loss: 48.98529815673828 \n",
      "epoch:256, d_loss:44.670841217041016, g_loss: 41.701316833496094 \n",
      "epoch:257, d_loss:36.18977737426758, g_loss: 32.81205749511719 \n",
      "epoch:258, d_loss:40.767005920410156, g_loss: 37.2741584777832 \n",
      "epoch:259, d_loss:39.15348815917969, g_loss: 35.75663375854492 \n",
      "epoch:260, d_loss:57.83618927001953, g_loss: 54.00580596923828 \n",
      "epoch:261, d_loss:34.94813537597656, g_loss: 31.427358627319336 \n",
      "epoch:262, d_loss:21.668537139892578, g_loss: 18.269662857055664 \n",
      "epoch:263, d_loss:58.920677185058594, g_loss: 55.709712982177734 \n",
      "epoch:264, d_loss:28.210216522216797, g_loss: 24.64935302734375 \n",
      "epoch:265, d_loss:74.3912353515625, g_loss: 71.11851501464844 \n",
      "epoch:266, d_loss:24.90030288696289, g_loss: 21.60514259338379 \n",
      "epoch:267, d_loss:24.533023834228516, g_loss: 21.440814971923828 \n",
      "epoch:268, d_loss:25.135761260986328, g_loss: 22.810344696044922 \n",
      "epoch:269, d_loss:25.096471786499023, g_loss: 23.22283363342285 \n"
     ]
    }
   ],
   "source": [
    "gan = GAN()\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
