{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"AC-DRAGAN_SRResNet_PixelCNN_for_IRASUTOYA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.g_bn0 = BatchNormalization(name = 'g_bn0')\n",
    "\n",
    "        self.num_res_blocks = 16\n",
    "        self.num_pixel_CNN_blocks = 3\n",
    "        \n",
    "        self.res_bns = []\n",
    "        for i in range(int(self.num_res_blocks)):\n",
    "            self.res_bns.append(BatchNormalization(name = \"res_%d\" % (2*i)))\n",
    "            self.res_bns.append(BatchNormalization(name = \"res_%d\" % (2*i+1)))\n",
    "        \n",
    "        self.ps_bns = []\n",
    "        for i in range(int(self.num_pixel_CNN_blocks)):\n",
    "            self.ps_bns.append(BatchNormalization(name = \"ps_%d\" % i))\n",
    "        \n",
    "        self.g_bn1 = BatchNormalization(name = 'g_bn1')\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            \n",
    "            # reshape from inputs\n",
    "            with tf.variable_scope('fc0'):\n",
    "                #z0 = tf.reshape(z, [-1, self.z_dim])\n",
    "                fc0 = full_connection_layer(z, 64*16*16, name=\"fc0\")\n",
    "                fc0 = self.g_bn0(fc0)\n",
    "                fc0 = tf.nn.relu(fc0)\n",
    "                fc0 = tf.reshape(fc0, [-1,16,16,64])\n",
    "\n",
    "            assert fc0.get_shape().as_list()[1:] == [16,16,64]\n",
    "            \n",
    "            layers = []\n",
    "            layers.append(fc0)\n",
    "            \n",
    "            for i in range(int(self.num_res_blocks)):\n",
    "                with tf.variable_scope('res_%d' % (i+1)):\n",
    "                    res = conv2d_layer(layers[-1], 64, kernel_size=3, strides=1, name=\"g_conv_res_%d\" % (2*i))\n",
    "                    res = self.res_bns[2*i](res)\n",
    "                    res = tf.nn.relu(res)\n",
    "\n",
    "                    res = conv2d_layer(res, 64, kernel_size=3, strides=1, name=\"g_conv_res_%d\" % (2*i+1))\n",
    "                    res = self.res_bns[2*i+1](res)\n",
    "                    res = layers[-1] + res\n",
    "                    layers.append(res)                    \n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [16,16,64]\n",
    "            \n",
    "            with tf.variable_scope('conv17'):\n",
    "                conv17 = conv2d_layer(layers[-1], 64, kernel_size=3, strides=1, name=\"g_conv_17\")\n",
    "                conv17 = self.g_bn1(conv17)\n",
    "                conv17 = tf.nn.relu(conv17)\n",
    "                conv17 = layers[0] + conv17\n",
    "                layers.append(conv17)\n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [16, 16, 64]\n",
    "\n",
    "            for i in range(int(self.num_pixel_CNN_blocks)):\n",
    "                with tf.variable_scope('pixel_CNN_%d' % (i+1)):\n",
    "                    ps = conv2d_layer(layers[-1], 256, kernel_size=3, strides=1, name=\"g_conv_ps_%d\" % (i))\n",
    "                    ps = pixel_shuffle_layer(ps, 2, 64)\n",
    "                    ps = self.ps_bns[i](ps)\n",
    "                    ps = tf.nn.relu(ps)\n",
    "                    layers.append(ps)\n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [128, 128, 64]\n",
    "                    \n",
    "            with tf.variable_scope('output'):\n",
    "                output = conv2d_layer(layers[-1], 3, kernel_size=9, strides=1, name=\"output\")\n",
    "                output = tf.nn.sigmoid(output)\n",
    "\n",
    "            assert output.get_shape().as_list()[1:] == [128, 128, 3]            \n",
    "            \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, cat_size):\n",
    "        self.reuse = False\n",
    "        self.d_bn0 = BatchNormalization(name=\"d_bn0\")\n",
    "        self.d_bn1 = BatchNormalization(name=\"d_bn1\")\n",
    "        self.d_bn2 = BatchNormalization(name=\"d_bn2\")\n",
    "        self.d_bn3 = BatchNormalization(name=\"d_bn3\")\n",
    "        self.d_bn4 = BatchNormalization(name=\"d_bn4\")\n",
    "        \n",
    "        self.cat_size = cat_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        def leaky_relu(x):\n",
    "            return lrelu(x, leak=0.2)\n",
    "\n",
    "        with tf.variable_scope('d', reuse=self.reuse):\n",
    "           \n",
    "            x = tf.reshape(x, [-1, 128, 128, 3])\n",
    "            with tf.variable_scope('conv1'):\n",
    "                conv1 = tf.layers.conv2d(x, 32, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv1 = leaky_relu(conv1)\n",
    "\n",
    "            with tf.variable_scope('res1'):\n",
    "                res1 = tf.layers.conv2d(conv1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res1 = leaky_relu(res1)\n",
    "                res1 = tf.layers.conv2d(res1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res1 = res1 + conv1\n",
    "                res1 = leaky_relu(res1)\n",
    "\n",
    "            with tf.variable_scope('res2'):\n",
    "                res2 = tf.layers.conv2d(res1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res2 = leaky_relu(res2)\n",
    "                res2 = tf.layers.conv2d(res2, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res2 = res2 + res1\n",
    "                res2 = leaky_relu(res2)\n",
    "\n",
    "            with tf.variable_scope('conv2'):\n",
    "                conv2 = tf.layers.conv2d(res2, 64, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv2 = leaky_relu(conv2)\n",
    "\n",
    "            with tf.variable_scope('res3'):\n",
    "                res3 = tf.layers.conv2d(conv2, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res3 = leaky_relu(res3)\n",
    "                res3 = tf.layers.conv2d(res3, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res3 = leaky_relu(res3)\n",
    "                res3 = res3 + conv2\n",
    "                res3 = leaky_relu(res3)\n",
    "\n",
    "            with tf.variable_scope('res4'):\n",
    "                res4 = tf.layers.conv2d(res3, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res4 = leaky_relu(res4)\n",
    "                res4 = tf.layers.conv2d(res4, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res4 = leaky_relu(res4)\n",
    "                res4 = res4 + res3\n",
    "                res4 = leaky_relu(res4)\n",
    "\n",
    "            with tf.variable_scope('conv3'):\n",
    "                conv3 = tf.layers.conv2d(res4, 128, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv3 = leaky_relu(conv3)\n",
    "\n",
    "            num_res_itr = 3\n",
    "            layers = []\n",
    "            layers.append(conv3)\n",
    "            \n",
    "            depth = [128, 256, 512, 1024]\n",
    "            for i in range(int(num_res_itr)):\n",
    "                with tf.variable_scope('res_%d_1' % (i+1+4)):\n",
    "                    res = tf.layers.conv2d(layers[-1], depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = tf.layers.conv2d(res, depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = layers[-1] + res\n",
    "                    res = leaky_relu(res)\n",
    "                layers.append(res)\n",
    "\n",
    "                with tf.variable_scope('res_%d_2' % (i+1+4)):\n",
    "                    res = tf.layers.conv2d(layers[-1], depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = tf.layers.conv2d(res, depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = layers[-1] + res\n",
    "                    res = leaky_relu(res)\n",
    "\n",
    "                conv = tf.layers.conv2d(res, depth[i+1], [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv = leaky_relu(conv) \n",
    "                layers.append(conv)\n",
    "\n",
    "            disc = full_connection_layer(layers[-1], 1, name=\"disc\")\n",
    "            aux = full_connection_layer(layers[-1], self.cat_size, name=\"aux\")\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "\n",
    "        return disc, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.img_size = 128\n",
    "        self.rand_size = 100\n",
    "        self.cat_size = 4\n",
    "        self.z_size = self.rand_size + self.cat_size\n",
    "        \n",
    "        self.epochs = 50000\n",
    "        self.epoch_saveMetrics = 100\n",
    "        self.epoch_saveSampleImg = 100\n",
    "        self.epoch_saveParamter = 5000\n",
    "        self.losses = {\"d_loss\":[], \"g_loss\":[]}\n",
    "\n",
    "        # unrolled counts\n",
    "        self.steps = 5\n",
    "\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, self.img_size*self.img_size*3])\n",
    "        self.Y_tr = tf.placeholder(tf.float32, shape=[None, self.cat_size])\n",
    "        self.z = tf.placeholder(tf.float32, [None, self.z_size])\n",
    "        self.X_per = tf.placeholder(tf.float32, shape=[None, self.img_size*self.img_size*3])\n",
    "\n",
    "        self.g = Generator()\n",
    "        self.d = Discriminator(self.cat_size)\n",
    "        self.Xg = self.g(self.z)\n",
    "        #self.dtd = DTD()\n",
    "        self.irasutoya = IRASUTOYA()\n",
    "        self.learning_rate = tf.placeholder(\"float\", [])\n",
    "\n",
    "    def loss(self):\n",
    "        disc_tr, aux_tr = self.d(self.X_tr)\n",
    "        disc_gen, aux_gen = self.d(self.Xg)\n",
    "        \n",
    "        lambda_adv = 34\n",
    "        lambda_gp = 0.5\n",
    "        lambda_c = 1\n",
    "       \n",
    "        loss_g = lambda_adv*tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_gen, labels=tf.ones_like(disc_gen)))\n",
    "        #loss_g = lambda_adv*tf.reduce_mean(1 - tf.log(disc_gen + TINY))\n",
    "\n",
    "        diff = self.X_per - self.X_tr\n",
    "        #print(g_outputs.shape[0])\n",
    "        alpha = tf.random_uniform(shape=[self.batch_size,1], minval=0., maxval=1.)\n",
    "        interpolates = self.X_tr + (alpha*diff)\n",
    "        disc_interplates, _ = self.d(interpolates)\n",
    "        gradients = tf.gradients(disc_interplates, [interpolates])[0]\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "        gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "\n",
    "        loss_d_tr = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_tr, labels=tf.ones_like(disc_tr)))\n",
    "        loss_d_gen = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_gen, labels=tf.zeros_like(disc_gen)))\n",
    "        loss_d = lambda_adv*(loss_d_tr + loss_d_gen)\n",
    "        loss_d += lambda_gp*gradient_penalty\n",
    "\n",
    "        loss_c_tr = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=aux_tr, labels=self.Y_tr))\n",
    "        loss_c_gen = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=aux_gen, labels=self.Y_tr))\n",
    "        loss_c = (loss_c_tr + loss_c_gen)\n",
    "\n",
    "        loss_g += loss_c\n",
    "        loss_d += loss_c\n",
    "        return loss_g, loss_d\n",
    "\n",
    "    def train(self):\n",
    "        # Optimizer\n",
    "        d_lr = 1e-4\n",
    "        d_beta1 = 0.5\n",
    "        g_lr = 1e-4\n",
    "        g_beta1 = 0.5\n",
    "\n",
    "        self.L_g, self.L_d = self.loss()\n",
    "\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        d_train_op = d_opt.minimize(self.L_d, var_list=self.d.variables)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        g_train_op = g_opt.minimize(self.L_g, var_list=self.g.variables)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        config = tf.ConfigProto(\n",
    "            gpu_options=tf.GPUOptions(\n",
    "                visible_device_list= \"0\"\n",
    "            )\n",
    "        )\n",
    "                \n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # preparing noise vec for test\n",
    "            bs = 100\n",
    "            test_z = np.random.uniform(-1, 1, size=[bs, self.z_size])\n",
    "\n",
    "            # cat 0\n",
    "            bs = 10\n",
    "            test_cat0_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat0_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat0_cat[:, 0] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat0_z = np.concatenate((test_cat0_rand, test_cat0_cat), axis=1)  \n",
    "\n",
    "            # cat 1\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat1_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat1_cat[:, 1] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat1_z = np.concatenate((test_cat0_rand, test_cat1_cat), axis=1)  \n",
    "\n",
    "            # cat 2\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat2_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat2_cat[:, 1] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat2_z = np.concatenate((test_cat0_rand, test_cat2_cat), axis=1)\n",
    "\n",
    "            # cat 3\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat3_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat3_cat[:, 1] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat3_z = np.concatenate((test_cat0_rand, test_cat3_cat), axis=1)\n",
    "\n",
    "            lr = 1e-4\n",
    "            for epoch in range(self.epochs):\n",
    "                if epoch > 2000:\n",
    "                    lr = 5e-5\n",
    "                if epoch > 4000:\n",
    "                    lr = 1e-5\n",
    "\n",
    "                # visualize generated images during training\n",
    "                if epoch % self.epoch_saveSampleImg == 0:\n",
    "                    # rand\n",
    "                    img = sess.run(self.Xg, feed_dict={self.z: test_z})\n",
    "                    save_imgs(model_name, img, name=str(epoch)+\"_rand\")\n",
    "\n",
    "                    # cat\n",
    "                    test_cat = np.concatenate((test_cat0_z, test_cat1_z, test_cat2_z, test_cat3_z), axis=0)\n",
    "                    img = sess.run(self.Xg, feed_dict={self.z: test_cat})\n",
    "                    save_imgs(model_name, img, plot_dim=(4,10), size=(20, 8), name=str(epoch)+\"_cat\")\n",
    "\n",
    "                for step in range(self.steps):\n",
    "                    # extract images for training\n",
    "                    #rand_index = np.random.randint(0, self.dataset.shape[0], size=self.batch_size)\n",
    "                    #X_mb, Y_mb = self.dataset[rand_index, :].astype(np.float32)\n",
    "                    X_mb, Y_mb = self.irasutoya.extract(self.batch_size, self.img_size)\n",
    "                    X_mb = np.reshape(X_mb, [self.batch_size, -1])\n",
    "                    X_mb_per = X_mb + 0.5*np.std(X_mb)*np.random.random(X_mb.shape)\n",
    "\n",
    "                    rand = np.random.uniform(-1, 1, size=[self.batch_size, self.rand_size])\n",
    "                    #print(rand.shape)\n",
    "                    #print(Y_mb.shape)\n",
    "                    z = np.hstack((rand, Y_mb))\n",
    "                    #print(z.shape)\n",
    "\n",
    "                    # train Discriminator\n",
    "                    _, d_loss_value = sess.run([d_train_op, self.L_d], feed_dict={\n",
    "                        self.X_tr: X_mb,\n",
    "                        self.z:z,\n",
    "                        self.Y_tr: Y_mb,\n",
    "                        self.X_per: X_mb_per,\n",
    "                        self.learning_rate:lr,\n",
    "                    })\n",
    "\n",
    "                # train Generator\n",
    "                _, g_loss_value = sess.run([g_train_op, self.L_g], feed_dict={\n",
    "                    self.X_tr: X_mb,\n",
    "                    self.z:z,\n",
    "                    self.Y_tr: Y_mb,\n",
    "                    self.X_per: X_mb_per,\n",
    "                    self.learning_rate:lr,\n",
    "                })\n",
    "\n",
    "                # append loss value for visualizing\n",
    "                self.losses[\"d_loss\"].append(np.sum(d_loss_value))\n",
    "                self.losses[\"g_loss\"].append(np.sum(g_loss_value))\n",
    "                \n",
    "                # print epoch\n",
    "                if epoch % 1 == 0:\n",
    "                    print('epoch:{0}, d_loss:{1}, g_loss: {2} '.format(epoch, d_loss_value, g_loss_value))\n",
    "                \n",
    "                # visualize loss\n",
    "                if epoch % self.epoch_saveMetrics == 0:\n",
    "                    save_metrics(model_name, self.losses, epoch)\n",
    "\n",
    "\n",
    "                # save model parameters \n",
    "                if epoch % self.epoch_saveParamter == 0:\n",
    "                    dir_path = \"model_\" + model_name\n",
    "                    if not os.path.isdir(dir_path):\n",
    "                        os.makedirs(dir_path)\n",
    "\n",
    "                    saver.save(sess, dir_path + \"/\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init IRASUTOYA\n",
      "1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujitoko/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:81: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, d_loss:-0.8569135665893555, g_loss: -30.048709869384766 \n",
      "epoch:1, d_loss:-790.8031005859375, g_loss: -1787.4302978515625 \n",
      "epoch:2, d_loss:-40194.81640625, g_loss: -83129.8046875 \n",
      "epoch:3, d_loss:1634377.75, g_loss: -3440358.5 \n",
      "epoch:4, d_loss:-2468638.5, g_loss: -2819081.5 \n",
      "epoch:5, d_loss:5345255.0, g_loss: -4971751.5 \n",
      "epoch:6, d_loss:262802336.0, g_loss: -11049725.0 \n",
      "epoch:7, d_loss:1072840.0, g_loss: -475068.8125 \n",
      "epoch:8, d_loss:-61453.0546875, g_loss: -53124.21875 \n",
      "epoch:9, d_loss:-19747.9765625, g_loss: -16304.1328125 \n",
      "epoch:10, d_loss:-7541.74462890625, g_loss: -6616.76953125 \n",
      "epoch:11, d_loss:-4697.9609375, g_loss: -4323.63037109375 \n",
      "epoch:12, d_loss:-3162.202880859375, g_loss: -2998.727294921875 \n",
      "epoch:13, d_loss:-2966.089111328125, g_loss: -2866.6787109375 \n",
      "epoch:14, d_loss:-2878.9677734375, g_loss: -2815.4873046875 \n",
      "epoch:15, d_loss:-2496.4501953125, g_loss: -2458.7021484375 \n",
      "epoch:16, d_loss:-2570.921875, g_loss: -2541.39208984375 \n",
      "epoch:17, d_loss:-2037.0167236328125, g_loss: -2018.194091796875 \n",
      "epoch:18, d_loss:-2407.5380859375, g_loss: -2390.04248046875 \n",
      "epoch:19, d_loss:-2157.082275390625, g_loss: -2141.240966796875 \n",
      "epoch:20, d_loss:-2649.692138671875, g_loss: -2635.515380859375 \n",
      "epoch:21, d_loss:-1945.786865234375, g_loss: -1934.51416015625 \n",
      "epoch:22, d_loss:-2255.345458984375, g_loss: -2241.75 \n",
      "epoch:23, d_loss:-1790.614013671875, g_loss: -1777.552978515625 \n",
      "epoch:24, d_loss:-2689.3056640625, g_loss: -2679.7822265625 \n",
      "epoch:25, d_loss:-2668.240478515625, g_loss: -2655.125732421875 \n",
      "epoch:26, d_loss:-2532.633544921875, g_loss: -2519.50927734375 \n",
      "epoch:27, d_loss:-2539.144287109375, g_loss: -2526.1064453125 \n",
      "epoch:28, d_loss:-2340.713623046875, g_loss: -2328.109375 \n",
      "epoch:29, d_loss:-2659.39599609375, g_loss: -2646.15771484375 \n",
      "epoch:30, d_loss:-1894.778076171875, g_loss: -1880.8197021484375 \n",
      "epoch:31, d_loss:-2293.24951171875, g_loss: -2279.89599609375 \n",
      "epoch:32, d_loss:-2685.845703125, g_loss: -2672.4189453125 \n",
      "epoch:33, d_loss:-2698.602294921875, g_loss: -2685.63720703125 \n",
      "epoch:34, d_loss:-2424.405029296875, g_loss: -2410.81982421875 \n",
      "epoch:35, d_loss:-2373.9921875, g_loss: -2359.75 \n",
      "epoch:36, d_loss:-2779.498046875, g_loss: -2767.314453125 \n",
      "epoch:37, d_loss:-2251.09130859375, g_loss: -2238.497314453125 \n",
      "epoch:38, d_loss:-2565.023681640625, g_loss: -2551.12646484375 \n",
      "epoch:39, d_loss:-2535.13134765625, g_loss: -2520.923095703125 \n",
      "epoch:40, d_loss:-2578.375, g_loss: -2565.68994140625 \n",
      "epoch:41, d_loss:-2765.5537109375, g_loss: -2750.60400390625 \n",
      "epoch:42, d_loss:-2343.7236328125, g_loss: -2329.51171875 \n",
      "epoch:43, d_loss:-2048.468505859375, g_loss: -2035.53662109375 \n",
      "epoch:44, d_loss:-2355.211669921875, g_loss: -2338.945556640625 \n",
      "epoch:45, d_loss:-2753.165283203125, g_loss: -2739.338134765625 \n",
      "epoch:46, d_loss:-2353.9765625, g_loss: -2340.899658203125 \n",
      "epoch:47, d_loss:-2684.8564453125, g_loss: -2670.689453125 \n",
      "epoch:48, d_loss:-2332.88671875, g_loss: -2320.937255859375 \n",
      "epoch:49, d_loss:-2807.86279296875, g_loss: -2792.48828125 \n",
      "epoch:50, d_loss:-2299.9873046875, g_loss: -2285.259521484375 \n",
      "epoch:51, d_loss:-2583.57275390625, g_loss: -2568.266845703125 \n",
      "epoch:52, d_loss:-2553.71484375, g_loss: -2541.090576171875 \n",
      "epoch:53, d_loss:-2210.841796875, g_loss: -2194.936767578125 \n",
      "epoch:54, d_loss:-2409.8486328125, g_loss: -2393.098388671875 \n",
      "epoch:55, d_loss:-2281.50048828125, g_loss: -2267.3623046875 \n",
      "epoch:56, d_loss:-2629.65283203125, g_loss: -2613.545654296875 \n",
      "epoch:57, d_loss:-2542.847412109375, g_loss: -2530.260498046875 \n",
      "epoch:58, d_loss:-2769.73046875, g_loss: -2755.826416015625 \n",
      "epoch:59, d_loss:-2839.3759765625, g_loss: -2826.4853515625 \n",
      "epoch:60, d_loss:-2666.864990234375, g_loss: -2649.62890625 \n",
      "epoch:61, d_loss:-1734.3988037109375, g_loss: -1717.801025390625 \n",
      "epoch:62, d_loss:-2716.74951171875, g_loss: -2704.998046875 \n",
      "epoch:63, d_loss:-2886.734375, g_loss: -2871.249755859375 \n",
      "epoch:64, d_loss:-2038.3106689453125, g_loss: -2022.3800048828125 \n",
      "epoch:65, d_loss:-2900.0185546875, g_loss: -2884.044921875 \n",
      "epoch:66, d_loss:-2631.36474609375, g_loss: -2615.025634765625 \n",
      "epoch:67, d_loss:-2763.664306640625, g_loss: -2750.56884765625 \n",
      "epoch:68, d_loss:-2582.889404296875, g_loss: -2566.273681640625 \n",
      "epoch:69, d_loss:-2211.8193359375, g_loss: -2193.207763671875 \n",
      "epoch:70, d_loss:-2982.060791015625, g_loss: -2964.994140625 \n",
      "epoch:71, d_loss:-2451.915771484375, g_loss: -2436.2890625 \n",
      "epoch:72, d_loss:-3013.010498046875, g_loss: -2997.952392578125 \n",
      "epoch:73, d_loss:-3217.82666015625, g_loss: -3204.68603515625 \n",
      "epoch:74, d_loss:-2926.24365234375, g_loss: -2911.38720703125 \n",
      "epoch:75, d_loss:-2717.779296875, g_loss: -2701.6220703125 \n",
      "epoch:76, d_loss:-2994.95654296875, g_loss: -2979.66552734375 \n",
      "epoch:77, d_loss:-2833.766845703125, g_loss: -2818.365234375 \n",
      "epoch:78, d_loss:-2618.07373046875, g_loss: -2602.162109375 \n",
      "epoch:79, d_loss:-2874.1318359375, g_loss: -2859.452392578125 \n",
      "epoch:80, d_loss:-2750.29736328125, g_loss: -2731.45703125 \n",
      "epoch:81, d_loss:-2942.635498046875, g_loss: -2927.354248046875 \n",
      "epoch:82, d_loss:-3420.10498046875, g_loss: -3403.777587890625 \n",
      "epoch:83, d_loss:-2830.02197265625, g_loss: -2813.195556640625 \n",
      "epoch:84, d_loss:-2533.87451171875, g_loss: -2516.509033203125 \n",
      "epoch:85, d_loss:-2954.9013671875, g_loss: -2941.21044921875 \n",
      "epoch:86, d_loss:-2997.982177734375, g_loss: -2980.479248046875 \n",
      "epoch:87, d_loss:-3213.54443359375, g_loss: -3198.62158203125 \n",
      "epoch:88, d_loss:-3460.741943359375, g_loss: -3445.5673828125 \n",
      "epoch:89, d_loss:-2910.13671875, g_loss: -2891.831787109375 \n",
      "epoch:90, d_loss:-2903.89990234375, g_loss: -2887.789306640625 \n",
      "epoch:91, d_loss:-2928.454833984375, g_loss: -2912.46875 \n",
      "epoch:92, d_loss:-3516.0966796875, g_loss: -3501.162353515625 \n",
      "epoch:93, d_loss:-2811.8642578125, g_loss: -2793.595947265625 \n",
      "epoch:94, d_loss:-3366.805908203125, g_loss: -3349.361328125 \n",
      "epoch:95, d_loss:-3523.794677734375, g_loss: -3507.666748046875 \n",
      "epoch:96, d_loss:-3301.56591796875, g_loss: -3283.8662109375 \n",
      "epoch:97, d_loss:-3819.81982421875, g_loss: -3802.6884765625 \n",
      "epoch:98, d_loss:-3301.464599609375, g_loss: -3285.727294921875 \n",
      "epoch:99, d_loss:-3913.6943359375, g_loss: -3899.5869140625 \n",
      "epoch:100, d_loss:-3696.68505859375, g_loss: -3681.43505859375 \n",
      "epoch:101, d_loss:-2836.330078125, g_loss: -2819.542724609375 \n",
      "epoch:102, d_loss:-3367.61572265625, g_loss: -3350.66650390625 \n",
      "epoch:103, d_loss:-3349.650146484375, g_loss: -3332.294189453125 \n",
      "epoch:104, d_loss:-3397.21240234375, g_loss: -3379.40283203125 \n",
      "epoch:105, d_loss:-3154.681640625, g_loss: -3139.56298828125 \n",
      "epoch:106, d_loss:-3252.739013671875, g_loss: -3237.849365234375 \n",
      "epoch:107, d_loss:-3725.99951171875, g_loss: -3713.292236328125 \n",
      "epoch:108, d_loss:-4265.458984375, g_loss: -4251.3896484375 \n",
      "epoch:109, d_loss:-3351.7392578125, g_loss: -3337.544189453125 \n",
      "epoch:110, d_loss:-3695.75146484375, g_loss: -3680.579345703125 \n",
      "epoch:111, d_loss:-3691.216552734375, g_loss: -3674.114013671875 \n",
      "epoch:112, d_loss:-3781.735107421875, g_loss: -3768.88330078125 \n",
      "epoch:113, d_loss:-4434.11279296875, g_loss: -4425.1982421875 \n",
      "epoch:114, d_loss:-3962.280029296875, g_loss: -3952.429931640625 \n",
      "epoch:115, d_loss:-4181.68603515625, g_loss: -4170.6318359375 \n",
      "epoch:116, d_loss:-4618.30029296875, g_loss: -4612.72900390625 \n",
      "epoch:117, d_loss:-4797.822265625, g_loss: -4792.865234375 \n",
      "epoch:118, d_loss:-4050.364990234375, g_loss: -4039.0419921875 \n",
      "epoch:119, d_loss:-5294.72314453125, g_loss: -5295.56884765625 \n",
      "epoch:120, d_loss:-4910.85546875, g_loss: -4912.32763671875 \n",
      "epoch:121, d_loss:-5544.5185546875, g_loss: -5555.94677734375 \n",
      "epoch:122, d_loss:-5612.8583984375, g_loss: -5625.2607421875 \n",
      "epoch:123, d_loss:-6219.6630859375, g_loss: -6247.5458984375 \n",
      "epoch:124, d_loss:-5094.2646484375, g_loss: -5114.55859375 \n",
      "epoch:125, d_loss:-5627.6220703125, g_loss: -5660.43505859375 \n",
      "epoch:126, d_loss:-6263.71337890625, g_loss: -6309.849609375 \n",
      "epoch:127, d_loss:-5756.5869140625, g_loss: -5806.20361328125 \n",
      "epoch:128, d_loss:-6766.44384765625, g_loss: -6838.54296875 \n",
      "epoch:129, d_loss:-9571.87890625, g_loss: -9734.400390625 \n",
      "epoch:130, d_loss:-10491.3857421875, g_loss: -10697.685546875 \n",
      "epoch:131, d_loss:-9356.373046875, g_loss: -9579.3017578125 \n",
      "epoch:132, d_loss:-13464.0302734375, g_loss: -13897.55078125 \n",
      "epoch:133, d_loss:-15621.341796875, g_loss: -16250.6376953125 \n",
      "epoch:134, d_loss:-21219.6484375, g_loss: -22297.908203125 \n",
      "epoch:135, d_loss:-21239.62890625, g_loss: -22648.75 \n",
      "epoch:136, d_loss:-38990.55078125, g_loss: -42409.796875 \n",
      "epoch:137, d_loss:-47110.83984375, g_loss: -52964.00390625 \n",
      "epoch:138, d_loss:-76694.9921875, g_loss: -90586.6953125 \n",
      "epoch:139, d_loss:-153340.5, g_loss: -198028.875 \n",
      "epoch:140, d_loss:-239465.25, g_loss: -416058.4375 \n",
      "epoch:141, d_loss:60592.0, g_loss: -1422622.875 \n",
      "epoch:142, d_loss:7435148.0, g_loss: -12709963.0 \n",
      "epoch:143, d_loss:9417550848.0, g_loss: -6056524.0 \n",
      "epoch:144, d_loss:1022945.5625, g_loss: 10227.921875 \n",
      "epoch:145, d_loss:83569.2578125, g_loss: 23401.2890625 \n",
      "epoch:146, d_loss:477824.78125, g_loss: 51516.83203125 \n",
      "epoch:147, d_loss:1990075.75, g_loss: 105079.5546875 \n",
      "epoch:148, d_loss:4125821.5, g_loss: 135870.875 \n",
      "epoch:149, d_loss:5497386.5, g_loss: 165756.46875 \n",
      "epoch:150, d_loss:5028030.0, g_loss: 156764.90625 \n",
      "epoch:151, d_loss:3563061.75, g_loss: 142839.859375 \n",
      "epoch:152, d_loss:2676411.75, g_loss: 144527.078125 \n",
      "epoch:153, d_loss:2066408.375, g_loss: 143700.65625 \n",
      "epoch:154, d_loss:1571663.875, g_loss: 134454.9375 \n",
      "epoch:155, d_loss:1262370.75, g_loss: 110602.6875 \n",
      "epoch:156, d_loss:1045606.0625, g_loss: 109914.046875 \n",
      "epoch:157, d_loss:905529.25, g_loss: 103593.265625 \n",
      "epoch:158, d_loss:773671.375, g_loss: 95923.875 \n",
      "epoch:159, d_loss:740361.875, g_loss: 97239.5390625 \n",
      "epoch:160, d_loss:652143.0, g_loss: 86135.0546875 \n",
      "epoch:161, d_loss:659120.4375, g_loss: 95098.59375 \n",
      "epoch:162, d_loss:591093.625, g_loss: 90351.921875 \n",
      "epoch:163, d_loss:550549.0625, g_loss: 92792.4765625 \n",
      "epoch:164, d_loss:515704.90625, g_loss: 88729.453125 \n",
      "epoch:165, d_loss:495515.71875, g_loss: 95656.84375 \n",
      "epoch:166, d_loss:489128.21875, g_loss: 93562.8046875 \n",
      "epoch:167, d_loss:459817.5, g_loss: 85317.5625 \n",
      "epoch:168, d_loss:441843.6875, g_loss: 76615.5625 \n",
      "epoch:169, d_loss:438749.40625, g_loss: 79375.515625 \n",
      "epoch:170, d_loss:409303.8125, g_loss: 74525.109375 \n",
      "epoch:171, d_loss:420218.3125, g_loss: 74801.7734375 \n",
      "epoch:172, d_loss:429428.875, g_loss: 96905.1796875 \n",
      "epoch:173, d_loss:432798.0, g_loss: 81451.7109375 \n",
      "epoch:174, d_loss:412984.125, g_loss: 88431.203125 \n",
      "epoch:175, d_loss:423899.1875, g_loss: 83897.21875 \n",
      "epoch:176, d_loss:439444.5625, g_loss: 98740.40625 \n",
      "epoch:177, d_loss:419584.0, g_loss: 95234.703125 \n",
      "epoch:178, d_loss:432335.0625, g_loss: 92120.1015625 \n",
      "epoch:179, d_loss:426650.0625, g_loss: 91139.03125 \n",
      "epoch:180, d_loss:446657.0625, g_loss: 92592.21875 \n",
      "epoch:181, d_loss:440975.5625, g_loss: 90293.078125 \n",
      "epoch:182, d_loss:465523.75, g_loss: 101618.0234375 \n",
      "epoch:183, d_loss:475099.6875, g_loss: 97539.5 \n",
      "epoch:184, d_loss:494246.8125, g_loss: 100617.5 \n",
      "epoch:185, d_loss:473030.6875, g_loss: 89806.7578125 \n",
      "epoch:186, d_loss:507660.75, g_loss: 120146.8671875 \n",
      "epoch:187, d_loss:523958.0625, g_loss: 100651.15625 \n",
      "epoch:188, d_loss:533169.5625, g_loss: 110147.328125 \n",
      "epoch:189, d_loss:538260.375, g_loss: 98400.53125 \n",
      "epoch:190, d_loss:573032.625, g_loss: 125698.390625 \n",
      "epoch:191, d_loss:595122.375, g_loss: 106128.96875 \n",
      "epoch:192, d_loss:587809.25, g_loss: 119742.109375 \n",
      "epoch:193, d_loss:647026.0, g_loss: 155783.28125 \n",
      "epoch:194, d_loss:664200.5, g_loss: 149069.546875 \n",
      "epoch:195, d_loss:665772.8125, g_loss: 145373.0 \n",
      "epoch:196, d_loss:709124.0625, g_loss: 147904.59375 \n",
      "epoch:197, d_loss:736998.4375, g_loss: 120786.5625 \n",
      "epoch:198, d_loss:754690.125, g_loss: 126800.25 \n",
      "epoch:199, d_loss:795965.125, g_loss: 126210.09375 \n",
      "epoch:200, d_loss:823294.625, g_loss: 120421.03125 \n",
      "epoch:201, d_loss:889290.1875, g_loss: 132776.59375 \n",
      "epoch:202, d_loss:914322.125, g_loss: 137616.125 \n",
      "epoch:203, d_loss:986704.0, g_loss: 134586.09375 \n",
      "epoch:204, d_loss:1058593.75, g_loss: 155201.5625 \n",
      "epoch:205, d_loss:1104891.0, g_loss: 135572.0625 \n",
      "epoch:206, d_loss:1129186.5, g_loss: 130729.375 \n",
      "epoch:207, d_loss:1239358.0, g_loss: 133219.75 \n",
      "epoch:208, d_loss:1335960.5, g_loss: 161151.25 \n",
      "epoch:209, d_loss:1398768.5, g_loss: 192358.75 \n",
      "epoch:210, d_loss:1486302.125, g_loss: 189563.125 \n",
      "epoch:211, d_loss:1476740.5, g_loss: 117458.5 \n",
      "epoch:212, d_loss:1623037.5, g_loss: 154906.9375 \n",
      "epoch:213, d_loss:1676355.125, g_loss: 36656.375 \n",
      "epoch:214, d_loss:2046163.625, g_loss: 156812.0 \n",
      "epoch:215, d_loss:2208942.0, g_loss: 103413.9375 \n",
      "epoch:216, d_loss:2195690.25, g_loss: -89006.125 \n",
      "epoch:217, d_loss:2897285.5, g_loss: 111031.25 \n",
      "epoch:218, d_loss:3109005.25, g_loss: 92983.25 \n",
      "epoch:219, d_loss:3665424.0, g_loss: -231639.125 \n",
      "epoch:220, d_loss:4535491.0, g_loss: 25732.5 \n",
      "epoch:221, d_loss:6026056.0, g_loss: -546521.0 \n",
      "epoch:222, d_loss:9065424.0, g_loss: -1236304.5 \n",
      "epoch:223, d_loss:19470984.0, g_loss: -3031612.0 \n",
      "epoch:224, d_loss:108406096.0, g_loss: -56122156.0 \n",
      "epoch:225, d_loss:-162230176.0, g_loss: -311448704.0 \n",
      "epoch:226, d_loss:61346996224.0, g_loss: -7336354304.0 \n",
      "epoch:227, d_loss:41770467328.0, g_loss: -247745872.0 \n",
      "epoch:228, d_loss:84959504.0, g_loss: -5540363.0 \n",
      "epoch:229, d_loss:19972.4375, g_loss: -318375.0 \n",
      "epoch:230, d_loss:38919.25, g_loss: -283201.375 \n",
      "epoch:231, d_loss:125100.25, g_loss: -315861.90625 \n",
      "epoch:232, d_loss:276626.0, g_loss: -279591.78125 \n",
      "epoch:233, d_loss:263429.5, g_loss: -377878.6875 \n",
      "epoch:234, d_loss:374646.0625, g_loss: -330051.9375 \n",
      "epoch:235, d_loss:367917.375, g_loss: -414374.3125 \n",
      "epoch:236, d_loss:512739.375, g_loss: -345236.0625 \n",
      "epoch:237, d_loss:645417.75, g_loss: -299809.25 \n",
      "epoch:238, d_loss:715403.9375, g_loss: -368815.28125 \n",
      "epoch:239, d_loss:754524.75, g_loss: -388151.0 \n",
      "epoch:240, d_loss:762111.25, g_loss: -504113.53125 \n",
      "epoch:241, d_loss:820750.25, g_loss: -549205.25 \n",
      "epoch:242, d_loss:918828.625, g_loss: -684560.0 \n",
      "epoch:243, d_loss:1402803.125, g_loss: -328316.4375 \n",
      "epoch:244, d_loss:1464286.5, g_loss: -510695.3125 \n",
      "epoch:245, d_loss:1508662.625, g_loss: -652080.125 \n",
      "epoch:246, d_loss:1920590.375, g_loss: -587801.375 \n",
      "epoch:247, d_loss:2284628.0, g_loss: -499910.0 \n",
      "epoch:248, d_loss:2359528.0, g_loss: -787321.6875 \n",
      "epoch:249, d_loss:2966499.0, g_loss: -556603.75 \n",
      "epoch:250, d_loss:3230769.0, g_loss: -615030.25 \n",
      "epoch:251, d_loss:3514690.5, g_loss: -865186.875 \n",
      "epoch:252, d_loss:4000265.0, g_loss: -788326.0 \n",
      "epoch:253, d_loss:4711371.0, g_loss: -940050.875 \n",
      "epoch:254, d_loss:5140946.5, g_loss: -1041899.4375 \n",
      "epoch:255, d_loss:6093432.0, g_loss: -821804.0 \n",
      "epoch:256, d_loss:6328663.0, g_loss: -1286292.75 \n",
      "epoch:257, d_loss:7336027.5, g_loss: -1313560.0 \n",
      "epoch:258, d_loss:8394435.0, g_loss: -1085623.0 \n",
      "epoch:259, d_loss:9647504.0, g_loss: -1148250.25 \n",
      "epoch:260, d_loss:10392395.0, g_loss: -1467421.0 \n",
      "epoch:261, d_loss:11652495.0, g_loss: -1241903.0 \n",
      "epoch:262, d_loss:12668101.0, g_loss: -1591870.5 \n",
      "epoch:263, d_loss:13783908.0, g_loss: -1859951.5 \n",
      "epoch:264, d_loss:15188522.0, g_loss: -1516800.25 \n",
      "epoch:265, d_loss:15564144.0, g_loss: -2433528.5 \n",
      "epoch:266, d_loss:17054502.0, g_loss: -1887581.0 \n",
      "epoch:267, d_loss:18524696.0, g_loss: -2196545.5 \n",
      "epoch:268, d_loss:20182622.0, g_loss: -1387449.875 \n",
      "epoch:269, d_loss:19670530.0, g_loss: -2817477.5 \n",
      "epoch:270, d_loss:20353244.0, g_loss: -2158440.0 \n",
      "epoch:271, d_loss:21971576.0, g_loss: -2148125.75 \n",
      "epoch:272, d_loss:21684936.0, g_loss: -2671260.5 \n",
      "epoch:273, d_loss:22727974.0, g_loss: -3277001.5 \n",
      "epoch:274, d_loss:22927936.0, g_loss: -3140174.5 \n",
      "epoch:275, d_loss:23981450.0, g_loss: -2905152.5 \n",
      "epoch:276, d_loss:24017862.0, g_loss: -3124625.25 \n",
      "epoch:277, d_loss:25557060.0, g_loss: -2247489.75 \n",
      "epoch:278, d_loss:25191764.0, g_loss: -3451546.0 \n",
      "epoch:279, d_loss:24830700.0, g_loss: -3767123.75 \n",
      "epoch:280, d_loss:24785636.0, g_loss: -4062193.5 \n",
      "epoch:281, d_loss:24797482.0, g_loss: -3860133.0 \n",
      "epoch:282, d_loss:24942748.0, g_loss: -4209286.0 \n",
      "epoch:283, d_loss:25376498.0, g_loss: -3700149.0 \n",
      "epoch:284, d_loss:23608996.0, g_loss: -4282714.0 \n",
      "epoch:285, d_loss:22444800.0, g_loss: -4625395.0 \n",
      "epoch:286, d_loss:21145980.0, g_loss: -5976004.0 \n",
      "epoch:287, d_loss:20836312.0, g_loss: -6500623.0 \n",
      "epoch:288, d_loss:22461072.0, g_loss: -7419233.0 \n",
      "epoch:289, d_loss:21894536.0, g_loss: -8228237.0 \n",
      "epoch:290, d_loss:22269750.0, g_loss: -8577309.0 \n",
      "epoch:291, d_loss:19728128.0, g_loss: -11240254.0 \n",
      "epoch:292, d_loss:25201294.0, g_loss: -8793810.0 \n",
      "epoch:293, d_loss:22133972.0, g_loss: -12590645.0 \n",
      "epoch:294, d_loss:16114902.0, g_loss: -18063580.0 \n",
      "epoch:295, d_loss:13676616.0, g_loss: -19568928.0 \n",
      "epoch:296, d_loss:1680864.0, g_loss: -30088046.0 \n",
      "epoch:297, d_loss:-20622920.0, g_loss: -49039004.0 \n",
      "epoch:298, d_loss:-56046384.0, g_loss: -80946328.0 \n",
      "epoch:299, d_loss:-131268032.0, g_loss: -171513456.0 \n",
      "epoch:300, d_loss:-370614976.0, g_loss: -505515264.0 \n",
      "epoch:301, d_loss:173912817664.0, g_loss: -910660096.0 \n",
      "epoch:302, d_loss:1747516416.0, g_loss: -62652880.0 \n",
      "epoch:303, d_loss:50963528.0, g_loss: -8985536.0 \n",
      "epoch:304, d_loss:1310532.5, g_loss: -2719430.75 \n",
      "epoch:305, d_loss:278583.625, g_loss: -1076325.5 \n",
      "epoch:306, d_loss:112697.5625, g_loss: -949111.0 \n",
      "epoch:307, d_loss:177472.5, g_loss: -770012.625 \n",
      "epoch:308, d_loss:208453.5, g_loss: -730032.6875 \n",
      "epoch:309, d_loss:135625.625, g_loss: -810007.375 \n",
      "epoch:310, d_loss:255010.0625, g_loss: -723329.875 \n",
      "epoch:311, d_loss:196666.875, g_loss: -833159.25 \n"
     ]
    }
   ],
   "source": [
    "gan = GAN()\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
