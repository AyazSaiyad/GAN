{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"AC-DRAGAN_SRResNet_PixelCNN_for_IRASUTOYA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from model import *\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.g_bn0 = BatchNormalization(name = 'g_bn0')\n",
    "\n",
    "        self.num_res_blocks = 16\n",
    "        self.num_pixel_CNN_blocks = 3\n",
    "        \n",
    "        self.res_bns = []\n",
    "        for i in range(int(self.num_res_blocks)):\n",
    "            self.res_bns.append(BatchNormalization(name = \"res_%d\" % (2*i)))\n",
    "            self.res_bns.append(BatchNormalization(name = \"res_%d\" % (2*i+1)))\n",
    "        \n",
    "        self.ps_bns = []\n",
    "        for i in range(int(self.num_pixel_CNN_blocks)):\n",
    "            self.ps_bns.append(BatchNormalization(name = \"ps_%d\" % i))\n",
    "        \n",
    "        self.g_bn1 = BatchNormalization(name = 'g_bn1')\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            \n",
    "            # reshape from inputs\n",
    "            with tf.variable_scope('fc0'):\n",
    "                #z0 = tf.reshape(z, [-1, self.z_dim])\n",
    "                fc0 = full_connection_layer(z, 64*16*16, name=\"fc0\")\n",
    "                fc0 = self.g_bn0(fc0)\n",
    "                fc0 = tf.nn.relu(fc0)\n",
    "                fc0 = tf.reshape(fc0, [-1,16,16,64])\n",
    "\n",
    "            assert fc0.get_shape().as_list()[1:] == [16,16,64]\n",
    "            \n",
    "            layers = []\n",
    "            layers.append(fc0)\n",
    "            \n",
    "            for i in range(int(self.num_res_blocks)):\n",
    "                with tf.variable_scope('res_%d' % (i+1)):\n",
    "                    res = conv2d_layer(layers[-1], 64, kernel_size=3, strides=1, name=\"g_conv_res_%d\" % (2*i))\n",
    "                    res = self.res_bns[2*i](res)\n",
    "                    res = tf.nn.relu(res)\n",
    "\n",
    "                    res = conv2d_layer(res, 64, kernel_size=3, strides=1, name=\"g_conv_res_%d\" % (2*i+1))\n",
    "                    res = self.res_bns[2*i+1](res)\n",
    "                    res = layers[-1] + res\n",
    "                    layers.append(res)                    \n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [16,16,64]\n",
    "            \n",
    "            with tf.variable_scope('conv17'):\n",
    "                conv17 = conv2d_layer(layers[-1], 64, kernel_size=3, strides=1, name=\"g_conv_17\")\n",
    "                conv17 = self.g_bn1(conv17)\n",
    "                conv17 = tf.nn.relu(conv17)\n",
    "                conv17 = layers[0] + conv17\n",
    "                layers.append(conv17)\n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [16, 16, 64]\n",
    "\n",
    "            for i in range(int(self.num_pixel_CNN_blocks)):\n",
    "                with tf.variable_scope('pixel_CNN_%d' % (i+1)):\n",
    "                    ps = conv2d_layer(layers[-1], 256, kernel_size=3, strides=1, name=\"g_conv_ps_%d\" % (i))\n",
    "                    ps = pixel_shuffle_layer(ps, 2, 64)\n",
    "                    ps = self.ps_bns[i](ps)\n",
    "                    ps = tf.nn.relu(ps)\n",
    "                    layers.append(ps)\n",
    "\n",
    "            assert layers[-1].get_shape().as_list()[1:] == [128, 128, 64]\n",
    "                    \n",
    "            with tf.variable_scope('output'):\n",
    "                output = conv2d_layer(layers[-1], 3, kernel_size=9, strides=1, name=\"output\")\n",
    "                output = tf.nn.sigmoid(output)\n",
    "\n",
    "            assert output.get_shape().as_list()[1:] == [128, 128, 3]            \n",
    "            \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, cat_size):\n",
    "        self.reuse = False\n",
    "        self.d_bn0 = BatchNormalization(name=\"d_bn0\")\n",
    "        self.d_bn1 = BatchNormalization(name=\"d_bn1\")\n",
    "        self.d_bn2 = BatchNormalization(name=\"d_bn2\")\n",
    "        self.d_bn3 = BatchNormalization(name=\"d_bn3\")\n",
    "        self.d_bn4 = BatchNormalization(name=\"d_bn4\")\n",
    "        \n",
    "        self.cat_size = cat_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "        def leaky_relu(x):\n",
    "            return lrelu(x, leak=0.2)\n",
    "\n",
    "        with tf.variable_scope('d', reuse=self.reuse):\n",
    "           \n",
    "            x = tf.reshape(x, [-1, 128, 128, 3])\n",
    "            with tf.variable_scope('conv1'):\n",
    "                conv1 = tf.layers.conv2d(x, 32, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv1 = leaky_relu(conv1)\n",
    "\n",
    "            with tf.variable_scope('res1'):\n",
    "                res1 = tf.layers.conv2d(conv1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res1 = leaky_relu(res1)\n",
    "                res1 = tf.layers.conv2d(res1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res1 = res1 + conv1\n",
    "                res1 = leaky_relu(res1)\n",
    "\n",
    "            with tf.variable_scope('res2'):\n",
    "                res2 = tf.layers.conv2d(res1, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res2 = leaky_relu(res2)\n",
    "                res2 = tf.layers.conv2d(res2, 32, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res2 = res2 + res1\n",
    "                res2 = leaky_relu(res2)\n",
    "\n",
    "            with tf.variable_scope('conv2'):\n",
    "                conv2 = tf.layers.conv2d(res2, 64, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv2 = leaky_relu(conv2)\n",
    "\n",
    "            with tf.variable_scope('res3'):\n",
    "                res3 = tf.layers.conv2d(conv2, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res3 = leaky_relu(res3)\n",
    "                res3 = tf.layers.conv2d(res3, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res3 = leaky_relu(res3)\n",
    "                res3 = res3 + conv2\n",
    "                res3 = leaky_relu(res3)\n",
    "\n",
    "            with tf.variable_scope('res4'):\n",
    "                res4 = tf.layers.conv2d(res3, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res4 = leaky_relu(res4)\n",
    "                res4 = tf.layers.conv2d(res4, 64, [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                res4 = leaky_relu(res4)\n",
    "                res4 = res4 + res3\n",
    "                res4 = leaky_relu(res4)\n",
    "\n",
    "            with tf.variable_scope('conv3'):\n",
    "                conv3 = tf.layers.conv2d(res4, 128, [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv3 = leaky_relu(conv3)\n",
    "\n",
    "            num_res_itr = 3\n",
    "            layers = []\n",
    "            layers.append(conv3)\n",
    "            \n",
    "            depth = [128, 256, 512, 1024]\n",
    "            for i in range(int(num_res_itr)):\n",
    "                with tf.variable_scope('res_%d_1' % (i+1+4)):\n",
    "                    res = tf.layers.conv2d(layers[-1], depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = tf.layers.conv2d(res, depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = layers[-1] + res\n",
    "                    res = leaky_relu(res)\n",
    "                layers.append(res)\n",
    "\n",
    "                with tf.variable_scope('res_%d_2' % (i+1+4)):\n",
    "                    res = tf.layers.conv2d(layers[-1], depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = tf.layers.conv2d(res, depth[i], [3,3], [1,1], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    res = leaky_relu(res)\n",
    "                    res = layers[-1] + res\n",
    "                    res = leaky_relu(res)\n",
    "\n",
    "                conv = tf.layers.conv2d(res, depth[i+1], [4, 4], [2 ,2], padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                conv = leaky_relu(conv) \n",
    "                layers.append(conv)\n",
    "\n",
    "            disc = full_connection_layer(layers[-1], 1, name=\"disc\")\n",
    "            aux = full_connection_layer(layers[-1], self.cat_size, name=\"aux\")\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "\n",
    "        return disc, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.img_size = 128\n",
    "        self.rand_size = 100\n",
    "        self.cat_size = 4\n",
    "        self.z_size = self.rand_size + self.cat_size\n",
    "        \n",
    "        self.epochs = 50000\n",
    "        self.epoch_saveMetrics = 50\n",
    "        self.epoch_saveSampleImg = 50\n",
    "        self.epoch_saveParamter = 5000\n",
    "        self.losses = {\"d_loss\":[], \"g_loss\":[]}\n",
    "\n",
    "        # unrolled counts\n",
    "        self.steps = 5\n",
    "\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, self.img_size*self.img_size*3])\n",
    "        self.Y_tr = tf.placeholder(tf.float32, shape=[None, self.cat_size])\n",
    "        self.z = tf.placeholder(tf.float32, [None, self.z_size])\n",
    "        self.X_per = tf.placeholder(tf.float32, shape=[None, self.img_size*self.img_size*3])\n",
    "\n",
    "        self.g = Generator()\n",
    "        self.d = Discriminator(self.cat_size)\n",
    "        self.Xg = self.g(self.z)\n",
    "        #self.dtd = DTD()\n",
    "        self.irasutoya = IRASUTOYA()\n",
    "\n",
    "    def loss(self):\n",
    "        disc_tr, aux_tr = self.d(self.X_tr)\n",
    "        disc_gen, aux_gen = self.d(self.Xg)\n",
    "        \n",
    "        lambda_adv = 34\n",
    "        lambda_gp = 0.5\n",
    "       \n",
    "        loss_g = lambda_adv*tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_gen, labels=tf.ones_like(disc_gen)))\n",
    "        #loss_g = lambda_adv*tf.reduce_mean(1 - tf.log(disc_gen + TINY))\n",
    "\n",
    "        diff = self.X_per - self.X_tr\n",
    "        #print(g_outputs.shape[0])\n",
    "        alpha = tf.random_uniform(shape=[self.batch_size,1], minval=0., maxval=1.)\n",
    "        interpolates = self.X_tr + (alpha*diff)\n",
    "        disc_interplates, _ = self.d(interpolates)\n",
    "        gradients = tf.gradients(disc_interplates, [interpolates])[0]\n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "        gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "\n",
    "        loss_d_tr = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_tr, labels=tf.ones_like(disc_tr)))\n",
    "        loss_d_gen = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_gen, labels=tf.zeros_like(disc_gen)))\n",
    "        loss_d = lambda_adv*(loss_d_tr + loss_d_gen)\n",
    "        loss_d += lambda_gp*gradient_penalty\n",
    "\n",
    "        loss_c_tr = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=aux_tr, labels=self.Y_tr))\n",
    "        loss_c_gen = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=aux_gen, labels=self.Y_tr))\n",
    "        loss_c = (loss_c_tr + loss_c_gen)\n",
    "\n",
    "        loss_g += loss_c\n",
    "        loss_d += loss_c\n",
    "        return loss_g, loss_d\n",
    "\n",
    "    def train(self):\n",
    "        # Optimizer\n",
    "        d_lr = 1e-4\n",
    "        d_beta1 = 0.5\n",
    "        g_lr = 1e-4\n",
    "        g_beta1 = 0.5\n",
    "\n",
    "        self.L_g, self.L_d = self.loss()\n",
    "\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate=d_lr)\n",
    "        d_train_op = d_opt.minimize(self.L_d, var_list=self.d.variables)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate=g_lr)\n",
    "        g_train_op = g_opt.minimize(self.L_g, var_list=self.g.variables)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        config = tf.ConfigProto(\n",
    "            gpu_options=tf.GPUOptions(\n",
    "                visible_device_list= \"0\"\n",
    "            )\n",
    "        )\n",
    "                \n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # preparing noise vec for test\n",
    "            bs = 100\n",
    "            test_z = np.random.uniform(-1, 1, size=[bs, self.z_size])\n",
    "\n",
    "            # cat 0\n",
    "            bs = 10\n",
    "            test_cat0_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat0_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat0_cat[:, 0] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat0_z = np.concatenate((test_cat0_rand, test_cat0_cat), axis=1)  \n",
    "\n",
    "            # cat 1\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat1_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat1_cat[:, 1] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat1_z = np.concatenate((test_cat0_rand, test_cat1_cat), axis=1)  \n",
    "\n",
    "            # cat 2\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat2_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat2_cat[:, 1] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat2_z = np.concatenate((test_cat0_rand, test_cat2_cat), axis=1)\n",
    "\n",
    "            # cat 3\n",
    "            bs = 10\n",
    "            #test_cat1_rand = np.random.uniform(-1, 1, size=[bs, self.rand_size])\n",
    "            test_cat3_cat = np.zeros([bs, self.cat_size])\n",
    "            test_cat3_cat[:, 1] = np.linspace(-1, 1, num=bs)\n",
    "            test_cat3_z = np.concatenate((test_cat0_rand, test_cat3_cat), axis=1)\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "\n",
    "                # visualize generated images during training\n",
    "                if epoch % self.epoch_saveSampleImg == 0:\n",
    "                    # rand\n",
    "                    img = sess.run(self.Xg, feed_dict={self.z: test_z})\n",
    "                    save_imgs(model_name, img, name=str(epoch)+\"_rand\")\n",
    "\n",
    "                    # cat\n",
    "                    test_cat = np.concatenate((test_cat0_z, test_cat1_z, test_cat2_z, test_cat3_z), axis=0)\n",
    "                    img = sess.run(self.Xg, feed_dict={self.z: test_cat})\n",
    "                    save_imgs(model_name, img, plot_dim=(4,10), size=(20, 8), name=str(epoch)+\"_cat\")\n",
    "\n",
    "                for step in range(self.steps):\n",
    "                    # extract images for training\n",
    "                    #rand_index = np.random.randint(0, self.dataset.shape[0], size=self.batch_size)\n",
    "                    #X_mb, Y_mb = self.dataset[rand_index, :].astype(np.float32)\n",
    "                    X_mb, Y_mb = self.irasutoya.extract(self.batch_size, self.img_size)\n",
    "                    X_mb = np.reshape(X_mb, [self.batch_size, -1])\n",
    "                    X_mb_per = X_mb + 0.5*np.std(X_mb)*np.random.random(X_mb.shape)\n",
    "\n",
    "                    rand = np.random.uniform(-1, 1, size=[self.batch_size, self.rand_size])\n",
    "                    #print(rand.shape)\n",
    "                    #print(Y_mb.shape)\n",
    "                    z = np.hstack((rand, Y_mb))\n",
    "                    #print(z.shape)\n",
    "\n",
    "                    # train Discriminator\n",
    "                    _, d_loss_value = sess.run([d_train_op, self.L_d], feed_dict={\n",
    "                        self.X_tr: X_mb,\n",
    "                        self.z:z,\n",
    "                        self.Y_tr: Y_mb,\n",
    "                        self.X_per: X_mb_per,\n",
    "                    })\n",
    "\n",
    "                # train Generator\n",
    "                _, g_loss_value = sess.run([g_train_op, self.L_g], feed_dict={\n",
    "                    self.X_tr: X_mb,\n",
    "                    self.z:z,\n",
    "                    self.Y_tr: Y_mb,\n",
    "                    self.X_per: X_mb_per,\n",
    "                })\n",
    "\n",
    "                # append loss value for visualizing\n",
    "                self.losses[\"d_loss\"].append(np.sum(d_loss_value))\n",
    "                self.losses[\"g_loss\"].append(np.sum(g_loss_value))\n",
    "                \n",
    "                # print epoch\n",
    "                if epoch % 1 == 0:\n",
    "                    print('epoch:{0}, d_loss:{1}, g_loss: {2} '.format(epoch, d_loss_value, g_loss_value))\n",
    "                \n",
    "                # visualize loss\n",
    "                if epoch % self.epoch_saveMetrics == 0:\n",
    "                    save_metrics(model_name, self.losses, epoch)\n",
    "\n",
    "\n",
    "                # save model parameters \n",
    "                if epoch % self.epoch_saveParamter == 0:\n",
    "                    dir_path = \"model_\" + model_name\n",
    "                    if not os.path.isdir(dir_path):\n",
    "                        os.makedirs(dir_path)\n",
    "\n",
    "                    saver.save(sess, dir_path + \"/\" + str(epoch) + \".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init IRASUTOYA\n",
      "1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujitoko/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:82: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, d_loss:10.717164039611816, g_loss: 0.45469027757644653 \n",
      "epoch:1, d_loss:10.66978931427002, g_loss: 0.8071359395980835 \n",
      "epoch:2, d_loss:6.59810733795166, g_loss: 1.2604871988296509 \n",
      "epoch:3, d_loss:4.8326735496521, g_loss: 5.1893744468688965 \n",
      "epoch:4, d_loss:4.323659420013428, g_loss: 0.3473781645298004 \n",
      "epoch:5, d_loss:6.667032241821289, g_loss: 0.7388228178024292 \n",
      "epoch:6, d_loss:1.5299060344696045, g_loss: 0.8058099746704102 \n",
      "epoch:7, d_loss:0.7448770999908447, g_loss: 1.3019134998321533 \n",
      "epoch:8, d_loss:0.30956876277923584, g_loss: 2.12503719329834 \n",
      "epoch:9, d_loss:0.6747624278068542, g_loss: 2.5885472297668457 \n",
      "epoch:10, d_loss:0.3586234450340271, g_loss: 4.15969705581665 \n",
      "epoch:11, d_loss:0.670871376991272, g_loss: 3.7476446628570557 \n",
      "epoch:12, d_loss:1.5405986309051514, g_loss: 1.1674647331237793 \n",
      "epoch:13, d_loss:2.2786359786987305, g_loss: 2.4205222129821777 \n",
      "epoch:14, d_loss:3.8509740829467773, g_loss: 1.8217016458511353 \n",
      "epoch:15, d_loss:2.854445457458496, g_loss: 0.8390018939971924 \n",
      "epoch:16, d_loss:3.615755319595337, g_loss: 2.785057544708252 \n",
      "epoch:17, d_loss:8.658374786376953, g_loss: 0.655158281326294 \n",
      "epoch:18, d_loss:9.700729370117188, g_loss: 0.34763607382774353 \n",
      "epoch:19, d_loss:9.473654747009277, g_loss: 0.34034013748168945 \n",
      "epoch:20, d_loss:9.265873908996582, g_loss: 0.43469369411468506 \n",
      "epoch:21, d_loss:8.518251419067383, g_loss: 0.531298816204071 \n",
      "epoch:22, d_loss:7.012516975402832, g_loss: 0.49524837732315063 \n",
      "epoch:23, d_loss:2.752302885055542, g_loss: 0.8947331309318542 \n",
      "epoch:24, d_loss:1.461061954498291, g_loss: 1.5787866115570068 \n",
      "epoch:25, d_loss:1.4757342338562012, g_loss: 1.2305362224578857 \n",
      "epoch:26, d_loss:0.5687026381492615, g_loss: 1.5699607133865356 \n",
      "epoch:27, d_loss:1.0463606119155884, g_loss: 1.1846578121185303 \n",
      "epoch:28, d_loss:2.175955295562744, g_loss: 2.2298049926757812 \n",
      "epoch:29, d_loss:2.269537925720215, g_loss: 0.7880600690841675 \n",
      "epoch:30, d_loss:2.2733349800109863, g_loss: 0.5874090194702148 \n",
      "epoch:31, d_loss:1.0627801418304443, g_loss: 1.6573824882507324 \n",
      "epoch:32, d_loss:1.1260722875595093, g_loss: 1.4436922073364258 \n",
      "epoch:33, d_loss:1.4038100242614746, g_loss: 2.4397871494293213 \n",
      "epoch:34, d_loss:0.39007920026779175, g_loss: 1.7821311950683594 \n",
      "epoch:35, d_loss:1.1245529651641846, g_loss: 2.079902410507202 \n",
      "epoch:36, d_loss:0.3727557957172394, g_loss: 2.176720142364502 \n",
      "epoch:37, d_loss:1.3675107955932617, g_loss: 4.241151809692383 \n",
      "epoch:38, d_loss:1.0763435363769531, g_loss: 1.7332234382629395 \n",
      "epoch:39, d_loss:1.414736270904541, g_loss: 6.805483818054199 \n",
      "epoch:40, d_loss:0.02154059335589409, g_loss: 4.27391242980957 \n",
      "epoch:41, d_loss:0.3029160499572754, g_loss: 5.645326137542725 \n",
      "epoch:42, d_loss:1.6932361125946045, g_loss: 1.524463176727295 \n",
      "epoch:43, d_loss:0.30997055768966675, g_loss: 4.069281578063965 \n",
      "epoch:44, d_loss:1.8006742000579834, g_loss: 1.3362895250320435 \n",
      "epoch:45, d_loss:2.6868443489074707, g_loss: 0.5506136417388916 \n",
      "epoch:46, d_loss:2.954575777053833, g_loss: 2.647036552429199 \n",
      "epoch:47, d_loss:0.3572796881198883, g_loss: 2.6258468627929688 \n",
      "epoch:48, d_loss:1.7560474872589111, g_loss: 3.660822868347168 \n",
      "epoch:49, d_loss:0.5781767964363098, g_loss: 1.9959425926208496 \n",
      "epoch:50, d_loss:0.25145700573921204, g_loss: 2.4116125106811523 \n",
      "epoch:51, d_loss:0.7443937659263611, g_loss: 3.8136990070343018 \n",
      "epoch:52, d_loss:0.39207106828689575, g_loss: 2.2954983711242676 \n",
      "epoch:53, d_loss:0.4135637879371643, g_loss: 1.9238808155059814 \n",
      "epoch:54, d_loss:1.0326429605484009, g_loss: 0.7202580571174622 \n",
      "epoch:55, d_loss:1.4466948509216309, g_loss: 2.0264663696289062 \n",
      "epoch:56, d_loss:1.4363055229187012, g_loss: 2.844414234161377 \n",
      "epoch:57, d_loss:0.49068909883499146, g_loss: 2.5554256439208984 \n",
      "epoch:58, d_loss:2.7532389163970947, g_loss: 2.030081272125244 \n",
      "epoch:59, d_loss:0.8269243836402893, g_loss: 1.3015108108520508 \n",
      "epoch:60, d_loss:1.3505746126174927, g_loss: 3.2320382595062256 \n",
      "epoch:61, d_loss:0.9678570032119751, g_loss: 0.9448582530021667 \n",
      "epoch:62, d_loss:0.5040811896324158, g_loss: 2.613949775695801 \n",
      "epoch:63, d_loss:0.3703089952468872, g_loss: 2.1206612586975098 \n",
      "epoch:64, d_loss:0.36221110820770264, g_loss: 1.8958274126052856 \n",
      "epoch:65, d_loss:0.8575378656387329, g_loss: 2.1627964973449707 \n",
      "epoch:66, d_loss:0.2615095376968384, g_loss: 2.3890533447265625 \n",
      "epoch:67, d_loss:1.4578393697738647, g_loss: 1.2807762622833252 \n",
      "epoch:68, d_loss:0.5377755165100098, g_loss: 3.3027772903442383 \n",
      "epoch:69, d_loss:0.9344547986984253, g_loss: 1.845695972442627 \n",
      "epoch:70, d_loss:0.3306316137313843, g_loss: 1.7436127662658691 \n",
      "epoch:71, d_loss:0.24503090977668762, g_loss: 4.67402458190918 \n",
      "epoch:72, d_loss:0.1076587438583374, g_loss: 3.4616003036499023 \n",
      "epoch:73, d_loss:0.19281676411628723, g_loss: 3.4492311477661133 \n",
      "epoch:74, d_loss:0.7714297771453857, g_loss: 4.45121955871582 \n",
      "epoch:75, d_loss:0.2209033966064453, g_loss: 4.498551368713379 \n",
      "epoch:76, d_loss:0.20948699116706848, g_loss: 2.9924159049987793 \n",
      "epoch:77, d_loss:0.07535336911678314, g_loss: 5.218549728393555 \n",
      "epoch:78, d_loss:0.1153179481625557, g_loss: 4.342514514923096 \n",
      "epoch:79, d_loss:0.9607517719268799, g_loss: 1.586376667022705 \n",
      "epoch:80, d_loss:0.9858332276344299, g_loss: 3.49261736869812 \n",
      "epoch:81, d_loss:0.7579993009567261, g_loss: 3.0770344734191895 \n",
      "epoch:82, d_loss:0.7058517336845398, g_loss: 6.482786178588867 \n",
      "epoch:83, d_loss:0.3777218461036682, g_loss: 2.7169952392578125 \n",
      "epoch:84, d_loss:1.2365186214447021, g_loss: 3.25341796875 \n",
      "epoch:85, d_loss:0.7954406142234802, g_loss: 2.5467092990875244 \n",
      "epoch:86, d_loss:0.5147008895874023, g_loss: 2.941035747528076 \n",
      "epoch:87, d_loss:0.3679783344268799, g_loss: 3.5518102645874023 \n",
      "epoch:88, d_loss:0.4453333914279938, g_loss: 3.309108257293701 \n",
      "epoch:89, d_loss:0.7407570481300354, g_loss: 4.478944778442383 \n",
      "epoch:90, d_loss:0.34902316331863403, g_loss: 2.1607437133789062 \n",
      "epoch:91, d_loss:0.21415406465530396, g_loss: 3.884641170501709 \n",
      "epoch:92, d_loss:0.47109362483024597, g_loss: 5.542732238769531 \n",
      "epoch:93, d_loss:0.6567695140838623, g_loss: 1.0883792638778687 \n",
      "epoch:94, d_loss:1.4124149084091187, g_loss: 5.303041934967041 \n",
      "epoch:95, d_loss:0.8410992622375488, g_loss: 1.477843165397644 \n",
      "epoch:96, d_loss:2.062298059463501, g_loss: 3.4924724102020264 \n",
      "epoch:97, d_loss:1.0714620351791382, g_loss: 3.657095193862915 \n",
      "epoch:98, d_loss:0.49470168352127075, g_loss: 3.1744234561920166 \n",
      "epoch:99, d_loss:0.6701787114143372, g_loss: 2.027568817138672 \n",
      "epoch:100, d_loss:0.7005956172943115, g_loss: 1.7417528629302979 \n",
      "epoch:101, d_loss:0.6043227910995483, g_loss: 1.0366580486297607 \n",
      "epoch:102, d_loss:0.9944584965705872, g_loss: 2.673222064971924 \n",
      "epoch:103, d_loss:1.5935673713684082, g_loss: 3.8191046714782715 \n",
      "epoch:104, d_loss:0.5494407415390015, g_loss: 2.8716866970062256 \n",
      "epoch:105, d_loss:0.6066812872886658, g_loss: 2.416433334350586 \n",
      "epoch:106, d_loss:0.33116617798805237, g_loss: 0.6980668902397156 \n",
      "epoch:107, d_loss:0.10111844539642334, g_loss: 4.5808305740356445 \n",
      "epoch:108, d_loss:1.394883155822754, g_loss: 1.84814453125 \n",
      "epoch:109, d_loss:1.6871130466461182, g_loss: 1.3369557857513428 \n",
      "epoch:110, d_loss:0.8701191544532776, g_loss: 4.026816368103027 \n",
      "epoch:111, d_loss:0.3293279707431793, g_loss: 3.9815306663513184 \n",
      "epoch:112, d_loss:1.500383973121643, g_loss: 5.352835655212402 \n",
      "epoch:113, d_loss:2.0062944889068604, g_loss: 1.2392470836639404 \n",
      "epoch:114, d_loss:1.0768532752990723, g_loss: 3.236762046813965 \n",
      "epoch:115, d_loss:1.2349764108657837, g_loss: 1.7127809524536133 \n",
      "epoch:116, d_loss:0.8227634429931641, g_loss: 1.551527500152588 \n",
      "epoch:117, d_loss:1.3899128437042236, g_loss: 3.5677735805511475 \n",
      "epoch:118, d_loss:0.542998731136322, g_loss: 1.5772887468338013 \n",
      "epoch:119, d_loss:0.20266106724739075, g_loss: 3.335598945617676 \n",
      "epoch:120, d_loss:0.09701068699359894, g_loss: 3.483747720718384 \n",
      "epoch:121, d_loss:0.22396039962768555, g_loss: 2.8761415481567383 \n",
      "epoch:122, d_loss:0.05664977431297302, g_loss: 3.9388656616210938 \n",
      "epoch:123, d_loss:0.3765079975128174, g_loss: 2.3890881538391113 \n",
      "epoch:124, d_loss:0.32978886365890503, g_loss: 2.8815441131591797 \n",
      "epoch:125, d_loss:0.3500325679779053, g_loss: 3.919934034347534 \n",
      "epoch:126, d_loss:2.0678670406341553, g_loss: 0.7423321008682251 \n",
      "epoch:127, d_loss:3.7239437103271484, g_loss: 2.532397747039795 \n",
      "epoch:128, d_loss:1.8831896781921387, g_loss: 1.4927996397018433 \n",
      "epoch:129, d_loss:1.3528697490692139, g_loss: 2.9675309658050537 \n",
      "epoch:130, d_loss:0.4591802656650543, g_loss: 2.334348678588867 \n",
      "epoch:131, d_loss:0.3234662711620331, g_loss: 5.196880340576172 \n",
      "epoch:132, d_loss:0.4830353856086731, g_loss: 2.894925832748413 \n",
      "epoch:133, d_loss:0.3616982102394104, g_loss: 2.4956612586975098 \n",
      "epoch:134, d_loss:1.0395017862319946, g_loss: 4.306349277496338 \n",
      "epoch:135, d_loss:0.21623384952545166, g_loss: 3.6618494987487793 \n",
      "epoch:136, d_loss:0.0973065048456192, g_loss: 5.707635402679443 \n",
      "epoch:137, d_loss:2.5611588954925537, g_loss: 4.819432258605957 \n",
      "epoch:138, d_loss:3.888256549835205, g_loss: 0.8212016820907593 \n",
      "epoch:139, d_loss:2.206340789794922, g_loss: 1.9823462963104248 \n",
      "epoch:140, d_loss:2.3034839630126953, g_loss: 3.095078229904175 \n",
      "epoch:141, d_loss:0.9436284303665161, g_loss: 2.130556344985962 \n",
      "epoch:142, d_loss:0.5585445165634155, g_loss: 1.4132554531097412 \n",
      "epoch:143, d_loss:0.9763692021369934, g_loss: 3.0378968715667725 \n",
      "epoch:144, d_loss:1.0630110502243042, g_loss: 2.3505334854125977 \n",
      "epoch:145, d_loss:0.4311632812023163, g_loss: 3.0457963943481445 \n",
      "epoch:146, d_loss:0.19209711253643036, g_loss: 3.697782039642334 \n",
      "epoch:147, d_loss:0.2783535420894623, g_loss: 2.7471699714660645 \n",
      "epoch:148, d_loss:0.5497400760650635, g_loss: 3.6206517219543457 \n",
      "epoch:149, d_loss:0.08808867633342743, g_loss: 3.2464380264282227 \n",
      "epoch:150, d_loss:0.13387009501457214, g_loss: 2.6397271156311035 \n",
      "epoch:151, d_loss:0.13445214927196503, g_loss: 4.186676025390625 \n",
      "epoch:152, d_loss:0.20000824332237244, g_loss: 4.004762649536133 \n",
      "epoch:153, d_loss:0.23686128854751587, g_loss: 4.140825271606445 \n",
      "epoch:154, d_loss:0.7455919981002808, g_loss: 0.8086395263671875 \n",
      "epoch:155, d_loss:4.498863697052002, g_loss: 1.6233325004577637 \n",
      "epoch:156, d_loss:1.1108992099761963, g_loss: 1.0539557933807373 \n",
      "epoch:157, d_loss:0.721461296081543, g_loss: 2.5562539100646973 \n",
      "epoch:158, d_loss:0.7563756108283997, g_loss: 2.0911705493927 \n",
      "epoch:159, d_loss:0.24135538935661316, g_loss: 2.194262742996216 \n",
      "epoch:160, d_loss:0.37917277216911316, g_loss: 2.312448024749756 \n",
      "epoch:161, d_loss:0.3079255223274231, g_loss: 2.0100512504577637 \n",
      "epoch:162, d_loss:0.32662490010261536, g_loss: 2.7484960556030273 \n",
      "epoch:163, d_loss:0.5441604852676392, g_loss: 2.482769012451172 \n",
      "epoch:164, d_loss:0.378703773021698, g_loss: 1.9951750040054321 \n",
      "epoch:165, d_loss:0.2699013650417328, g_loss: 3.5874433517456055 \n",
      "epoch:166, d_loss:0.2594062089920044, g_loss: 1.9252548217773438 \n",
      "epoch:167, d_loss:0.5137218236923218, g_loss: 3.3386127948760986 \n",
      "epoch:168, d_loss:1.1445684432983398, g_loss: 1.7786251306533813 \n",
      "epoch:169, d_loss:0.8120204210281372, g_loss: 2.258002281188965 \n",
      "epoch:170, d_loss:0.8527844548225403, g_loss: 2.4753003120422363 \n",
      "epoch:171, d_loss:0.4539722204208374, g_loss: 2.2198891639709473 \n",
      "epoch:172, d_loss:0.1449998915195465, g_loss: 3.98813533782959 \n",
      "epoch:173, d_loss:0.335299551486969, g_loss: 5.8107757568359375 \n",
      "epoch:174, d_loss:0.23190827667713165, g_loss: 3.9063191413879395 \n",
      "epoch:175, d_loss:0.059215642511844635, g_loss: 6.36169958114624 \n",
      "epoch:176, d_loss:0.14565330743789673, g_loss: 8.866996765136719 \n",
      "epoch:177, d_loss:1.0471488237380981, g_loss: 2.754563093185425 \n",
      "epoch:178, d_loss:0.201422780752182, g_loss: 5.132617950439453 \n",
      "epoch:179, d_loss:0.1235857605934143, g_loss: 2.7639644145965576 \n",
      "epoch:180, d_loss:0.31651628017425537, g_loss: 5.137599945068359 \n",
      "epoch:181, d_loss:0.28244906663894653, g_loss: 5.37803840637207 \n",
      "epoch:182, d_loss:0.4304797947406769, g_loss: 5.067893028259277 \n",
      "epoch:183, d_loss:0.08500421047210693, g_loss: 5.200397491455078 \n",
      "epoch:184, d_loss:0.40355563163757324, g_loss: 2.7398805618286133 \n",
      "epoch:185, d_loss:0.24045836925506592, g_loss: 4.655374526977539 \n",
      "epoch:186, d_loss:0.05855077505111694, g_loss: 5.8302154541015625 \n",
      "epoch:187, d_loss:0.11569786071777344, g_loss: 3.210852861404419 \n",
      "epoch:188, d_loss:0.3675328493118286, g_loss: 3.0675268173217773 \n",
      "epoch:189, d_loss:0.14950929582118988, g_loss: 5.269809722900391 \n",
      "epoch:190, d_loss:0.2813408672809601, g_loss: 5.955319404602051 \n",
      "epoch:191, d_loss:0.8568156361579895, g_loss: 3.165571689605713 \n",
      "epoch:192, d_loss:0.3546934425830841, g_loss: 3.0982825756073 \n",
      "epoch:193, d_loss:0.6291055083274841, g_loss: 5.454893589019775 \n",
      "epoch:194, d_loss:0.41892510652542114, g_loss: 5.05405855178833 \n",
      "epoch:195, d_loss:0.9803651571273804, g_loss: 1.8582230806350708 \n",
      "epoch:196, d_loss:1.4078989028930664, g_loss: 2.4602577686309814 \n",
      "epoch:197, d_loss:1.1648623943328857, g_loss: 4.238668918609619 \n",
      "epoch:198, d_loss:1.2987122535705566, g_loss: 0.9122869968414307 \n",
      "epoch:199, d_loss:0.6501948833465576, g_loss: 2.645951271057129 \n",
      "epoch:200, d_loss:0.26277273893356323, g_loss: 3.5584158897399902 \n",
      "epoch:201, d_loss:0.08066976070404053, g_loss: 3.165050745010376 \n",
      "epoch:202, d_loss:0.4070868492126465, g_loss: 3.0958199501037598 \n",
      "epoch:203, d_loss:0.32179808616638184, g_loss: 3.836900472640991 \n",
      "epoch:204, d_loss:0.4289672076702118, g_loss: 2.483412027359009 \n",
      "epoch:205, d_loss:0.02440987527370453, g_loss: 7.109862327575684 \n",
      "epoch:206, d_loss:0.3160097897052765, g_loss: 2.5893988609313965 \n",
      "epoch:207, d_loss:0.18993988633155823, g_loss: 3.984158515930176 \n",
      "epoch:208, d_loss:0.5084668397903442, g_loss: 5.7152228355407715 \n",
      "epoch:209, d_loss:0.24678879976272583, g_loss: 3.2322769165039062 \n",
      "epoch:210, d_loss:0.10990995168685913, g_loss: 4.181411266326904 \n",
      "epoch:211, d_loss:0.2272999882698059, g_loss: 3.1340219974517822 \n",
      "epoch:212, d_loss:0.40606653690338135, g_loss: 2.3137459754943848 \n",
      "epoch:213, d_loss:0.9117353558540344, g_loss: 1.1965816020965576 \n",
      "epoch:214, d_loss:0.25829797983169556, g_loss: 4.46437931060791 \n",
      "epoch:215, d_loss:0.20658810436725616, g_loss: 3.3567662239074707 \n",
      "epoch:216, d_loss:0.14324058592319489, g_loss: 2.6169424057006836 \n",
      "epoch:217, d_loss:0.4382844567298889, g_loss: 2.6122655868530273 \n",
      "epoch:218, d_loss:0.5191720724105835, g_loss: 1.4156702756881714 \n",
      "epoch:219, d_loss:0.04635865241289139, g_loss: 4.347629547119141 \n",
      "epoch:220, d_loss:0.09246158599853516, g_loss: 2.6253557205200195 \n",
      "epoch:221, d_loss:1.0670504570007324, g_loss: 2.833763360977173 \n",
      "epoch:222, d_loss:0.17497886717319489, g_loss: 3.954439163208008 \n",
      "epoch:223, d_loss:0.3711506128311157, g_loss: 3.0310206413269043 \n",
      "epoch:224, d_loss:0.8171516060829163, g_loss: 2.8332605361938477 \n",
      "epoch:225, d_loss:1.2360748052597046, g_loss: 2.9829578399658203 \n",
      "epoch:226, d_loss:0.13214346766471863, g_loss: 4.061777114868164 \n",
      "epoch:227, d_loss:2.236713171005249, g_loss: 0.6404314041137695 \n",
      "epoch:228, d_loss:2.15179443359375, g_loss: 3.315950870513916 \n",
      "epoch:229, d_loss:0.4679710865020752, g_loss: 4.1286516189575195 \n",
      "epoch:230, d_loss:0.371493399143219, g_loss: 2.8748111724853516 \n",
      "epoch:231, d_loss:0.1968235969543457, g_loss: 3.745218276977539 \n",
      "epoch:232, d_loss:0.29638153314590454, g_loss: 3.928758144378662 \n",
      "epoch:233, d_loss:0.12551212310791016, g_loss: 3.8174173831939697 \n",
      "epoch:234, d_loss:0.08171384781599045, g_loss: 5.347031593322754 \n",
      "epoch:235, d_loss:0.27728593349456787, g_loss: 3.987459897994995 \n",
      "epoch:236, d_loss:0.26037025451660156, g_loss: 5.337210655212402 \n",
      "epoch:237, d_loss:0.04168090596795082, g_loss: 5.387823581695557 \n",
      "epoch:238, d_loss:0.4498390555381775, g_loss: 4.330897331237793 \n",
      "epoch:239, d_loss:0.6083054542541504, g_loss: 2.587355136871338 \n",
      "epoch:240, d_loss:0.19594994187355042, g_loss: 3.1085104942321777 \n",
      "epoch:241, d_loss:1.4101519584655762, g_loss: 2.3480794429779053 \n",
      "epoch:242, d_loss:0.5293982028961182, g_loss: 3.3478951454162598 \n",
      "epoch:243, d_loss:0.48966121673583984, g_loss: 5.781130313873291 \n",
      "epoch:244, d_loss:0.21719717979431152, g_loss: 4.194482803344727 \n",
      "epoch:245, d_loss:0.24836719036102295, g_loss: 2.9628748893737793 \n",
      "epoch:246, d_loss:0.7287784814834595, g_loss: 3.6183037757873535 \n",
      "epoch:247, d_loss:1.151938796043396, g_loss: 1.6912117004394531 \n",
      "epoch:248, d_loss:0.03288502246141434, g_loss: 7.009799957275391 \n",
      "epoch:249, d_loss:0.09407851099967957, g_loss: 2.0674262046813965 \n",
      "epoch:250, d_loss:0.24295103549957275, g_loss: 4.561675071716309 \n",
      "epoch:251, d_loss:0.12311358749866486, g_loss: 5.590257167816162 \n",
      "epoch:252, d_loss:0.18839657306671143, g_loss: 4.4480204582214355 \n",
      "epoch:253, d_loss:0.0808512419462204, g_loss: 3.3378219604492188 \n",
      "epoch:254, d_loss:0.38164693117141724, g_loss: 4.5114850997924805 \n",
      "epoch:255, d_loss:0.043743811547756195, g_loss: 5.754994869232178 \n",
      "epoch:256, d_loss:0.19288651645183563, g_loss: 4.538221836090088 \n",
      "epoch:257, d_loss:0.30405744910240173, g_loss: 3.7911505699157715 \n",
      "epoch:258, d_loss:0.6983814239501953, g_loss: 3.495408535003662 \n",
      "epoch:259, d_loss:0.711910605430603, g_loss: 3.5206737518310547 \n",
      "epoch:260, d_loss:0.193105086684227, g_loss: 2.3548755645751953 \n",
      "epoch:261, d_loss:0.38104215264320374, g_loss: 4.064190864562988 \n",
      "epoch:262, d_loss:0.6892796158790588, g_loss: 2.5374093055725098 \n",
      "epoch:263, d_loss:0.2672284245491028, g_loss: 2.4966273307800293 \n",
      "epoch:264, d_loss:0.9923942685127258, g_loss: 2.142812728881836 \n",
      "epoch:265, d_loss:0.572157621383667, g_loss: 1.543687343597412 \n",
      "epoch:266, d_loss:0.7492769360542297, g_loss: 2.656571388244629 \n",
      "epoch:267, d_loss:0.1880701631307602, g_loss: 3.2271628379821777 \n",
      "epoch:268, d_loss:0.10453212261199951, g_loss: 3.3470537662506104 \n",
      "epoch:269, d_loss:0.20099283754825592, g_loss: 3.703638792037964 \n",
      "epoch:270, d_loss:0.13299554586410522, g_loss: 2.974555492401123 \n",
      "epoch:271, d_loss:0.0914868712425232, g_loss: 3.5875205993652344 \n",
      "epoch:272, d_loss:0.1179790198802948, g_loss: 3.5637784004211426 \n",
      "epoch:273, d_loss:0.266125351190567, g_loss: 2.763702869415283 \n",
      "epoch:274, d_loss:0.4082631766796112, g_loss: 4.726972579956055 \n",
      "epoch:275, d_loss:0.13188625872135162, g_loss: 2.598280191421509 \n",
      "epoch:276, d_loss:0.2586720585823059, g_loss: 3.041163206100464 \n",
      "epoch:277, d_loss:0.12327884137630463, g_loss: 4.263484001159668 \n",
      "epoch:278, d_loss:0.44958364963531494, g_loss: 1.9651457071304321 \n",
      "epoch:279, d_loss:1.168656826019287, g_loss: 5.673983097076416 \n",
      "epoch:280, d_loss:0.5684097409248352, g_loss: 1.6862529516220093 \n",
      "epoch:281, d_loss:0.08639709651470184, g_loss: 4.666906833648682 \n",
      "epoch:282, d_loss:0.07299324125051498, g_loss: 4.175431251525879 \n",
      "epoch:283, d_loss:0.05405529960989952, g_loss: 3.708704948425293 \n",
      "epoch:284, d_loss:0.7383724451065063, g_loss: 3.369797945022583 \n",
      "epoch:285, d_loss:0.08355855941772461, g_loss: 2.8060436248779297 \n",
      "epoch:286, d_loss:0.08763635158538818, g_loss: 3.182028293609619 \n",
      "epoch:287, d_loss:0.05786357820034027, g_loss: 4.058224678039551 \n",
      "epoch:288, d_loss:0.5051929950714111, g_loss: 4.287707805633545 \n",
      "epoch:289, d_loss:0.09857940673828125, g_loss: 3.1637794971466064 \n",
      "epoch:290, d_loss:0.05693595111370087, g_loss: 3.6941933631896973 \n",
      "epoch:291, d_loss:0.057934120297431946, g_loss: 4.689449310302734 \n",
      "epoch:292, d_loss:0.06759820878505707, g_loss: 5.1429948806762695 \n",
      "epoch:293, d_loss:0.061739951372146606, g_loss: 3.117124319076538 \n",
      "epoch:294, d_loss:0.08620104193687439, g_loss: 3.313352108001709 \n",
      "epoch:295, d_loss:0.09472998976707458, g_loss: 2.672542095184326 \n",
      "epoch:296, d_loss:0.0928741842508316, g_loss: 4.715221881866455 \n",
      "epoch:297, d_loss:0.6581792235374451, g_loss: 1.8959789276123047 \n",
      "epoch:298, d_loss:0.4699174165725708, g_loss: 4.167719841003418 \n",
      "epoch:299, d_loss:0.19630727171897888, g_loss: 3.399170160293579 \n",
      "epoch:300, d_loss:0.8857303857803345, g_loss: 2.649312734603882 \n",
      "epoch:301, d_loss:0.8881897330284119, g_loss: 0.8340575695037842 \n",
      "epoch:302, d_loss:0.20110777020454407, g_loss: 3.1514086723327637 \n",
      "epoch:303, d_loss:2.1098785400390625, g_loss: 1.2564647197723389 \n",
      "epoch:304, d_loss:1.1740844249725342, g_loss: 3.345486640930176 \n",
      "epoch:305, d_loss:0.9992399215698242, g_loss: 4.08444881439209 \n",
      "epoch:306, d_loss:0.7370264530181885, g_loss: 1.051820993423462 \n",
      "epoch:307, d_loss:0.3267059922218323, g_loss: 3.853461503982544 \n",
      "epoch:308, d_loss:0.4337233901023865, g_loss: 2.3822922706604004 \n",
      "epoch:309, d_loss:0.22868110239505768, g_loss: 2.630375385284424 \n",
      "epoch:310, d_loss:1.8137331008911133, g_loss: 1.6406316757202148 \n",
      "epoch:311, d_loss:0.07907591015100479, g_loss: 3.813918113708496 \n",
      "epoch:312, d_loss:0.31178876757621765, g_loss: 2.507901430130005 \n",
      "epoch:313, d_loss:0.2272190898656845, g_loss: 3.8008742332458496 \n",
      "epoch:314, d_loss:0.19899819791316986, g_loss: 3.0617101192474365 \n",
      "epoch:315, d_loss:1.3278687000274658, g_loss: 3.9029414653778076 \n",
      "epoch:316, d_loss:0.3929072916507721, g_loss: 3.478522300720215 \n",
      "epoch:317, d_loss:0.13349613547325134, g_loss: 2.617940902709961 \n",
      "epoch:318, d_loss:0.7645249962806702, g_loss: 2.731839656829834 \n",
      "epoch:319, d_loss:0.7104644179344177, g_loss: 2.136924982070923 \n",
      "epoch:320, d_loss:0.2001934051513672, g_loss: 4.9192023277282715 \n",
      "epoch:321, d_loss:0.7067939639091492, g_loss: 4.2030348777771 \n",
      "epoch:322, d_loss:0.13487710058689117, g_loss: 4.805882453918457 \n",
      "epoch:323, d_loss:1.3513113260269165, g_loss: 1.4176808595657349 \n",
      "epoch:324, d_loss:0.27254053950309753, g_loss: 2.5188772678375244 \n",
      "epoch:325, d_loss:0.3984372317790985, g_loss: 2.226536750793457 \n",
      "epoch:326, d_loss:0.8637831211090088, g_loss: 2.2993807792663574 \n",
      "epoch:327, d_loss:0.5210510492324829, g_loss: 3.2144339084625244 \n",
      "epoch:328, d_loss:0.3721344470977783, g_loss: 2.594390869140625 \n",
      "epoch:329, d_loss:0.11248607933521271, g_loss: 3.8411221504211426 \n",
      "epoch:330, d_loss:0.23281309008598328, g_loss: 4.931342601776123 \n",
      "epoch:331, d_loss:0.772411584854126, g_loss: 1.8077436685562134 \n",
      "epoch:332, d_loss:0.526179850101471, g_loss: 2.075688362121582 \n",
      "epoch:333, d_loss:0.1517551690340042, g_loss: 4.781519889831543 \n",
      "epoch:334, d_loss:0.21119967103004456, g_loss: 5.3152384757995605 \n",
      "epoch:335, d_loss:0.13367190957069397, g_loss: 4.076798439025879 \n",
      "epoch:336, d_loss:0.21440322697162628, g_loss: 4.187993049621582 \n",
      "epoch:337, d_loss:0.04593006521463394, g_loss: 4.016950607299805 \n",
      "epoch:338, d_loss:0.05550123751163483, g_loss: 4.743387699127197 \n",
      "epoch:339, d_loss:0.6146237254142761, g_loss: 2.2983460426330566 \n",
      "epoch:340, d_loss:0.05169632285833359, g_loss: 7.222146987915039 \n",
      "epoch:341, d_loss:0.08615438640117645, g_loss: 3.6542234420776367 \n"
     ]
    }
   ],
   "source": [
    "gan = GAN()\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
