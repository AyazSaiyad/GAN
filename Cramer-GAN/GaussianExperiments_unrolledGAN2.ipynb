{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of Gaussian Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# utility func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_plot(x, epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"gaussian\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)    \n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(x[:,0],x[:,1],s=2, color=matplotlib.colors.cnames[\"orangered\"])\n",
    "    plt.ylim(-4.0, 4.0)\n",
    "    plt.xlim(-4.0, 4.0)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"gaussian\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def kdeplot(x, epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"kdeplot\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)    \n",
    "    ax = plt.figure()\n",
    "    ax = sns.kdeplot(x[:,0], x[:,1], shade=True, cmap=\"Greens\",n_levels=20, clip=[[-2, 2]]*2)\n",
    "    bg_color = sns.color_palette(\"Greens\", n_colors=256)[0]\n",
    "    ax.set_axis_bgcolor(bg_color)\n",
    "    ax.savefig(os.path.join(path, \"gaussian\" + str(epoch) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save metrics\n",
    "def save_metrics(metrics, epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"metrics\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # save metrics\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"dis_loss\"], label=\"discriminative loss\", color=\"b\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"dloss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"gen_loss\"], label=\"generative loss\", color=\"r\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"g_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"gen_loss\"], label=\"generative loss\", color=\"r\")\n",
    "    plt.plot(metrics[\"dis_loss\"], label=\"discriminative loss\", color=\"b\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"both_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot images\n",
    "def save_imgs(images, plot_dim=(5,12), size=(12,5), epoch=None):\n",
    "    # make directory if there is not\n",
    "    path = \"generated_figures\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    num_examples = plot_dim[0]*plot_dim[1]\n",
    "    num_examples = 60\n",
    "    fig = plt.figure(figsize=size)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(plot_dim[0], plot_dim[1], i+1)\n",
    "        img = images[i, :]\n",
    "        img = img.reshape((96, 96, 3))\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(os.path.join(path, str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(x, output_shape, name):\n",
    "    shape = x.get_shape().as_list()\n",
    "    dim = np.prod(shape[1:])\n",
    "    x = tf.reshape(x, [-1, dim])\n",
    "    input_shape = dim\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.001)\n",
    "    with tf.variable_scope(name):\n",
    "        weight = tf.get_variable(\"weight\", shape=[input_shape, output_shape], initializer=initializer)\n",
    "        x = tf.matmul(x, weight)\n",
    "\n",
    "        bias = tf.get_variable(\"bias\", shape=[output_shape], initializer=tf.constant_initializer(0.))\n",
    "        x = tf.nn.bias_add(x, bias)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def gaussian_mixture_circle(batch_size, num_cluster=8, scale=2, std=0.2):\n",
    "    rand_indices = np.random.randint(0, num_cluster, size=batch_size)\n",
    "    base_angle = math.pi * 2 / num_cluster\n",
    "    angle = rand_indices * base_angle - math.pi / 2\n",
    "    mean = np.zeros((batch_size, 2), dtype=np.float32)\n",
    "    mean[:, 0] = np.cos(angle) * scale\n",
    "    mean[:, 1] = np.sin(angle) * scale\n",
    "    return np.random.normal(mean, std**2, (batch_size, 2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self):\n",
    "        self.reuse = False\n",
    "        self.z_dim = 256\n",
    "        self.h_dim = 128\n",
    "        self.o_dim = 2\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            with tf.variable_scope(\"fc1\"):\n",
    "                weight = tf.get_variable(\"W\", shape=[self.z_dim, self.h_dim], initializer=self.initializer)\n",
    "                bias = tf.get_variable(\"b\", shape=[self.h_dim], initializer=self.initializer)\n",
    "                x = tf.matmul(x, weight) + bias\n",
    "                #x = tf.nn.relu(x)\n",
    "                x = tf.nn.tanh(x)\n",
    "\n",
    "            with tf.variable_scope(\"fc2\"):\n",
    "                weight = tf.get_variable(\"W\", shape=[self.h_dim, self.o_dim], initializer=self.initializer)\n",
    "                bias = tf.get_variable(\"b\", shape=[self.o_dim], initializer=self.initializer)\n",
    "                x = tf.matmul(x, weight) + bias\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, batch_size=64):\n",
    "        self.reuse = False\n",
    "#        self.initializer = tf.truncated_normal(stddev=0.8)\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "        self.X_dim = 2\n",
    "        self.h_dim = 128\n",
    "        self.o_dim = 1\n",
    "        \n",
    "    def __call__(self, x, training=False, name=''):\n",
    "        with tf.name_scope('d' + name), tf.variable_scope('d', reuse=self.reuse):\n",
    "            x = x * 0.25\n",
    "\n",
    "            with tf.variable_scope(\"fc1\"):\n",
    "                weight = tf.get_variable(\"W\", shape=[self.X_dim, self.h_dim], initializer=self.initializer)\n",
    "                bias = tf.get_variable(\"b\", shape=[self.h_dim], initializer=self.initializer)\n",
    "                x = tf.matmul(x, weight) + bias\n",
    "                x = tf.nn.tanh(x)\n",
    "\n",
    "            with tf.variable_scope(\"fc2\"):\n",
    "                weight = tf.get_variable(\"W\", shape=[self.h_dim, self.o_dim], initializer=self.initializer)\n",
    "                bias = tf.get_variable(\"b\", shape=[self.o_dim], initializer=self.initializer)\n",
    "                x = tf.matmul(x, weight) + bias\n",
    "#                x = tf.nn.tanh(x)\n",
    "                \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        self.g = Generator()\n",
    "        self.d = Discriminator()\n",
    "        self.z_dim = 256\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch_save_gauss = np.array([0, 1, 5, 10, 20, 50, 100])*1000\n",
    "        self.epoch_save_metrics = 5000\n",
    "        self.losses = {\"dis_loss\":[], \"gen_loss\":[]}\n",
    "        self.gaussians = []\n",
    "\n",
    "    def loss(self, y, y_gen):\n",
    "        \n",
    "        d_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=tf.ones_like(y))) + tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_gen, labels=tf.zeros_like(y_gen))) # 怪しい\n",
    "        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_gen, labels=tf.ones_like(y_gen)))    # 怪しい\n",
    "        #d_loss = -tf.reduce_mean(tf.log(y) + tf.log(1. - y_gen)) \n",
    "        #g_loss = tf.reduce_mean(tf.log(1-y_gen))\n",
    "        return g_loss, d_loss\n",
    "\n",
    "    def train(self, batch_size=64, epochs=100001):\n",
    "        z = tf.placeholder(tf.float32, shape=[None, self.z_dim])\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "        x_gen = self.g(z)\n",
    "        y = self.d(x)\n",
    "        y_gen = self.d(x_gen)\n",
    "        g_loss, d_loss = self.loss(y, y_gen)\n",
    "        \n",
    "        #t_vars = tf.global_variables()\n",
    "        #g_vars = [var for var in t_vars if \"g\" in var.name]\n",
    "        #d_vars = [var for var in t_vars if \"d\" in var.name]\n",
    "\n",
    "        opt_d = tf.train.AdamOptimizer(1e-4, beta1=0.5).minimize(d_loss, var_list=self.d.variables)\n",
    "        opt_g = tf.train.AdamOptimizer(1e-4, beta1=0.5).minimize(g_loss, var_list=self.g.variables)\n",
    "\n",
    "        z_fix = np.random.uniform(-1, 1, size=[1024, self.z_dim])\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            steps = 10\n",
    "            for step in range(steps):\n",
    "                # 潜在変数と生成データ\n",
    "                z_gen = np.random.uniform(-1, 1, size=[self.batch_size, self.z_dim])\n",
    "                # 訓練データを生成\n",
    "                X_tr = gaussian_mixture_circle(self.batch_size)\n",
    "                _, gen_loss = self.sess.run([opt_g, g_loss], feed_dict={z: z_gen, x: X_tr})             \n",
    "                _, dis_loss = self.sess.run([opt_d, d_loss], feed_dict={z: z_gen, x: X_tr})\n",
    "                if step == 0:\n",
    "                    dis_var = self.sess.run(self.d.variables)\n",
    "                \n",
    "            np_dis_var = np.array(dis_var)\n",
    "            for (dst, src) in zip(self.d.variables, np_dis_var):\n",
    "                dst = src\n",
    "\n",
    "            self.sess.run(self.d.variables)\n",
    "            del np_dis_var\n",
    "\n",
    "            self.losses[\"dis_loss\"].append(dis_loss)\n",
    "            self.losses[\"gen_loss\"].append(gen_loss)\n",
    "            \n",
    "            if epoch in self.epoch_save_gauss:\n",
    "\n",
    "                x_ = self.sess.run(x_gen, feed_dict={z: z_fix})\n",
    "                self.gaussians.append(x_)\n",
    "                print(epoch)\n",
    "\n",
    "            if epoch % self.epoch_save_metrics == 0:\n",
    "                save_metrics(self.losses, epoch)\n",
    "            \n",
    "        x_tr = gaussian_mixture_circle(1024)\n",
    "        self.gaussians.append(x_tr)\n",
    "\n",
    "    def sample_images(self, row=5, col=12, inputs=None, epoch=None):\n",
    "        images = self.g(inputs, training=True)\n",
    "        return images\n",
    "\n",
    "    def save_gauss_dist(self):\n",
    "        i = 0\n",
    "        for gauss in self.gaussians:\n",
    "            i+=1\n",
    "            save_plot(gauss, str(i))\n",
    "\n",
    "    def save_gauss_dists(self):\n",
    "        path = \"gaussian_unrolled\"\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 2))\n",
    "        epochs = self.epoch_save_gauss = np.array([0, 1, 5, 10, 20, 50, 100, \"target\"])\n",
    "        i = 0\n",
    "        print(len(self.gaussians))\n",
    "        for x in self.gaussians:\n",
    "\n",
    "            ax = fig.add_subplot(1, len(self.gaussians), i+1)\n",
    "            ax.scatter(x[:,0],x[:,1],s=2, color=matplotlib.colors.cnames[\"darkorange\"], alpha=0.3)\n",
    "\n",
    "            if i==0:\n",
    "                ax.set_ylabel(\"vanilla GAN\")\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_ylim(-4.0, 4.0)\n",
    "            ax.set_xlim(-4.0, 4.0)   \n",
    "            print(i)\n",
    "            if i < 7:\n",
    "                ax.patch.set_facecolor(matplotlib.colors.cnames[\"whitesmoke\"])\n",
    "                ax.set_title('epoch: ' + str(epochs[i]) + \"k\")\n",
    "            else:\n",
    "                ax.patch.set_facecolor(matplotlib.colors.cnames[\"lightgrey\"])   \n",
    "                ax.set_title('target')\n",
    "            i += 1\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()   \n",
    "        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.09, hspace=0.07)\n",
    "        plt.axvline(x=-4.0)\n",
    "\n",
    "        plt.savefig(os.path.join(path, \"gaussian_dist.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujitoko/anaconda3/lib/python3.6/site-packages/matplotlib/transforms.py:661: RuntimeWarning: invalid value encountered in absolute\n",
      "  inside = ((abs(dx0 + dx1) + abs(dy0 + dy1)) == 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "5000\n",
      "10000\n",
      "20000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a071ffd52526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_gauss_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_gauss_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-81231529d9e5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch_size, epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# 訓練データを生成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mX_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_mixture_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ujitoko/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ujitoko/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ujitoko/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ujitoko/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ujitoko/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gan = GAN()\n",
    "    gan.train()\n",
    "    gan.save_gauss_dist()\n",
    "    gan.save_gauss_dists()\n",
    "#    gan.g()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
