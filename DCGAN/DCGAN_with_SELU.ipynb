{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN implementation by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# utility関数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_metrics(metrics, epoch=None):\n",
    "    path = \"metrics\"\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"d_loss\"], label=\"discriminative loss\", color=\"b\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"dloss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"g_loss\"], label=\"generative loss\", color=\"r\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"g_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(metrics[\"g_loss\"], label=\"generative loss\", color=\"r\")\n",
    "    plt.plot(metrics[\"d_loss\"], label=\"discriminative loss\", color=\"b\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"both_loss\" + str(epoch) + \".png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# noise[[examples, 100]]から生成した画像をplot_dim(例えば4x4)で表示\n",
    "def save_imgs(images, plot_dim=(5,12), size=(24,10), epoch=None):\n",
    "    path = \"generated_figures\"\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    examples = plot_dim[0]*plot_dim[1]\n",
    "    \n",
    "    # 表示\n",
    "    fig = plt.figure(figsize=size)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(plot_dim[0], plot_dim[1], i+1)\n",
    "        img = images[i, :]\n",
    "        img = img.reshape((128, 128, 3))\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig(os.path.join(path, str(epoch) + \".png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selu(x):\n",
    "    #with ops.name_scope('elu') as scope:\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, img_size, isBN):\n",
    "        self.img_size = img_size\n",
    "        self.G_h_size = 64\n",
    "        self.reuse = False\n",
    "        self.isBN = isBN\n",
    "        self.z_dim = 100\n",
    "\n",
    "    def __call__(self, x, training=False):\n",
    "        mult = self.img_size//8\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        with tf.variable_scope('g', reuse=self.reuse):\n",
    "            # reshape from inputs\n",
    "            with tf.variable_scope('reshape'):\n",
    "                ## start\n",
    "                outputs = tf.layers.dense(x, self.z_dim*2*2, kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                outputs = tf.reshape(outputs, [-1, 2, 2, self.z_dim])\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, self.G_h_size*mult, [4,4], strides=(2,2), padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02)) # 4x4\n",
    "                if self.isBN == True:\n",
    "                    outputs = tf.layers.batch_normalization(outputs)\n",
    "                    outputs = tf.nn.relu(outputs)\n",
    "                else:\n",
    "                    outputs = selu(outputs)\n",
    "\n",
    "                ## middle [4, 8, 16, 32, 64, 128, 256, 512] 8\n",
    "                while mult > 1:\n",
    "                    outputs = tf.layers.conv2d_transpose(outputs, self.G_h_size*(mult//2), [4,4], strides=(2,2), padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                    if self.isBN == True:\n",
    "                        outputs = tf.layers.batch_normalization(outputs)\n",
    "                        outputs = tf.nn.relu(outputs)\n",
    "                    else:\n",
    "                        outputs = selu(outputs)\n",
    "                    mult = mult//2\n",
    "\n",
    "                ## end\n",
    "                outputs = tf.layers.conv2d_transpose(outputs, 3, [4,4], strides=(2,2), padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                outputs = tf.nn.tanh(outputs)\n",
    "\n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, img_size, isBN):\n",
    "        self.reuse = False\n",
    "        self.D_h_size = 64\n",
    "        self.img_size = img_size\n",
    "        self.isBN = isBN\n",
    "\n",
    "    def __call__(self, inputs, training=False, name=''):\n",
    "        def leaky_relu(x, leak=0.2):\n",
    "            return tf.maximum(x, x * leak)\n",
    "        outputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "        with tf.name_scope('d' + name), tf.variable_scope('d', reuse=self.reuse):\n",
    "            # convolution x 4\n",
    "            ## start\n",
    "            outputs = tf.reshape(outputs, [-1, self.img_size, self.img_size, 3])\n",
    "            outputs = tf.layers.conv2d(outputs, self.D_h_size, [4, 4], strides=2, padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "\n",
    "            if self.isBN == True:\n",
    "                outputs = tf.layers.batch_normalization(outputs)\n",
    "                outputs = leaky_relu(outputs)\n",
    "            else:\n",
    "                outputs = selu(outputs)\n",
    "\n",
    "            img_size_new = self.img_size//2\n",
    "            mult = 1\n",
    "\n",
    "            ## middle\n",
    "            while img_size_new > 4:\n",
    "                outputs = tf.layers.conv2d(outputs, self.D_h_size*(2*mult), [4, 4], strides=2, padding=\"SAME\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "                if self.isBN == True:\n",
    "                    outputs = tf.layers.batch_normalization(outputs)\n",
    "                    outputs = leaky_relu(outputs)\n",
    "                else:\n",
    "                    outputs = selu(outputs)\n",
    "\n",
    "                mult = mult*2\n",
    "                img_size_new = img_size_new//2\n",
    "            \n",
    "            ## end\n",
    "            outputs = tf.layers.conv2d(outputs, 1, [4, 4], strides=1, padding=\"VALID\", kernel_initializer=tf.truncated_normal_initializer(0.0, 0.02))\n",
    "            #outputs = tf.layers.dense(outputs, 1)\n",
    "            print(outputs.get_shape())\n",
    "            outputs = tf.nn.sigmoid(outputs)\n",
    "            \n",
    "        self.reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.img_size = 128\n",
    "        self.z_dim = 100\n",
    "\n",
    "        self.epochs = 1000000\n",
    "        self.epoch_saveMetrics = 200\n",
    "        self.epoch_saveSampleImg = 200\n",
    "        self.epoch_saveParamter = 10000\n",
    "        self.losses = {\"d_loss\":[], \"g_loss\":[]}\n",
    "\n",
    "        self.X_tr = tf.placeholder(tf.float32, shape=[None, self.img_size, self.img_size, 3])\n",
    "        self.Z1 = tf.placeholder(tf.float32, [None, self.z_dim])\n",
    "        \n",
    "        self.isBN = False\n",
    "\n",
    "        self.g = Generator(self.img_size, self.isBN)\n",
    "        self.d = Discriminator(self.img_size, self.isBN)\n",
    "        self.Xg = self.g(self.Z1)\n",
    "\n",
    "    def loss(self):\n",
    "        Dr = self.d(self.X_tr)\n",
    "        Dg = self.d(self.Xg)\n",
    "\n",
    "        L_d = -tf.reduce_mean(tf.log(Dr) + tf.log(1. - Dg))\n",
    "        L_g = -tf.reduce_mean(tf.log(Dg))\n",
    "\n",
    "        return L_g, L_d\n",
    "\n",
    "    def train(self):\n",
    "        # Optimizer\n",
    "        d_lr = 5e-5\n",
    "        g_lr =  2e-4\n",
    "        #d_lr = 2e-4\n",
    "        #g_lr = 2e-4\n",
    "        beta1 = 0.5\n",
    "        beta2 = 0.9\n",
    "\n",
    "        self.L_g, self.L_d = self.loss()\n",
    "\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate=d_lr, beta1=beta1, beta2=beta2)\n",
    "        d_train_op = d_opt.minimize(self.L_d, var_list=self.d.variables)\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate=g_lr, beta1=beta1, beta2=beta2)\n",
    "        g_train_op = g_opt.minimize(self.L_g, var_list=self.g.variables)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        #%debug\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            z_test = np.random.uniform(-1, 1, size=[60, self.z_dim])\n",
    "\n",
    "            for epoch in range(self.epochs):\n",
    "\n",
    "                # X_mb\n",
    "                def extractXimg(path, batch_size):\n",
    "                    imgs = os.listdir(path)\n",
    "                    rand_id = np.random.randint(0, len(imgs), size=batch_size)\n",
    "                    X_mb = np.zeros((1, self.img_size, self.img_size, 3))\n",
    "\n",
    "                    for i in range(batch_size):\n",
    "                        img = Image.open(path+\"/\"+imgs[rand_id[i]])\n",
    "\n",
    "                        img_np = np.asarray(img)\n",
    "                        img_np_copied = np.copy(img_np[:,:,0:3])\n",
    "\n",
    "                        for x in range(img.size[0]): \n",
    "                            for y in range(img.size[1]):\n",
    "                                if img_np[x][y][3] < 255:    # check alpha\n",
    "                                    img_np_copied[x][y] = (255,255,255)\n",
    "                                    #img_np_copied[x][y] = (0, 0, 0)\n",
    "\n",
    "                        if (i==0)and (epoch % 10==1):\n",
    "                            %matplotlib inline\n",
    "                            plt.imshow(img_np_copied)\n",
    " \n",
    "                        X_mb = np.vstack((X_mb, img_np_copied[np.newaxis, :]))\n",
    "                        img.close()\n",
    "                    X_mb = X_mb[1:,:]\n",
    "                    return X_mb\n",
    "                \n",
    "                for _ in range(1):\n",
    "                    # 訓練データを抜粋\n",
    "                    z1 = np.random.uniform(-1, 1, size=[self.batch_size, self.z_dim])\n",
    "\n",
    "                    X_mb = extractXimg(str(self.img_size) + \"x\" + str(self.img_size) + \"x3resized_faceimgs\", self.batch_size).astype(np.float32)\n",
    "\n",
    "                    X_mb = X_mb/255\n",
    "                    \n",
    "                    _, d_loss_value = sess.run([d_train_op, self.L_d], feed_dict={self.X_tr: X_mb, self.Z1:z1})\n",
    "\n",
    "                # train G\n",
    "                _, g_loss_value = sess.run([g_train_op, self.L_g], feed_dict={self.X_tr: X_mb, self.Z1: z1})\n",
    "\n",
    "                # 結果をappend\n",
    "                self.losses[\"d_loss\"].append(np.sum(d_loss_value))\n",
    "                self.losses[\"g_loss\"].append(np.sum(g_loss_value))\n",
    "                \n",
    "                if epoch % 100 == 0:\n",
    "                    print(\"epoch:\" + str(epoch))\n",
    "\n",
    "                # lossの可視化\n",
    "                if epoch % self.epoch_saveMetrics == 1:\n",
    "                    save_metrics(self.losses, epoch)\n",
    "\n",
    "                # 画像の変換テスト\n",
    "                if epoch % self.epoch_saveSampleImg == 0:\n",
    "                    img = sess.run(self.Xg, feed_dict={self.Z1: z_test})\n",
    "                    save_imgs(img, epoch=str(epoch))\n",
    "\n",
    "                # parameterのsave\n",
    "                if epoch % self.epoch_saveParamter == 1:\n",
    "                    path = \"model\"\n",
    "                    if not os.path.isdir(path):\n",
    "                        os.makedirs(path)\n",
    "\n",
    "                    saver.save(sess, \"./model/acgan_model\" + str(epoch) + \".ckpt\")\n",
    "       \n",
    "\n",
    "    def sample_images(self, row=5, col=12, inputs=None, epoch=None):\n",
    "        images = self.g(inputs, training=True)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gan = GAN()\n",
    "gan.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
